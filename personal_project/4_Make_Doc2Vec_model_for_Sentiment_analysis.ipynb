{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec model\n",
    "> * Positive or Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Paragraph Vector\n",
    "> Le and Mikolov 2014 introduces the Paragraph Vector, which outperforms more naïve representations of documents such as averaging the Word2vec word vectors of a document. The idea is straightforward: we act as if a paragraph (or document) is just another vector like a word vector, but we will call it a paragraph vector. We determine the embedding of the paragraph in vector space in the same way as words. Our paragraph vector model considers local word order like bag of n-grams, but gives us a denser representation in vector space compared to a sparse, high-dimensional representation.\n",
    "\n",
    "> * Paragraph Vector - Distributed Memory (PV-DM)\n",
    ">> This is the Paragraph Vector model analogous to Continuous-bag-of-words Word2vec. The paragraph vectors are obtained by training a neural network on the fake task of inferring a center word based on context words and a context paragraph. A paragraph is a context for all words in the paragraph, and a word in a paragraph can have that paragraph as a context.\n",
    "\n",
    "> * Paragraph Vector - Distributed Bag of Words (PV-DBOW)\n",
    ">> This is the Paragraph Vector model analogous to Skip-gram Word2vec. The paragraph vectors are obtained by training a neural network on the fake task of predicting a probability distribution of words in a paragraph given a randomly-sampled word from the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성을 위한 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = int(multiprocessing.cpu_count())\n",
    "def Make_Doc2Vec_Model(data, size, dm, dm_concat, dm_mean, hs, negative, epoch, window, alpha, min_alpha, workers, tagger):\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas(desc=\"progress-bar\")\n",
    "    from datetime import datetime\n",
    "    from gensim.models import doc2vec\n",
    "    start = datetime.now()\n",
    "    modelPath = './model/'\n",
    "    modelName = 'doc2vec_size-{}_epoch-{}_window-{}_negative-{}_hs-{}_dm-{}_dm_concat-{}_dm_mean-{}_by-{}.model'.format(\n",
    "        size, epoch, window, negative, hs, dm, dm_concat, dm_mean, tagger)\n",
    "    modelName = modelPath+modelName\n",
    "    print (modelName)\n",
    "    if window!=None:\n",
    "        d2v_model = doc2vec.Doc2Vec(vector_size = size, dm = dm, dm_concat = dm_concat,\n",
    "                   dm_mean = dm_mean, negative = negative, hs = hs, window = window,\n",
    "                   alpha = alpha, min_alpha = min_alpha, workers = workers, epochs= epoch)\n",
    "    else:\n",
    "        d2v_model = doc2vec.Doc2Vec(vector_size = size, dm = dm, dm_concat = dm_concat,\n",
    "                   dm_mean = dm_mean, negative = negative, hs = hs,\n",
    "                   alpha = alpha, min_alpha = min_alpha, workers = workers, epochs= epoch)\n",
    "    d2v_model.build_vocab(tqdm(data))\n",
    "    d2v_model.train(tqdm(data), total_examples=d2v_model.corpus_count, epochs=d2v_model.iter)\n",
    "    \n",
    "    end = datetime.now()\n",
    "    d2v_model.save(modelName)\n",
    "    print (\"Total running time: \", end-start)\n",
    "    return d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정 분석을 위한 rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('./data/sentiment_data/raw_data_for_sentiment.txt',header=None,encoding='utf-8')\n",
    "print (rawdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Doc2Vec Using tagger Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "ct = ctwitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter\n",
    "def tokenize1(doc):\n",
    "    return ['/'.join(t) for t in ct.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_data_by_ct_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    raw_doc_ct = pickle.load(open('./data/pre_data/tagged_data/pre_raw_data_by_ct_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:    \n",
    "    raw_doc_ct = [(tokenize1(rawdata.loc[idx][0]), ['doc_'+str(idx)], [rawdata.loc[idx][1]]) for idx in tqdm(rawdata.index)]\n",
    "    pickle.dump(raw_doc_ct, open('./data/pre_data/tagged_data/pre_raw_data_by_ct_for_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec 기본 포맷으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_data_by_ct_tagged_doc2vec_sentiment_analysis.pickled'):\n",
    "    tagged_ct = pickle.load(open('./data/pre_data/tagged_data/pre_data_by_ct_tagged_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    tagged_ct = [TaggedDocument(b, c, d) for b, c, d in tqdm(raw_doc_ct)]\n",
    "    pickle.dump(tagged_ct, open('./data/pre_data/tagged_data/pre_data_by_ct_tagged_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_doc_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dataset & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(tagged_ct, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_by_ct_train_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    train = pickle.load(open('./data/pre_data/train_test_Data/pre_data_by_ct_train_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(train, open('./data/pre_data/train_test_Data/pre_data_by_ct_train_for_doc2vec_sentiment_analysis.pickled','wb'))\n",
    "    \n",
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_by_ct_test_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    test = pickle.load(open('./data/pre_data/train_test_Data/pre_data_by_ct_test_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(test, open('./data/pre_data/train_test_Data/pre_data_by_ct_test_for_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tagged_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 1 - distibuted memory (PV-DM)  \n",
    "* dm_concat : 1 - use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 0 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 5 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-5_negative-7_hs-0_dm-1_dm_concat-1_dm_mean-0_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:17<00:00, 25390.23it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [1:36:44<00:00, 76.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  4:55:11.823557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('문국현/Noun', 0.5745145678520203),\n",
      " ('손학규/Noun', 0.5639787912368774),\n",
      " ('정몽준/Noun', 0.5287864208221436),\n",
      " ('추미애/Noun', 0.5242229104042053),\n",
      " ('김종인/Noun', 0.5189003944396973),\n",
      " ('심상정/Noun', 0.5182517766952515),\n",
      " ('조순형/Noun', 0.5097339153289795),\n",
      " ('안상수/Noun', 0.5079224109649658),\n",
      " ('이정희/Noun', 0.49288955330848694),\n",
      " ('송영길/Noun', 0.4892556071281433)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('盧/Foreign', 0.5360435247421265),\n",
      " ('이명박/Noun', 0.4909990727901459),\n",
      " ('金泳三/Foreign', 0.4755754768848419),\n",
      " ('盧泰愚/Foreign', 0.467711865901947),\n",
      " ('金大中/Foreign', 0.4661300778388977),\n",
      " ('김영삼/Noun', 0.4571351706981659),\n",
      " ('마두로/Noun', 0.4521355926990509),\n",
      " ('김대중/Noun', 0.4520781636238098),\n",
      " ('노태우/Noun', 0.44878318905830383),\n",
      " ('무샤라프/Noun', 0.44861674308776855)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MB/Alpha', 0.4731568396091461),\n",
      " ('이명박/Noun', 0.4706622362136841),\n",
      " ('朴/Foreign', 0.4702518582344055),\n",
      " ('盧/Foreign', 0.4422094225883484),\n",
      " ('최병렬/Noun', 0.4401675760746002),\n",
      " ('노무현/Noun', 0.4201396107673645),\n",
      " ('아로요/Noun', 0.4178679585456848),\n",
      " ('盧泰愚/Foreign', 0.41626977920532227),\n",
      " ('무가베/Noun', 0.4150621294975281),\n",
      " ('라모스/Noun', 0.41151320934295654)]\n",
      "Wall time: 4h 55min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 1000, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 1 - distibuted memory (PV-DM)  \n",
    "* dm_concat : 0 - don't use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 1 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 10 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-10_negative-7_hs-0_dm-1_dm_concat-0_dm_mean-1_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:15<00:00, 29377.88it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [02:21<00:00, 3123.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:41:51.613135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('손학규/Noun', 0.28437939286231995),\n",
      " ('정세균/Noun', 0.2816855311393738),\n",
      " ('문/Noun', 0.28093063831329346),\n",
      " ('김한길/Noun', 0.2715970575809479),\n",
      " ('추미애/Noun', 0.2682795226573944),\n",
      " ('이태근/Noun', 0.2642826437950134),\n",
      " ('김중권/Noun', 0.2622499167919159),\n",
      " ('김/Noun', 0.2603785991668701),\n",
      " ('김종인/Noun', 0.25953930616378784),\n",
      " ('이인찬/Noun', 0.25789928436279297)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('노/Noun', 0.4571610391139984),\n",
      " ('이명박/Noun', 0.3688324987888336),\n",
      " ('김영삼/Noun', 0.3431937098503113),\n",
      " ('노태우/Noun', 0.34158068895339966),\n",
      " ('박근혜/Noun', 0.3341344892978668),\n",
      " ('金大中/Foreign', 0.30319347977638245),\n",
      " ('취임일/Noun', 0.30027008056640625),\n",
      " ('박/Noun', 0.2979949712753296),\n",
      " ('면노/Noun', 0.2967212200164795),\n",
      " ('“金大中/Foreign', 0.29175442457199097)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('박/Noun', 0.45748814940452576),\n",
      " ('이명박/Noun', 0.39562541246414185),\n",
      " ('김영삼/Noun', 0.36602863669395447),\n",
      " ('노/Noun', 0.3357464671134949),\n",
      " ('노태우/Noun', 0.33475083112716675),\n",
      " ('노무현/Noun', 0.33413445949554443),\n",
      " ('金泳三/Foreign', 0.32288122177124023),\n",
      " ('김대중/Noun', 0.3181714117527008),\n",
      " ('김전/Noun', 0.3008650541305542),\n",
      " ('盧泰愚/Foreign', 0.3006989359855652)]\n",
      "Wall time: 42min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 1000, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 0 - distributed bag of words (PV-DBOW)\n",
    "* dm_concat : 0 - don't use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 0 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 5 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-None_negative-7_hs-0_dm-0_dm_concat-0_dm_mean-0_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:18<00:00, 23646.48it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [01:55<00:00, 3833.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:32:03.951003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('사항/Noun', 0.1305052787065506),\n",
      " ('추진/Noun', 0.12882840633392334),\n",
      " ('해결될/Verb', 0.12366967648267746),\n",
      " ('놀람/Noun', 0.12347520887851715),\n",
      " ('부과방식/Noun', 0.1232670471072197),\n",
      " ('유가공/Noun', 0.12200957536697388),\n",
      " ('상의/Noun', 0.12150819599628448),\n",
      " ('동자/Noun', 0.12081922590732574),\n",
      " ('크로네/Noun', 0.12057416141033173),\n",
      " ('로맨스/Noun', 0.11997126042842865)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('표현하기/Verb', 0.1285589337348938),\n",
      " ('創黨/Foreign', 0.12728844583034515),\n",
      " ('궤적/Noun', 0.1240358054637909),\n",
      " ('할부금/Noun', 0.1219300925731659),\n",
      " ('향토기업/Noun', 0.12023414671421051),\n",
      " ('Customer/Alpha', 0.11999914795160294),\n",
      " ('최중경/Noun', 0.11913421750068665),\n",
      " ('계기/Noun', 0.11692361533641815),\n",
      " ('농식품부/Noun', 0.1168595626950264),\n",
      " ('홍대앞/Noun', 0.1159517914056778)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('에일린/Noun', 0.12598663568496704),\n",
      " ('스테이크하우스/Noun', 0.12526842951774597),\n",
      " ('핵심역량/Noun', 0.12277888506650925),\n",
      " ('오큘러스/Noun', 0.12205159664154053),\n",
      " ('자제령/Noun', 0.12167312204837799),\n",
      " ('choo/Alpha', 0.12156837433576584),\n",
      " ('김근/Noun', 0.12118206918239594),\n",
      " ('431/Number', 0.12076354771852493),\n",
      " ('바꾸시/Verb', 0.12017674744129181),\n",
      " ('말하시/Verb', 0.11960489302873611)]\n",
      "Wall time: 32min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# PV - DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 1000, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = None,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test\n",
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Doc2Vec Using tagger mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab\n",
    "def tokenize2(doc):\n",
    "    return ['/'.join(t) for t in mecab.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_raw_data_by_mecab_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    raw_doc_mecab = pickle.load(open('./data/pre_data/tagged_data/pre_raw_data_by_mecab_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:    \n",
    "    raw_doc_mecab = [(tokenize2(rawdata.loc[idx][0]), ['doc_'+str(idx)], [rawdata.loc[idx][1]]) for idx in tqdm(rawdata.index)]\n",
    "    pickle.dump(raw_doc_mecab, open('./data/pre_data/tagged_data/pre_raw_data_by_mecab_for_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec 기본 포맷으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_data_by_mecab_tagged_doc2vec_sentiment_analysis.pickled'):\n",
    "    tagged_mecab = pickle.load(open('./data/pre_data/tagged_data/pre_data_by_mecab_tagged_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    tagged_mecab = [TaggedDocument(b, c, d) for b, c, d in tqdm(raw_doc_mecab)]\n",
    "    pickle.dump(tagged_mecab, open('./data/pre_data/tagged_data/pre_data_by_mecab_tagged_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_doc_mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dataset & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train2, test2 = train_test_split(tagged_mecab, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_by_mecab_train_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    train2 = pickle.load(open('./data/pre_data/train_test_Data/pre_data_by_mecab_train_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(train2, open('./data/pre_data/train_test_Data/pre_data_by_mecab_train_for_doc2vec_sentiment_analysis.pickled','wb'))\n",
    "    \n",
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_by_mecab_test_for_doc2vec_sentiment_analysis.pickled'):\n",
    "    test2 = pickle.load(open('./data/pre_data/train_test_Data/pre_data_by_mecab_test_for_doc2vec_sentiment_analysis.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(test2, open('./data/pre_data/train_test_Data/pre_data_by_mecab_test_for_doc2vec_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tagged_mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 1 - distibuted memory (PV-DM)  \n",
    "* dm_concat : 1 - use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 0 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 5 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-5_negative-7_hs-0_dm-1_dm_concat-1_dm_mean-0_by-mecab.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:17<00:00, 25506.64it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [1:36:20<00:00, 76.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  4:51:59.582521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('김종인/NNP', 0.5914317965507507),\n",
      " ('김문수/NNP', 0.5768975615501404),\n",
      " ('김두관/NNP', 0.5701437592506409),\n",
      " ('정몽준/NNP', 0.5679817199707031),\n",
      " ('최병렬/NNP', 0.5669589638710022),\n",
      " ('안철수/NNP', 0.5669171214103699),\n",
      " ('김무성/NNP', 0.566095769405365),\n",
      " ('이정희/NNP', 0.5634468793869019),\n",
      " ('김한길/NNP', 0.5606587529182434),\n",
      " ('정세균/NNP', 0.5414032936096191)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이명박/NNP', 0.5704056024551392),\n",
      " ('노태우/NNP', 0.539089560508728),\n",
      " ('박정희/NNP', 0.4880334734916687),\n",
      " ('김대중/NNP', 0.48197466135025024),\n",
      " ('MB/SL', 0.47288140654563904),\n",
      " ('盧/NNG', 0.47176772356033325),\n",
      " ('노/XPN', 0.4700508117675781),\n",
      " ('최규하/NNP', 0.46087783575057983),\n",
      " ('무바라크/NNP', 0.457191526889801),\n",
      " ('전두환/NNP', 0.45221325755119324)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이명박/NNP', 0.5519698262214661),\n",
      " ('이재오/NNP', 0.4740789830684662),\n",
      " ('문재인/NNP', 0.4669095575809479),\n",
      " ('노무현/NNP', 0.4510551691055298),\n",
      " ('김희옥/NNP', 0.43907028436660767),\n",
      " ('盧/NNG', 0.4387660026550293),\n",
      " ('김무성/NNP', 0.43777239322662354),\n",
      " ('정몽준/NNP', 0.42740482091903687),\n",
      " ('문희상/NNP', 0.4208645224571228),\n",
      " ('이계/NNP', 0.4183489680290222)]\n",
      "Wall time: 4h 52min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 1000, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 1 - distibuted memory (PV-DM)  \n",
    "* dm_concat : 0 - don't use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 1 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 10 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-10_negative-7_hs-0_dm-1_dm_concat-0_dm_mean-1_by-mecab.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:20<00:00, 21154.88it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [02:25<00:00, 3035.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:44:00.894669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('정세균/NNP', 0.301902174949646),\n",
      " ('문재/NNG', 0.28970351815223694),\n",
      " ('문/VV+ETM', 0.2805789113044739),\n",
      " ('김중권/NNP', 0.2722403407096863),\n",
      " ('이태근/NNP', 0.2683906555175781),\n",
      " ('이기택/NNP', 0.26732707023620605),\n",
      " ('손학규/NNP', 0.2630409598350525),\n",
      " ('원희목/NNP', 0.2590258717536926),\n",
      " ('김한길/NNP', 0.25734183192253113),\n",
      " ('이회창/NNP', 0.25231292843818665)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('노/NNP', 0.4737602472305298),\n",
      " ('이명박/NNP', 0.43864765763282776),\n",
      " ('박근혜/NNP', 0.4373871684074402),\n",
      " ('김영삼/NNP', 0.3979782462120056),\n",
      " ('박/NNP', 0.3549848198890686),\n",
      " ('박정희/NNP', 0.3496416211128235),\n",
      " ('노/XPN', 0.34903544187545776),\n",
      " ('노/IC', 0.3286374807357788),\n",
      " ('나온다든지/VV+EC', 0.32059842348098755),\n",
      " ('노태우/NNP', 0.30990082025527954)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('박/NNP', 0.5090948343276978),\n",
      " ('노무현/NNP', 0.4373871684074402),\n",
      " ('노/NNP', 0.4117463231086731),\n",
      " ('이명박/NNP', 0.3763102889060974),\n",
      " ('김전/NNP', 0.36156490445137024),\n",
      " ('김영삼/NNP', 0.3613571226596832),\n",
      " ('노태우/NNP', 0.330650269985199),\n",
      " ('노/XPN', 0.3244098424911499),\n",
      " ('이기흥/NNP', 0.31733354926109314),\n",
      " ('이회창/NNP', 0.3152332901954651)]\n",
      "Wall time: 44min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 1000, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size : Dimensionality of the feature vectors \n",
    "* dm : 0 - distributed bag of words (PV-DBOW)\n",
    "* dm_concat : 0 - don't use concatenation of context vectors rather than sum/average  \n",
    "* dm_mean : 0 - don't use the sum of the context word vectors  \n",
    "> dm is used in non-concatenative mode.\n",
    "* negative : 7 - neative specifies how many 'noise words' should be drawn.\n",
    "* hs : 0 - hierarchical softmax 사용여부\n",
    "* window : 5 - The maximum distance between the current and predicted word within a sentence.  \n",
    "* alpha : the initial learning rate  \n",
    "* min_alpha : learning rate will linearly drop to min_alpha as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/doc2vec_size-1000_epoch-20_window-None_negative-7_hs-0_dm-0_dm_concat-0_dm_mean-0_by-mecab.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442359/442359 [00:15<00:00, 28935.19it/s]\n",
      "  0%|          | 0/442359 [00:00<?, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "100%|██████████| 442359/442359 [01:46<00:00, 4162.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:33:27.333062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('恒/NNG', 0.13732600212097168),\n",
      " ('동대문을/NNP', 0.12650419771671295),\n",
      " ('지니/VV', 0.11878867447376251),\n",
      " ('296/SN', 0.11741693317890167),\n",
      " ('말투/NNG', 0.11736077070236206),\n",
      " ('끈다/VV+EF', 0.11415259540081024),\n",
      " ('쿠치마/NNP', 0.11363274604082108),\n",
      " ('공사발주/NNP', 0.11336299777030945),\n",
      " ('들쑤셔/VV+EC', 0.11329080164432526),\n",
      " ('밝혀라/VV+EF', 0.11317186057567596)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('하사관/NNG', 0.14039146900177002),\n",
      " ('내치/VV', 0.13206955790519714),\n",
      " ('한랭전선/NNP', 0.13179874420166016),\n",
      " ('이명박정부/NNP', 0.1309611052274704),\n",
      " ('무진장/MAG', 0.13049069046974182),\n",
      " ('재외국민/NNP', 0.12885761260986328),\n",
      " ('Yes/SL', 0.12869225442409515),\n",
      " ('Blue/SL', 0.12623512744903564),\n",
      " ('저탄소/NNP', 0.12375755608081818),\n",
      " ('가구별/NNP', 0.1205480769276619)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('전라선/NNG', 0.13626524806022644),\n",
      " ('주무른/VV+ETM', 0.13590066134929657),\n",
      " ('행복나눔/NNP', 0.13064438104629517),\n",
      " ('깍두기/NNG', 0.12917208671569824),\n",
      " ('안내서비스/NNP', 0.12885552644729614),\n",
      " ('베일/NNG', 0.12714152038097382),\n",
      " ('버스비/NNP', 0.12303851544857025),\n",
      " ('부대사/NNP', 0.12252257019281387),\n",
      " ('먹잇감/NNP', 0.12188868224620819),\n",
      " ('집념/NNG', 0.12122316658496857)]\n",
      "Wall time: 33min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 1000, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = None,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train2\n",
    "del test2\n",
    "del d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
