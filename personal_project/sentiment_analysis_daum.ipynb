{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수집된 데이터에 대한 통계 분석\n",
    "* 데이터 \n",
    "> 2017년 12월 1일부터 2018년 1월 1일까지 32일간 [네이버](http://www.naver.com)와 [다음](http://www.daum.net)의 랭킹뉴스와 뉴스의 댓글을 크롤링함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import sys\n",
    "import time, re, pickle, itertools\n",
    "import urllib3, json\n",
    "sys.path.append('~/Documents/GitHub/Private_Project/personal_project/')\n",
    "import re\n",
    "from operator import itemgetter\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import chat_bot as cb\n",
    "import Database_Handler as dh\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import functools\n",
    "from konlpy.tag import Mecab\n",
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site = 'Naver'\n",
    "site = 'daum'\n",
    "if site == 'daum':\n",
    "    binList = []\n",
    "    collection = 'newsDaum'\n",
    "elif site.lower() == 'naver':\n",
    "    binList = []\n",
    "    collection = 'newsNaver'\n",
    "\n",
    "mongodb = dh.ToMongoDB(*dh.AWS_MongoDB_Information())\n",
    "dbname = 'hy_db'\n",
    "useDb = dh.Use_Database(mongodb, dbname)\n",
    "useCollection = dh.Use_Collection(useDb, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "def tokenize_pos2(doc):\n",
    "    return ['/'.join(t) for t in mecab.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv('./data/sentiment_data/raw_data_for_sentiment.txt',header=None, encoding='utf-8')\n",
    "rawdata.head()\n",
    "X = list(rawdata[0])\n",
    "y = np.array(list(rawdata[1]), dtype=int)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mecab_log1 = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos2, ngram_range=(1,2))), \n",
    "            ('log', LogisticRegression()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model_mecab_log1.fit(train_X, train_y)\n",
    "print(classification_report(test_y, model_mecab_log1.predict(test_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_mecab_log1, open('./data/pre_data/classifier_log_classifier_ngram12_by_mecab.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mecab_log1 = pickle.load(open('./data/pre_data/classifier_log_classifier_ngram12_by_mecab.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('./model/doc2vec_size2000_epoch20_by_mecab.model')\n",
    "classifier = pickle.load(open('./data/pre_data/classifier_by_mecab_from_doc2vec_size2000_epoch20.pickled','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 주의 \n",
    "> gensim의 doc2vec 모델의 infer_vector 함수를 이용해 벡터를 생성하면, 같은 단어열(문서)에 대해서도 여러번 호출하면 각기 다른 벡터가 나온다  \n",
    "> 이는 문서 벡터 추론 과정에서 랜덤하게 초기화하는 과정이 있기 때문인데, 문제는 결과로 나오는 벡터의 차이가 꽤 크다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cls(text, model, num):\n",
    "    mecab = Mecab()\n",
    "    def tokenize_pos2(doc):\n",
    "        return ['/'.join(t) for t in mecab.pos(doc)]\n",
    "    TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "    x2 = TaggedDocument(tokenize_pos2(text), 0.5)\n",
    "    out = list()\n",
    "    for idx in range(num):\n",
    "        x = model.infer_vector(x2.words)\n",
    "        cl = classifier.predict(x.reshape(1,-1))\n",
    "        out.append(cl)\n",
    "    out = list(itertools.chain.from_iterable(out))\n",
    "    cls2 = int(round(sum(out)/len(out)))\n",
    "    return cls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsDict = pickle.load(open('./data/pre_data/keywords_daum.pickled','rb'))\n",
    "#keywordsDict = pickle.load(open('./data/pre_data/keywords_Naver.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8249b834170b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtmpdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keywordsindaum'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtmpdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'analyzedkeywords'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeywordsDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtmpdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_crawledcomments'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mtmpdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'commentsestimation'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtmpdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'press'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'press'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\cursor.py\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self, with_limit_and_skip)\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"skip\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__skip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdistinct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, cmd, collation)\u001b[0m\n\u001b[0;32m   1348\u001b[0m                 \u001b[0mcodec_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__write_response_codec_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mread_concern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 collation=collation)\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ns missing\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36m_command\u001b[1;34m(self, sock_info, command, slave_ok, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mwrite_concern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             collation=collation)\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;31m# Catch socket.error, KeyboardInterrupt, etc. and close ourselves.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_doc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36m_raise_connection_failure\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[0m_raise_connection_failure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\pool.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    475\u001b[0m                            \u001b[0mread_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                            \u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m                            collation=collation)\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreceive_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         unpacked = helpers._unpack_response(\n\u001b[0;32m    110\u001b[0m             response, codec_options=codec_options)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36mreceive_message\u001b[1;34m(sock, operation, request_id, max_message_size)\u001b[0m\n\u001b[0;32m    135\u001b[0m         sock, operation, request_id, max_message_size=MAX_MESSAGE_SIZE):\n\u001b[0;32m    136\u001b[0m     \u001b[1;34m\"\"\"Receive a raw BSON message or raise socket.error.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_receive_data_on_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_UNPACK_INT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pymongo\\network.py\u001b[0m in \u001b[0;36m_receive_data_on_socket\u001b[1;34m(sock, length)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_errno_from_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "outputDict  =dict()\n",
    "collection = useCollection.find({'site':site})\n",
    "for data in collection:\n",
    "    idis = data['_id']._ObjectId__id.hex()\n",
    "    text = data['title']+'. '+data['mainText']    \n",
    "    commentCollection = dh.Use_Collection(useDb, 'comments')\n",
    "    comments = commentCollection.find({'site':site, 'category':data['category'], 'date':data['date'], 'rank':data['rank'] })\n",
    "    commEstimation = list()\n",
    "    for comment in comments:\n",
    "        comm = comment['comments']\n",
    "        commEstimation.append(Cls(comm, model, 30))\n",
    "    cls = sum(commEstimation)/ len(commEstimation)    \n",
    "    outputDict[idis] = tmpdict = dict()\n",
    "    tmpdict['title'] = data['title']\n",
    "    tmpdict['maintextestimation'] = Cls(text, model, 50)\n",
    "    tmpdict['keywordsindaum'] = data['keywords']\n",
    "    tmpdict['analyzedkeywords'] = keywordsDict[idis]\n",
    "    tmpdict['number_crawledcomments'] = comments.count()\n",
    "    tmpdict['commentsestimation'] = cls\n",
    "    tmpdict['press'] = data['press']\n",
    "    tmpdict['number_of_comment'] = data['number_of_comment']\n",
    "pickle.dump(outputDict, open('./outcome/outcome_daum_by_mecab.pickled','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
