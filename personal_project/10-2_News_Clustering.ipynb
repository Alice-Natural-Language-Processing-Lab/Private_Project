{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import html\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.cluster import KMeans, k_means_, DBSCAN, AgglomerativeClustering\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import hdbscan\n",
    "from gensim import models\n",
    "from gensim.corpora import mmcorpus, Dictionary\n",
    "from gensim.models import lsimodel, ldamodel, tfidfmodel, rpmodel, logentropy_model, TfidfModel, LsiModel, LdaModel\n",
    "from gensim import matutils, corpora\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import doc2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "import sys\n",
    "sys.path.append('~/Documents/GitHub/Private_Project/personal_project/')\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import chat_bot as cb\n",
    "import Database_Handler as dh\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import functools\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "mecab = Mecab()\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7681\n",
      "(7681, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a29c445588c132954d1973a</td>\n",
       "      <td>정치</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1713</td>\n",
       "      <td>1474</td>\n",
       "      <td>1</td>\n",
       "      <td>北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"</td>\n",
       "      <td>美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...</td>\n",
       "      <td>[외무성, 핵전쟁, 대변인]</td>\n",
       "      <td>{중앙, 핵전쟁, 북한, 조선반도, 고위, 대변인, 도화선, 미국}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a29c445588c132954d1973b</td>\n",
       "      <td>정치</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>한국일보</td>\n",
       "      <td>2551</td>\n",
       "      <td>2121</td>\n",
       "      <td>2</td>\n",
       "      <td>예산전쟁, 예결위 간사ㆍ호남이 웃었다</td>\n",
       "      <td>예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...</td>\n",
       "      <td>[예산, 예결위, soc]</td>\n",
       "      <td>{지역구, 예산안, 정부안, 호남, 의원, 국민의당, 증액}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a29c445588c132954d1973c</td>\n",
       "      <td>정치</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>610</td>\n",
       "      <td>540</td>\n",
       "      <td>3</td>\n",
       "      <td>혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나</td>\n",
       "      <td>【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...</td>\n",
       "      <td>[최경환, 구속영장, 국가정보원]</td>\n",
       "      <td>{정기국회, 국정원장, 혐의, 의원, 검찰, 조사, 구속영장 청구}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a29c445588c132954d1973d</td>\n",
       "      <td>정치</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>145</td>\n",
       "      <td>134</td>\n",
       "      <td>4</td>\n",
       "      <td>최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"</td>\n",
       "      <td>감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...</td>\n",
       "      <td>[이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]</td>\n",
       "      <td>{공직 사회, 법관, 생활, 지명, 후보자, 감사원장}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a29c445588c132954d1973e</td>\n",
       "      <td>정치</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>1074</td>\n",
       "      <td>937</td>\n",
       "      <td>5</td>\n",
       "      <td>B-1B 한반도에 뜨자, 평양 비운 김정은</td>\n",
       "      <td>[동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...</td>\n",
       "      <td>[김정은, b-1b, 한반도]</td>\n",
       "      <td>{펠트먼, 공장, 시찰, 삼지연, 접경, 양강도, 사무차장, 훈련, 김정은}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id category        date press  number_of_comment  \\\n",
       "0  5a29c445588c132954d1973a       정치  2017-12-07  연합뉴스               1713   \n",
       "1  5a29c445588c132954d1973b       정치  2017-12-07  한국일보               2551   \n",
       "2  5a29c445588c132954d1973c       정치  2017-12-07   뉴시스                610   \n",
       "3  5a29c445588c132954d1973d       정치  2017-12-07  연합뉴스                145   \n",
       "4  5a29c445588c132954d1973e       정치  2017-12-07  동아일보               1074   \n",
       "\n",
       "   number_of_crawled_comment  rank                            title  \\\n",
       "0                       1474     1    北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"   \n",
       "1                       2121     2             예산전쟁, 예결위 간사ㆍ호남이 웃었다   \n",
       "2                        540     3  혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나   \n",
       "3                        134     4   최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"   \n",
       "4                        937     5          B-1B 한반도에 뜨자, 평양 비운 김정은   \n",
       "\n",
       "                                            mainText  \\\n",
       "0  美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...   \n",
       "1  예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...   \n",
       "2  【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...   \n",
       "3  감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...   \n",
       "4  [동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...   \n",
       "\n",
       "                             keywords  \\\n",
       "0                     [외무성, 핵전쟁, 대변인]   \n",
       "1                      [예산, 예결위, soc]   \n",
       "2                  [최경환, 구속영장, 국가정보원]   \n",
       "3  [이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]   \n",
       "4                    [김정은, b-1b, 한반도]   \n",
       "\n",
       "                           extracted_keywords  \n",
       "0       {중앙, 핵전쟁, 북한, 조선반도, 고위, 대변인, 도화선, 미국}  \n",
       "1           {지역구, 예산안, 정부안, 호남, 의원, 국민의당, 증액}  \n",
       "2       {정기국회, 국정원장, 혐의, 의원, 검찰, 조사, 구속영장 청구}  \n",
       "3              {공직 사회, 법관, 생활, 지명, 후보자, 감사원장}  \n",
       "4  {펠트먼, 공장, 시찰, 삼지연, 접경, 양강도, 사무차장, 훈련, 김정은}  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDict = pickle.load(open('./data/pre_data/stastics/for_statistics_Naver_from_mongodb.pickled','rb'))\n",
    "print (len(dataDict))\n",
    "\n",
    "keywordsDict = pickle.load(open('./data/pre_data/keywords/keywords_Naver.pickled','rb'))\n",
    "\n",
    "for idx in dataDict:\n",
    "    dataDict[idx]['extracted_keywords'] = keywordsDict[idx]\n",
    "\n",
    "df = pd.DataFrame.from_dict(dataDict, orient='index')\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df.reset_index(inplace = True)\n",
    "df.rename(columns={'index':'id'}, inplace=True)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722\n",
      "(4722, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a2a61bf588c13481c229d1e</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>1093</td>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>\"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소</td>\n",
       "      <td>주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...</td>\n",
       "      <td>[부작용, 비아그라, 아일랜드]</td>\n",
       "      <td>{남성들, 공장, 부작용, 지역, 세보 효과, 건강, 연기}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a2a61bf588c13481c229d1f</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헬스조선</td>\n",
       "      <td>603</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지</td>\n",
       "      <td>점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...</td>\n",
       "      <td>[커피, 낮잠, 음식물]</td>\n",
       "      <td>{치아, 점심 식사, 디스크, 낮잠, 자세, 건강, 식후, 커피, 입냄새, 철분}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a2a61bf588c13481c229d20</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1067</td>\n",
       "      <td>811</td>\n",
       "      <td>3</td>\n",
       "      <td>'십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"</td>\n",
       "      <td>(성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...</td>\n",
       "      <td>[살인혐의, 철원, 검찰송치]</td>\n",
       "      <td>{성관계, 진술, 철원, 아들, 경찰, 범행, 지인, 주변, 남편, 앙심}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a2a61bf588c13481c229d21</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>신영자, 억 소리나는 갑질</td>\n",
       "      <td>신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...</td>\n",
       "      <td>[신영자, 갑질, 롯데백화점]</td>\n",
       "      <td>{네이처리퍼블릭, 유통업체, 혐의, 매장, 롯데, 검찰, 신영자 이사장, 징역}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a2a61bf588c13481c229d22</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>434</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>\"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지</td>\n",
       "      <td>(청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...</td>\n",
       "      <td>[공범, 살인, 과자]</td>\n",
       "      <td>{폭행, 경찰, 범행, 혐의, 쪽지, 과자, 유치장, 남자친구}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id category        date  press  number_of_comment  \\\n",
       "0  5a2a61bf588c13481c229d1e       뉴스  2017-12-07   세계일보               1093   \n",
       "1  5a2a61bf588c13481c229d1f       뉴스  2017-12-07   헬스조선                603   \n",
       "2  5a2a61bf588c13481c229d20       뉴스  2017-12-07   연합뉴스               1067   \n",
       "3  5a2a61bf588c13481c229d21       뉴스  2017-12-07  헤럴드경제                418   \n",
       "4  5a2a61bf588c13481c229d22       뉴스  2017-12-07   연합뉴스                434   \n",
       "\n",
       "   number_of_crawled_comment rank                                title  \\\n",
       "0                        911    1     \"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소   \n",
       "1                        386    2  식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지   \n",
       "2                        811    3  '십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"   \n",
       "3                        369    4                       신영자, 억 소리나는 갑질   \n",
       "4                        368    5   \"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지   \n",
       "\n",
       "                                            mainText           keywords  \\\n",
       "0   주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...  [부작용, 비아그라, 아일랜드]   \n",
       "1   점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...      [커피, 낮잠, 음식물]   \n",
       "2   (성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...   [살인혐의, 철원, 검찰송치]   \n",
       "3  신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...   [신영자, 갑질, 롯데백화점]   \n",
       "4  (청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...       [공범, 살인, 과자]   \n",
       "\n",
       "                              extracted_keywords  \n",
       "0              {남성들, 공장, 부작용, 지역, 세보 효과, 건강, 연기}  \n",
       "1  {치아, 점심 식사, 디스크, 낮잠, 자세, 건강, 식후, 커피, 입냄새, 철분}  \n",
       "2      {성관계, 진술, 철원, 아들, 경찰, 범행, 지인, 주변, 남편, 앙심}  \n",
       "3   {네이처리퍼블릭, 유통업체, 혐의, 매장, 롯데, 검찰, 신영자 이사장, 징역}  \n",
       "4            {폭행, 경찰, 범행, 혐의, 쪽지, 과자, 유치장, 남자친구}  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDict2 = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "print (len(dataDict2))\n",
    "\n",
    "keywordsDict2 = pickle.load(open('./data/pre_data/keywords/keywords_daum.pickled','rb'))\n",
    "\n",
    "for idx in dataDict2:\n",
    "    dataDict2[idx]['extracted_keywords'] = keywordsDict2[idx]\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(dataDict2, orient='index')\n",
    "df2['date'] = pd.to_datetime(df2['date']).dt.date\n",
    "df2.reset_index(inplace = True)\n",
    "df2.rename(columns={'index':'id'}, inplace=True)\n",
    "print (df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nav_tokenizer(corpus):\n",
    "    pos = mecab.pos(corpus)\n",
    "    res = [x[0] for x in pos if (x[1] == u'VV' or x[1] == u'VA' or x[1] == u'NNB' or x[1] == u'NNP' or x[1] == u'NNG')]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))\n",
    "def remove_stopwords(words, stopwords):\n",
    "    res = [x for x in words if x not in stopwords]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12403"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = np.concatenate((df.title.values+'.\\n'+df.mainText.values,\n",
    "                        df2.title.values+'.\\n'+df2.mainText.values))\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>것</td>\n",
       "      <td>44316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>있</td>\n",
       "      <td>40526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>수</td>\n",
       "      <td>26881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>등</td>\n",
       "      <td>24590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>하</td>\n",
       "      <td>22918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>기자</td>\n",
       "      <td>19123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>없</td>\n",
       "      <td>17961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>말</td>\n",
       "      <td>16773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>받</td>\n",
       "      <td>15411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>중</td>\n",
       "      <td>11396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  count\n",
       "5      것  44316\n",
       "226    있  40526\n",
       "116    수  26881\n",
       "32     등  24590\n",
       "88     하  22918\n",
       "43    기자  19123\n",
       "117    없  17961\n",
       "73     말  16773\n",
       "453    받  15411\n",
       "194    중  11396"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect0 = CountVectorizer(tokenizer=nav_tokenizer).fit(tqdm(corpus))\n",
    "temp = pd.DataFrame(list(vect0.vocabulary_.keys()), columns=['word'])\n",
    "temp['idx'] = vect0.vocabulary_.values()\n",
    "temp.sort_values(by='idx', inplace=True)\n",
    "temp.drop('idx', axis=1, inplace=True)\n",
    "temp['count'] = vect0.transform(corpus).toarray().sum(axis=0)\n",
    "temp.sort_values(['count'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12403/12403 [00:58<00:00, 213.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token n/a/v: 80715\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(tokenizer=nav_tokenizer, stop_words=stopwords)\n",
    "vect.fit(tqdm(corpus))\n",
    "print(\"token n/a/v: %d\" % len(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1695"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = [x for x in vect.vocabulary_ if len(x) == 1]\n",
    "len(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12403/12403 [00:56<00:00, 217.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token n/a/v: 79020\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(tokenizer=nav_tokenizer, stop_words=stopwords + mask1)\n",
    "vect.fit(tqdm(corpus))\n",
    "print(\"token n/a/v: %d\" % len(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vect.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12403/12403 [00:55<00:00, 221.59it/s]\n",
      "100%|██████████| 12403/12403 [03:39<00:00, 56.50it/s]\n"
     ]
    }
   ],
   "source": [
    "lda_docs = [nav_tokenizer(x) for x in tqdm(corpus)]\n",
    "lda_docs = [remove_stopwords(x, stopwords + mask1) for x in tqdm(lda_docs)]\n",
    "lda_dict = corpora.Dictionary(lda_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12403/12403 [00:02<00:00, 4947.30it/s]\n"
     ]
    }
   ],
   "source": [
    "tf_ps = [lda_dict.doc2bow(x) for x in tqdm(lda_docs)]\n",
    "tf_model = models.TfidfModel(tf_ps)\n",
    "X_lda = tf_model[tf_ps]\n",
    "corpora.MmCorpus.serialize('ps.mm', X_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train topic model\n",
    "ntopics =10\n",
    "nwords = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.002*\"김현수\" + 0.002*\"양현종\" + 0.002*\"경찰\" + 0.002*\"이상민\" + 0.002*\"데얀\"'),\n",
      " (1, '0.002*\"대통령\" + 0.002*\"일본\" + 0.002*\"정소민\" + 0.002*\"북한\" + 0.002*\"중국\"'),\n",
      " (2, '0.006*\"전현무\" + 0.002*\"추자현\" + 0.002*\"송중기\" + 0.002*\"한혜진\" + 0.002*\"송혜교\"'),\n",
      " (3, '0.004*\"연예대상\" + 0.003*\"집사부일체\" + 0.003*\"강호동\" + 0.002*\"이상윤\" + 0.002*\"강식당\"'),\n",
      " (4, '0.007*\"선수\" + 0.005*\"손흥민\" + 0.005*\"경기\" + 0.004*\"감독\" + 0.004*\"계약\"'),\n",
      " (5, '0.004*\"대상\" + 0.003*\"유재석\" + 0.003*\"수상\" + 0.003*\"지성\" + 0.003*\"연기\"'),\n",
      " (6, '0.005*\"이준\" + 0.003*\"백종원\" + 0.002*\"일레븐\" + 0.001*\"팔라우\" + 0.001*\"번리\"'),\n",
      " (7, '0.003*\"고준희\" + 0.003*\"사이보그\" + 0.003*\"천호진\" + 0.003*\"이승기\" + 0.002*\"화유기\"'),\n",
      " (8, '0.001*\"류진\" + 0.001*\"이강인\" + 0.001*\"한양\" + 0.001*\"발렌시아\" + 0.001*\"독대\"'),\n",
      " (9, '0.003*\"박나래\" + 0.003*\"연기\" + 0.003*\"드라마\" + 0.003*\"이주연\" + 0.002*\"방송\"')]\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "np.random.seed(1)\n",
    "lda = models.ldamodel.LdaModel(X_lda, id2word=lda_dict, num_topics=ntopics)\n",
    "pprint(lda.print_topics(num_topics=ntopics, num_words=nwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labem from lda model\n",
    "def get_labels(model, tres, sentence):\n",
    "    lda = model\n",
    "    proba_list = lda[sentence]\n",
    "    res = [x for x in proba_list if x[1] >= tres]\n",
    "    if len(res) == 0:\n",
    "        res = None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunyoun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/hyunyoun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "for i in range(10):\n",
    "    dfRes[i] = 0; \n",
    "dfRes['unknown'] = 0\n",
    "    \n",
    "for i in range(len(tf_ps)):\n",
    "    temp = get_labels(lda, 0.3, tf_ps[i])\n",
    "    if temp != None:\n",
    "        idx = [x[0] for x in temp]\n",
    "        dfRes.set_value(i, idx, 1)\n",
    "    elif temp == None:\n",
    "        dfRes.set_value(i, ['unknown'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label(0): 3881\n",
      "label(1): 5429\n",
      "label(2): 38\n",
      "label(3): 71\n",
      "label(4): 2727\n",
      "label(5): 282\n",
      "label(6): 19\n",
      "label(7): 114\n",
      "label(8): 10\n",
      "label(9): 3245\n",
      "unknown: 106\n"
     ]
    }
   ],
   "source": [
    "# number of reviews for each label\n",
    "for i in range(10):\n",
    "    print('label({}): {}'.format(i, len(dfRes[(dfRes[i] == 1)])))\n",
    "print('unknown: {}'.format(len(dfRes[(dfRes['unknown'] == 1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12403it [00:00, 288904.92it/s]\n"
     ]
    }
   ],
   "source": [
    "d2v_docs = [nav_tokenizer(x) for x in corpus]\n",
    "d2v_docs = [remove_stopwords(x, (stopwords + mask1)) for x in d2v_docs]\n",
    "tagged_d2v_docs = [TaggedDocument(doc, [idx]) for idx, doc in tqdm(enumerate(d2v_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = doc2vec.Doc2Vec(size=300, window=5, alpha=0.025, min_alpha=0.025, seed=0)\n",
    "d2v_model.build_vocab(tagged_d2v_docs)\n",
    "d2v_model.train_lbls = False # do not train labels of words\n",
    "d2v_model.train_words = True # only train relations among words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    d2v_model.train(tagged_d2v_docs, total_examples=len(d2v_docs), epochs=epoch)\n",
    "    d2v_model.alpha -= 0.002 # decrease the learning rate\n",
    "    d2v_model.min_alpha = d2v_model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d2v = [d2v_model.infer_vector(x.words) for x in tagged_d2v_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.cluster import k_means_ \n",
    "\n",
    "def euc2cos_distance(X, Y=None, Y_norm_squared=None, squared=False):\n",
    "    return cosine_distances(X,Y)\n",
    "\n",
    "k_means_.euclidean_distances = euc2cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.038\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=cnum, init='k-means++', max_iter=300, n_init=20, tol=0.0001)\n",
    "km.fit(X_d2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_d2v, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label0: 63\n",
      "label1: 3644\n",
      "label2: 863\n",
      "label3: 529\n",
      "label4: 672\n",
      "label5: 245\n",
      "label6: 4187\n",
      "label7: 490\n",
      "label8: 787\n",
      "label9: 923\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "dfRes['label'] = km.labels_\n",
    "\n",
    "for i in range(cnum):\n",
    "    print('label{}: {}'.format(i, len(dfRes[dfRes.label == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top keywords\n",
    "def print_topwords(df, num, bar):\n",
    "    try:\n",
    "        temp_cor = df.text.values\n",
    "        temp_vec = TfidfVectorizer(tokenizer=nav_tokenizer, stop_words=stopwords + mask1)\n",
    "\n",
    "        temp_vec.fit(temp_cor)\n",
    "\n",
    "        temp = pd.DataFrame(temp_vec.vocabulary_.keys(), columns=['word'])\n",
    "        temp['idx'] = temp_vec.vocabulary_.values()\n",
    "        temp.sort_values(by='idx', inplace=True)\n",
    "        temp['count'] = temp_vec.transform(temp_cor).toarray().sum(axis=0)\n",
    "\n",
    "        topwords = temp.sort_values(['count'], ascending=False)[:num]    \n",
    "    \n",
    "        for i in range(num):\n",
    "            print(topwords['word'].values[i]),\n",
    "\n",
    "        if bar == True:\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.bar(range(num), topwords['count'].values, align='center')\n",
    "            plt.xticks([x for x in range(num)], topwords['word'].values)\n",
    "            ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "cluster 9:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.172\n"
     ]
    }
   ],
   "source": [
    "agg = AgglomerativeClustering(n_clusters=cnum, affinity='cosine', linkage='complete')\n",
    "agg.fit(X_d2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_d2v, agg.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 1382\n",
      "label 1: 1575\n",
      "label 2: 1708\n",
      "label 3: 784\n",
      "label 4: 3073\n",
      "label 5: 631\n",
      "label 6: 544\n",
      "label 7: 4\n",
      "label 8: 1140\n",
      "label 9: 1562\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "dfRes['label'] = agg.labels_\n",
    "for i in range(len(dfRes.label.unique())):\n",
    "    print('label {}: {}'.format(i, len(dfRes.loc[dfRes['label'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "cluster 9:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "dfRes['label'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label -1: 12403\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfRes.label.unique())):\n",
    "    if i == 0 :\n",
    "        print('label -1: {}'.format(len(dfRes.loc[dfRes['label'] == i-1])))\n",
    "    else:\n",
    "        print('label {}: {}'.format(i-1, len(dfRes.loc[dfRes['label'] == i-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster -1:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1, cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=10, prediction_data=True).fit(X_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnum = len(np.unique(cluster.labels_)) - 1\n",
    "cnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_docs = [nav_tokenizer(x) for x in corpus]\n",
    "lda_docs = [remove_stopwords(x, stopwords + mask1) for x in lda_docs]\n",
    "lda_dict = corpora.Dictionary(lda_docs)\n",
    "#calulate TF-IDF\n",
    "tf_ps = [lda_dict.doc2bow(x) for x in lda_docs]\n",
    "tf_model = models.TfidfModel(tf_ps)\n",
    "X_lda = tf_model[tf_ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.007*\"천호진\" + 0.004*\"강식당\" + 0.004*\"신과함께\" + 0.004*\"신생아\" + 0.003*\"박종철\"'),\n",
      " (1, '0.007*\"고준희\" + 0.005*\"로사리오\" + 0.005*\"시상\" + 0.004*\"김연아\" + 0.004*\"시신\"'),\n",
      " (2, '0.004*\"수상\" + 0.004*\"감독\" + 0.004*\"이준\" + 0.003*\"일본\" + 0.003*\"역적\"'),\n",
      " (3, '0.016*\"연예대상\" + 0.007*\"애플\" + 0.006*\"버라이어티\" + 0.006*\"아이폰\" + 0.005*\"배터리\"'),\n",
      " (4, '0.013*\"계약\" + 0.013*\"선수\" + 0.011*\"두산\" + 0.009*\"투수\" + 0.008*\"구단\"'),\n",
      " (5, '0.005*\"이민지\" + 0.005*\"가구\" + 0.004*\"엄기준\" + 0.004*\"배수지\" + 0.004*\"가요대축제\"'),\n",
      " (6, '0.007*\"추자현\" + 0.005*\"우효광\" + 0.005*\"당협위원장\" + 0.002*\"편의점\" + 0.002*\"로빈\"'),\n",
      " (7,\n",
      "  '0.007*\"비트코인\" + 0.005*\"가상화폐\" + 0.004*\"미운우리새끼\" + 0.004*\"박수홍\" + 0.003*\"거래소\"'),\n",
      " (8, '0.009*\"내연녀\" + 0.008*\"런닝맨\" + 0.005*\"전소민\" + 0.003*\"재신임\" + 0.003*\"이우인\"'),\n",
      " (9, '0.016*\"박나래\" + 0.014*\"전현무\" + 0.008*\"기안84\" + 0.004*\"한혜진\" + 0.004*\"이상윤\"'),\n",
      " (10, '0.010*\"강정호\" + 0.007*\"박시후\" + 0.006*\"서지안\" + 0.005*\"황금빛\" + 0.004*\"피츠버그\"'),\n",
      " (11, '0.008*\"선수\" + 0.006*\"한화\" + 0.005*\"양현종\" + 0.005*\"경기\" + 0.005*\"리그\"'),\n",
      " (12, '0.014*\"데얀\" + 0.003*\"김치\" + 0.003*\"손준호\" + 0.003*\"흑산\" + 0.003*\"아드리아노\"'),\n",
      " (13, '0.028*\"손흥민\" + 0.013*\"토트넘\" + 0.012*\"케인\" + 0.006*\"호날두\" + 0.004*\"포체티노\"'),\n",
      " (14, '0.005*\"대상\" + 0.004*\"연기\" + 0.004*\"방송\" + 0.003*\"배우\" + 0.003*\"대통령\"'),\n",
      " (15, '0.010*\"맨유\" + 0.004*\"맨체스터\" + 0.004*\"맨시티\" + 0.004*\"미키타리안\" + 0.004*\"포그바\"'),\n",
      " (16, '0.005*\"경찰\" + 0.004*\"남매\" + 0.004*\"아파트\" + 0.004*\"이승기\" + 0.004*\"광주\"'),\n",
      " (17, '0.003*\"당무\" + 0.003*\"베란다\" + 0.002*\"이종범\" + 0.002*\"장동건\" + 0.002*\"미디어센터\"'),\n",
      " (18, '0.009*\"이승우\" + 0.006*\"베로나\" + 0.005*\"안영명\" + 0.005*\"김승회\" + 0.003*\"보너스\"'),\n",
      " (19, '0.009*\"사이보그\" + 0.005*\"담뱃불\" + 0.004*\"혐의\" + 0.003*\"재판\" + 0.003*\"베란다\"'),\n",
      " (20, '0.003*\"송중기\" + 0.003*\"송혜교\" + 0.003*\"시상자\" + 0.003*\"강재욱\" + 0.002*\"인스타그램\"'),\n",
      " (21, '0.003*\"이상우\" + 0.003*\"윤계상\" + 0.003*\"유서\" + 0.003*\"조나탄\" + 0.002*\"실업자\"'),\n",
      " (22, '0.008*\"이주연\" + 0.004*\"시장\" + 0.003*\"윤균상\" + 0.003*\"지지율\" + 0.002*\"임금\"'),\n",
      " (23, '0.006*\"원전\" + 0.005*\"빈소\" + 0.004*\"테임즈\" + 0.004*\"장례식장\" + 0.003*\"애프터스쿨\"'),\n",
      " (24, '0.009*\"다스\" + 0.004*\"진선규\" + 0.003*\"박서준\" + 0.003*\"왓포드\" + 0.003*\"연예통신\"'),\n",
      " (25, '0.009*\"오승환\" + 0.009*\"월드컵\" + 0.007*\"류현진\" + 0.006*\"축구\" + 0.005*\"다저스\"'),\n",
      " (26, '0.008*\"화유기\" + 0.005*\"파퀴아오\" + 0.004*\"복싱\" + 0.004*\"김구라\" + 0.003*\"이재성\"'),\n",
      " (27, '0.006*\"추신수\" + 0.004*\"가르시아\" + 0.003*\"트레이드\" + 0.003*\"텍사스\" + 0.003*\"헥터\"'),\n",
      " (28, '0.011*\"이상민\" + 0.009*\"니퍼트\" + 0.004*\"조영국\" + 0.003*\"우제\" + 0.003*\"라틀리프\"'),\n",
      " (29, '0.008*\"김생민\" + 0.007*\"시티\" + 0.006*\"스완지\" + 0.005*\"김영철\" + 0.005*\"영수증\"')]\n"
     ]
    }
   ],
   "source": [
    "# train topic model\n",
    "ntopics = 30\n",
    "nwords = 5\n",
    "\n",
    "np.random.seed(1)\n",
    "lda_model = models.ldamodel.LdaModel(X_lda, id2word=lda_dict, num_topics=ntopics)\n",
    "pprint(lda_model.print_topics(num_topics=ntopics, num_words=nwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('文정부 첫 감사원장 후보자에 최재형 사법연수원장(상보).\\n'\n",
      " '감사원장 후보자로 지명된 최재형 사법연수원장. 2017.3.2/뉴스1 © News1 박정호 기자  (서울=뉴스1) 김현 기자 = 문재인 '\n",
      " '대통령은 7일 황찬현 전 감사원장의 퇴임으로 공석이 된 감사원장 후보자에 최재형(61) 사법연수원장을 지명했다.  최 후보자가 국회 '\n",
      " '인사청문회와 인준 표결을 거쳐 감사원장에 취임하게 되면 새 정부에서 임명된 첫 감사원장이 된다.  윤영찬 청와대 국민소통수석은 이날 '\n",
      " '춘추관에서 브리핑을 갖고 최 원장을 감사원장 후보자로 지명했다고 발표했다.  최 후보자는 경남 진해 출신으로, 경기고와 서울대 법학과를 '\n",
      " '졸업했다. 사법시험 23회(사법연수원 13기)로 서울지방법원 동부지원 판사를 시작으로 판사 생활을 걸어왔다.  대전지방법원 '\n",
      " '법원장(대전가정법원 법원장 겸임), 서울가정법원 법원장, 서울고등법원 부장판사를 거쳐 올해 2월부터 사법연수원장에 재임하고 있다.  '\n",
      " \"gayunlove@news1.kr  ▶ '평창2018' 관련 뉴스·포토 보기 ▶ 네이버메인에 ‘뉴스1채널’ 설정하기! ▶ 여러분의 제보를 \"\n",
      " '기다립니다.제보하기! [© 뉴스1코리아(news1.kr), 무단 전재 및 재배포 금지]')\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "pprint(corpus[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.083438501),\n",
       " (7, 0.11213528),\n",
       " (14, 0.16372836),\n",
       " (15, 0.03779294),\n",
       " (27, 0.46762866)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[X_lda[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12403, 30)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_vec = np.zeros((len(corpus), ntopics))\n",
    "lda_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise small number to calculate cosine distances\n",
    "lda_vec = lda_vec + 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l2v = np.hstack((X_d2v, lda_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.032\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=cnum, init='k-means++', max_iter=300, n_init=20, tol=0.0001)\n",
    "km.fit(X_l2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_l2v, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label0: 584\n",
      "label1: 762\n",
      "label2: 8\n",
      "label3: 814\n",
      "label4: 525\n",
      "label5: 4341\n",
      "label6: 898\n",
      "label7: 257\n",
      "label8: 616\n",
      "label9: 3598\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "dfRes['label'] = km.labels_\n",
    "\n",
    "for i in range(cnum):\n",
    "    print('label{}: {}'.format(i, len(dfRes[dfRes.label == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "cluster 9:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.30, min_samples=10, algorithm='kd_tree', metric='euclidean')\n",
    "Y = db.fit_predict(lda_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Silhouette Coefficient: 0.073\n"
     ]
    }
   ],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "cnum = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % cnum)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_l2v, db.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "dfRes['label'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise-1: 19\n",
      " | \n",
      "\n",
      "cluster 0: 12384\n",
      " | \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfRes.label.unique())):\n",
    "    if i == 0 :\n",
    "        print('noise-1: {}'.format(len(dfRes.loc[dfRes['label'] == i-1]))),\n",
    "        print(\" | \"),\n",
    "        print_topwords(df=dfRes.loc[dfRes['label'] == i-1], num=5, bar=False)\n",
    "    else:\n",
    "        print('cluster {}: {}'.format(i-1, len(dfRes.loc[dfRes['label'] == i-1]))),\n",
    "        print(\" | \"),\n",
    "        print_topwords(df=dfRes.loc[dfRes['label'] == i-1], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size=55, prediction_data=True).fit(X_l2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnum = len(np.unique(cluster.labels_)) - 1\n",
    "cnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid shape in axis 1: 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-cb0978523c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 클러스터별 Probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoft_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_points_membership_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msoft_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hdbscan/prediction.py\u001b[0m in \u001b[0;36mall_points_membership_vectors\u001b[0;34m(clusterer)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                                         \u001b[0mclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondensed_tree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                                                         \u001b[0mclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_data_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_max_lambdas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                                                         clusterer.prediction_data_.cluster_tree)\n\u001b[0m\u001b[1;32m    533\u001b[0m     in_cluster_probs = all_points_prob_in_some_cluster(clusters,\n\u001b[1;32m    534\u001b[0m                                                        \u001b[0mclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondensed_tree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mhdbscan/_prediction_utils.pyx\u001b[0m in \u001b[0;36mhdbscan._prediction_utils.all_points_outlier_membership_vector (hdbscan/_prediction_utils.c:6953)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mhdbscan/_prediction_utils.pyx\u001b[0m in \u001b[0;36mhdbscan._prediction_utils.all_points_outlier_membership_vector (hdbscan/_prediction_utils.c:6543)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mhdbscan/_prediction_utils.pyx\u001b[0m in \u001b[0;36mhdbscan._prediction_utils.all_points_per_cluster_scores (hdbscan/_prediction_utils.c:6093)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hdbscan/_prediction_utils.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mView.MemoryView.array_cwrapper (hdbscan/_prediction_utils.c:11490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hdbscan/_prediction_utils.cpython-36m-darwin.so\u001b[0m in \u001b[0;36mView.MemoryView.array.__cinit__ (hdbscan/_prediction_utils.c:10294)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid shape in axis 1: 0."
     ]
    }
   ],
   "source": [
    "# 클러스터별 Probabilities\n",
    "soft_cluster = hdbscan.all_points_membership_vectors(cluster)\n",
    "soft_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRes = pd.DataFrame(corpus, columns=['text'])\n",
    "for i in range(cnum):\n",
    "    dfRes[i] = 0; \n",
    "dfRes['noise'] = 0\n",
    "dfRes['unknown'] = 0\n",
    "\n",
    "for i in range(len(soft_cluster)):\n",
    "    \n",
    "    if np.isnan(soft_cluster[i][0]):\n",
    "        dfRes.set_value(i, ['noise'], 1)\n",
    "    elif len([x for x in soft_cluster[i] if x != 0]) == 0:\n",
    "        dfRes.set_value(i, ['unknown'], 1)\n",
    "    else:\n",
    "        # max probability의 0.9 이상일 때 라벨링\n",
    "        #idx = [j for j, x in enumerate(soft_cluster[i]) if x >= (0.9 * soft_cluster[i].max())]\n",
    "        idx = [j for j, x in enumerate(soft_cluster[i]) if (x == soft_cluster[i].max()) | (x >= 0.2)]\n",
    "        #idx = [j for j, x in enumerate(soft_cluster[i]) if (x == soft_cluster[i].max())]\n",
    "        dfRes.set_value(i, idx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('noise-1: {} | '.format(len(dfRes[(dfRes['noise'] == 1)]))),\n",
    "print_topwords(df=dfRes.loc[dfRes['noise'] == 1], num=5, bar=False)\n",
    "print(\"\")\n",
    "print('unknown: {} | '.format(len(dfRes[(dfRes['unknown'] == 1)]))),\n",
    "print_topwords(df=dfRes.loc[dfRes['unknown'] == 1], num=5, bar=False)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "for i in range(cnum):\n",
    "    print('cluster {}: {}'.format(i, len(dfRes.loc[dfRes[i] == 1]))),\n",
    "    print(\" | \"),\n",
    "    print_topwords(df=dfRes.loc[dfRes[i] == 1], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
