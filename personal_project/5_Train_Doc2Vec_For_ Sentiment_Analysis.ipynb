{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "> * Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import html\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "import multiprocessing\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "import numpy as np\n",
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "mecab = Mecab()\n",
    "ct = ctwitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open('./data/pre_data/train_test_Data/pre_by_ct_train.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('./model/doc2vec_size2000_epoch15_window5_dbow_words_by_ct.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = [model.infer_vector(doc.words) for doc in tqdm(train)]\n",
    "train_y = [doc.tags[0] for doc in tqdm(train)]\n",
    "pickle.dump(train_x,open('./data/pre_data/train_test_Data/train_x_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))\n",
    "pickle.dump(train_y,open('./data/pre_data/train_test_Data/train_y_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del train_x\n",
    "del train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load(open('./data/pre_data/train_test_Data/pre_by_ct_test.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [model.infer_vector(doc.words) for doc in tqdm(test)]\n",
    "test_y = [doc.tags[0] for doc in tqdm(test)]\n",
    "pickle.dump(test_x,open('./data/pre_data/train_test_Data/test_x_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))\n",
    "pickle.dump(test_y,open('./data/pre_data/train_test_Data/test_y_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open('./data/pre_data/train_test_Data/train_x_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))\n",
    "train_y = pickle.load(open('./data/pre_data/train_test_Data/train_y_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=1234)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier,open('./data/pre_data/classifier/classifier_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=1234, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2 = RandomForestRegressor(random_state=1234)\n",
    "classifier2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier2,open('./data/pre_data/classifier/classifier_randomforest_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_x\n",
    "del train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pickle.load(open('./data/pre_data/train_test_Data/test_x_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))\n",
    "test_y = pickle.load(open('./data/pre_data/train_test_Data/test_y_by_ct_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6434660535899575\n"
     ]
    }
   ],
   "source": [
    "print( classifier.score(test_x, test_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.023260050049506154\n"
     ]
    }
   ],
   "source": [
    "print( classifier2.score(test_x, test_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_x\n",
    "del test_y\n",
    "del classifier\n",
    "del classifier2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size 1000 : 0.640541518255\n",
    "* size 2000 : 0.646232190561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pickle.load(open('./data/pre_data/train_test_Data/pre_by_mecab_train.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = doc2vec.Doc2Vec.load('./model/doc2vec_size2000_epoch15_window5_dbow_words_by_mecab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_x = [model2.infer_vector(doc.words) for doc in tqdm(train2)]\n",
    "train2_y = [doc.tags[0] for doc in tqdm(train2)]\n",
    "pickle.dump(train2_x,open('./data/pre_data/train_test_Data/train2_x_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))\n",
    "pickle.dump(train2_y,open('./data/pre_data/train_test_Data/train2_y_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train2\n",
    "del train2_x\n",
    "del train2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pickle.load(open('./data/pre_data/train_test_Data/pre_by_mecab_test.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_x = [model2.infer_vector(doc.words) for doc in tqdm(test2)]\n",
    "test2_y = [doc.tags[0] for doc in tqdm(test2)]\n",
    "pickle.dump(test2_x,open('./data/pre_data/train_test_Data/test2_x_by_mecab_from_doc2vec_siz2000_epoch15_window5_dbow_words.pickled','wb'))\n",
    "pickle.dump(test2_y,open('./data/pre_data/train_test_Data/test2_y_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_x = pickle.load(open('./data/pre_data/train_test_Data/train2_x_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))\n",
    "train2_y = pickle.load(open('./data/pre_data/train_test_Data/train2_y_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_ = LogisticRegression(random_state=1234)\n",
    "classifier_.fit(train2_x, train2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier_,open('./data/pre_data/classifier/classifier_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=1234, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2_ = RandomForestRegressor(random_state=1234)\n",
    "classifier2_.fit(train2_x, train2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier2_,open('./data/pre_data/classifier/classifier_randomforest_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train2_x\n",
    "del train2_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_x = pickle.load(open('./data/pre_data/train_test_Data/test2_x_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))\n",
    "test2_y = pickle.load(open('./data/pre_data/train_test_Data/test2_y_by_mecab_from_doc2vec_size2000_epoch15_window5_dbow_words.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530080771500071\n"
     ]
    }
   ],
   "source": [
    "print( classifier_.score(test2_x, test2_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.020073609585938845\n"
     ]
    }
   ],
   "source": [
    "print( classifier2_.score(test2_x, test2_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test2_x\n",
    "del test2_y\n",
    "del classifier_\n",
    "del classifier2_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* size 1000 : 0.64909839715\n",
    "* size 2000 : 0.663053762244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "7555it [00:00, 75435.69it/s]\n",
      "16478it [00:00, 79866.21it/s]\n",
      "25102it [00:00, 81909.00it/s]\n",
      "36590it [00:00, 87824.12it/s]\n",
      "49574it [00:00, 95374.37it/s]\n",
      "60814it [00:00, 98256.43it/s]\n",
      "75523it [00:00, 104443.62it/s]\n",
      "89970it [00:00, 109286.45it/s]\n",
      "102956it [00:00, 110301.48it/s]\n",
      "114850it [00:01, 109319.37it/s]\n",
      "126221it [00:01, 109212.25it/s]\n",
      "138984it [00:01, 110313.68it/s]\n",
      "150536it [00:01, 110197.42it/s]\n",
      "163533it [00:01, 110852.58it/s]\n",
      "175390it [00:01, 111261.68it/s]\n",
      "190126it [00:01, 113472.58it/s]\n",
      "206870it [00:01, 116239.97it/s]\n",
      "224105it [00:01, 118835.63it/s]\n",
      "238550it [00:01, 120055.79it/s]\n",
      "258639it [00:02, 123920.08it/s]\n",
      "277552it [00:02, 126892.82it/s]\n",
      "294418it [00:02, 128654.01it/s]\n",
      "311276it [00:02, 129180.03it/s]\n",
      "327251it [00:02, 130130.69it/s]\n",
      "342948it [00:02, 130649.21it/s]\n",
      "358250it [00:02, 131269.86it/s]\n",
      "373369it [00:02, 131131.43it/s]\n",
      "387790it [00:02, 131307.97it/s]\n",
      "401967it [00:03, 131514.70it/s]\n",
      "416224it [00:03, 131685.32it/s]\n",
      "432113it [00:03, 132432.19it/s]\n",
      "442359it [00:03, 133040.55it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  8.61it/s]\n",
      "292it [00:00, 1306.21it/s]\n",
      "476it [00:00, 1443.71it/s]\n",
      "586it [00:00, 1236.49it/s]\n",
      "686it [00:00, 1146.94it/s]\n",
      "780it [00:00, 1072.45it/s]\n",
      "868it [00:00, 1042.16it/s]\n",
      "1353it [00:00, 1439.43it/s]\n",
      "1751it [00:01, 1681.86it/s]\n",
      "2195it [00:01, 1903.27it/s]\n",
      "2493it [00:01, 1937.85it/s]\n",
      "2859it [00:01, 2054.41it/s]\n",
      "3335it [00:01, 2213.28it/s]\n",
      "4234it [00:01, 2589.60it/s]\n",
      "4677it [00:01, 2685.33it/s]\n",
      "5158it [00:01, 2800.46it/s]\n",
      "6051it [00:02, 3001.34it/s]\n",
      "6814it [00:02, 3216.24it/s]\n",
      "8134it [00:02, 3658.96it/s]\n",
      "9019it [00:02, 3873.81it/s]\n",
      "9807it [00:02, 4005.51it/s]\n",
      "10556it [00:02, 3869.79it/s]\n",
      "11161it [00:02, 3936.92it/s]\n",
      "12078it [00:02, 4113.60it/s]\n",
      "12969it [00:03, 4253.13it/s]\n",
      "14048it [00:03, 4460.49it/s]\n",
      "15456it [00:03, 4756.30it/s]\n",
      "16456it [00:03, 4376.18it/s]\n",
      "17566it [00:04, 3574.62it/s]\n",
      "19624it [00:05, 3913.65it/s]\n",
      "20627it [00:05, 3489.25it/s]\n",
      "21378it [00:06, 3556.04it/s]\n",
      "22148it [00:06, 3623.16it/s]\n",
      "23050it [00:06, 3709.94it/s]\n",
      "25033it [00:06, 3915.49it/s]\n",
      "28169it [00:06, 4254.07it/s]\n",
      "31697it [00:06, 4677.22it/s]\n",
      "35896it [00:06, 5219.68it/s]\n",
      "38137it [00:07, 5313.41it/s]\n",
      "39930it [00:07, 5480.63it/s]\n",
      "41678it [00:07, 5622.40it/s]\n",
      "43530it [00:07, 5794.73it/s]\n",
      "45987it [00:07, 6041.26it/s]\n",
      "49151it [00:07, 6394.65it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "train_vecs_w2v = np.concatenate([z.reshape(1,-1) for z in tqdm(map(lambda x: x, train2_x))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([z.reshape(1,-1) for z in tqdm(map(lambda x: x, test2_x))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_test2 = np_utils.to_categorical(test2_y,2)\n",
    "y_train2 = np_utils.to_categorical(train2_y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 12s - loss: 0.8608 - acc: 0.5281\n",
      "Epoch 2/100\n",
      " - 13s - loss: 0.7960 - acc: 0.5569\n",
      "Epoch 3/100\n",
      " - 12s - loss: 0.7843 - acc: 0.5679\n",
      "Epoch 4/100\n",
      " - 12s - loss: 0.7781 - acc: 0.5723\n",
      "Epoch 5/100\n",
      " - 12s - loss: 0.7701 - acc: 0.5779\n",
      "Epoch 6/100\n",
      " - 12s - loss: 0.7607 - acc: 0.5852\n",
      "Epoch 7/100\n",
      " - 12s - loss: 0.7538 - acc: 0.5900\n",
      "Epoch 8/100\n",
      " - 12s - loss: 0.7476 - acc: 0.5934\n",
      "Epoch 9/100\n",
      " - 12s - loss: 0.7409 - acc: 0.5982\n",
      "Epoch 10/100\n",
      " - 12s - loss: 0.7388 - acc: 0.5983\n",
      "Epoch 11/100\n",
      " - 12s - loss: 0.7291 - acc: 0.6051\n",
      "Epoch 12/100\n",
      " - 12s - loss: 0.7220 - acc: 0.6081\n",
      "Epoch 13/100\n",
      " - 12s - loss: 0.7205 - acc: 0.6074\n",
      "Epoch 14/100\n",
      " - 12s - loss: 0.7162 - acc: 0.6102\n",
      "Epoch 15/100\n",
      " - 12s - loss: 0.7141 - acc: 0.6088\n",
      "Epoch 16/100\n",
      " - 12s - loss: 0.7095 - acc: 0.6110\n",
      "Epoch 17/100\n",
      " - 12s - loss: 0.7071 - acc: 0.6120\n",
      "Epoch 18/100\n",
      " - 12s - loss: 0.7019 - acc: 0.6141\n",
      "Epoch 19/100\n",
      " - 12s - loss: 0.6970 - acc: 0.6169\n",
      "Epoch 20/100\n",
      " - 12s - loss: 0.6926 - acc: 0.6169\n",
      "Epoch 21/100\n",
      " - 12s - loss: 0.6915 - acc: 0.6171\n",
      "Epoch 22/100\n",
      " - 12s - loss: 0.6878 - acc: 0.6190\n",
      "Epoch 23/100\n",
      " - 12s - loss: 0.6842 - acc: 0.6197\n",
      "Epoch 24/100\n",
      " - 12s - loss: 0.6817 - acc: 0.6199\n",
      "Epoch 25/100\n",
      " - 12s - loss: 0.6775 - acc: 0.6228\n",
      "Epoch 26/100\n",
      " - 12s - loss: 0.6736 - acc: 0.6235\n",
      "Epoch 27/100\n",
      " - 12s - loss: 0.6715 - acc: 0.6241\n",
      "Epoch 28/100\n",
      " - 12s - loss: 0.6709 - acc: 0.6228\n",
      "Epoch 29/100\n",
      " - 12s - loss: 0.6690 - acc: 0.6233\n",
      "Epoch 30/100\n",
      " - 12s - loss: 0.6671 - acc: 0.6231\n",
      "Epoch 31/100\n",
      " - 13s - loss: 0.6640 - acc: 0.6252\n",
      "Epoch 32/100\n",
      " - 12s - loss: 0.6607 - acc: 0.6266\n",
      "Epoch 33/100\n",
      " - 12s - loss: 0.6590 - acc: 0.6259\n",
      "Epoch 34/100\n",
      " - 13s - loss: 0.6570 - acc: 0.6268\n",
      "Epoch 35/100\n",
      " - 13s - loss: 0.6556 - acc: 0.6269\n",
      "Epoch 36/100\n",
      " - 13s - loss: 0.6530 - acc: 0.6271\n",
      "Epoch 37/100\n",
      " - 12s - loss: 0.6490 - acc: 0.6299\n",
      "Epoch 38/100\n",
      " - 12s - loss: 0.6478 - acc: 0.6298\n",
      "Epoch 39/100\n",
      " - 12s - loss: 0.6469 - acc: 0.6298\n",
      "Epoch 40/100\n",
      " - 12s - loss: 0.6468 - acc: 0.6291\n",
      "Epoch 41/100\n",
      " - 12s - loss: 0.6426 - acc: 0.6321\n",
      "Epoch 42/100\n",
      " - 12s - loss: 0.6414 - acc: 0.6317\n",
      "Epoch 43/100\n",
      " - 12s - loss: 0.6410 - acc: 0.6318\n",
      "Epoch 44/100\n",
      " - 12s - loss: 0.6389 - acc: 0.6326\n",
      "Epoch 45/100\n",
      " - 12s - loss: 0.6372 - acc: 0.6322\n",
      "Epoch 46/100\n",
      " - 12s - loss: 0.6352 - acc: 0.6332\n",
      "Epoch 47/100\n",
      " - 12s - loss: 0.6345 - acc: 0.6333\n",
      "Epoch 48/100\n",
      " - 12s - loss: 0.6321 - acc: 0.6343\n",
      "Epoch 49/100\n",
      " - 12s - loss: 0.6312 - acc: 0.6350\n",
      "Epoch 50/100\n",
      " - 12s - loss: 0.6306 - acc: 0.6337\n",
      "Epoch 51/100\n",
      " - 12s - loss: 0.6280 - acc: 0.6358\n",
      "Epoch 52/100\n",
      " - 12s - loss: 0.6279 - acc: 0.6349\n",
      "Epoch 53/100\n",
      " - 12s - loss: 0.6242 - acc: 0.6375\n",
      "Epoch 54/100\n",
      " - 12s - loss: 0.6254 - acc: 0.6356\n",
      "Epoch 55/100\n",
      " - 13s - loss: 0.6224 - acc: 0.6373\n",
      "Epoch 56/100\n",
      " - 13s - loss: 0.6233 - acc: 0.6359\n",
      "Epoch 57/100\n",
      " - 12s - loss: 0.6225 - acc: 0.6366\n",
      "Epoch 58/100\n",
      " - 12s - loss: 0.6217 - acc: 0.6366\n",
      "Epoch 59/100\n",
      " - 12s - loss: 0.6196 - acc: 0.6388\n",
      "Epoch 60/100\n",
      " - 12s - loss: 0.6172 - acc: 0.6386\n",
      "Epoch 61/100\n",
      " - 12s - loss: 0.6161 - acc: 0.6401\n",
      "Epoch 62/100\n",
      " - 12s - loss: 0.6190 - acc: 0.6362\n",
      "Epoch 63/100\n",
      " - 12s - loss: 0.6154 - acc: 0.6400\n",
      "Epoch 64/100\n",
      " - 12s - loss: 0.6144 - acc: 0.6407\n",
      "Epoch 65/100\n",
      " - 12s - loss: 0.6130 - acc: 0.6401\n",
      "Epoch 66/100\n",
      " - 12s - loss: 0.6132 - acc: 0.6413\n",
      "Epoch 67/100\n",
      " - 12s - loss: 0.6119 - acc: 0.6413\n",
      "Epoch 68/100\n",
      " - 12s - loss: 0.6134 - acc: 0.6378\n",
      "Epoch 69/100\n",
      " - 12s - loss: 0.6104 - acc: 0.6409\n",
      "Epoch 70/100\n",
      " - 12s - loss: 0.6088 - acc: 0.6418\n",
      "Epoch 71/100\n",
      " - 13s - loss: 0.6076 - acc: 0.6431\n",
      "Epoch 72/100\n",
      " - 12s - loss: 0.6077 - acc: 0.6430\n",
      "Epoch 73/100\n",
      " - 13s - loss: 0.6093 - acc: 0.6412\n",
      "Epoch 74/100\n",
      " - 13s - loss: 0.6060 - acc: 0.6432\n",
      "Epoch 75/100\n",
      " - 13s - loss: 0.6053 - acc: 0.6441\n",
      "Epoch 76/100\n",
      " - 13s - loss: 0.6049 - acc: 0.6433\n",
      "Epoch 77/100\n",
      " - 12s - loss: 0.6054 - acc: 0.6424\n",
      "Epoch 78/100\n",
      " - 12s - loss: 0.6036 - acc: 0.6450\n",
      "Epoch 79/100\n",
      " - 13s - loss: 0.6044 - acc: 0.6427\n",
      "Epoch 80/100\n",
      " - 12s - loss: 0.6045 - acc: 0.6413\n",
      "Epoch 81/100\n",
      " - 13s - loss: 0.6007 - acc: 0.6452\n",
      "Epoch 82/100\n",
      " - 13s - loss: 0.6030 - acc: 0.6431\n",
      "Epoch 83/100\n",
      " - 12s - loss: 0.5993 - acc: 0.6455\n",
      "Epoch 84/100\n",
      " - 13s - loss: 0.6023 - acc: 0.6425\n",
      "Epoch 85/100\n",
      " - 12s - loss: 0.5996 - acc: 0.6450\n",
      "Epoch 86/100\n",
      " - 12s - loss: 0.5995 - acc: 0.6470\n",
      "Epoch 87/100\n",
      " - 12s - loss: 0.5975 - acc: 0.6459\n",
      "Epoch 88/100\n",
      " - 13s - loss: 0.6021 - acc: 0.6436\n",
      "Epoch 89/100\n",
      " - 12s - loss: 0.5972 - acc: 0.6465\n",
      "Epoch 90/100\n",
      " - 13s - loss: 0.5954 - acc: 0.6494\n",
      "Epoch 91/100\n",
      " - 13s - loss: 0.5971 - acc: 0.6446\n",
      "Epoch 92/100\n",
      " - 13s - loss: 0.5971 - acc: 0.6464\n",
      "Epoch 93/100\n",
      " - 13s - loss: 0.5960 - acc: 0.6474\n",
      "Epoch 94/100\n",
      " - 13s - loss: 0.5956 - acc: 0.6481\n",
      "Epoch 95/100\n",
      " - 12s - loss: 0.5938 - acc: 0.6478\n",
      "Epoch 96/100\n",
      " - 13s - loss: 0.5963 - acc: 0.6457\n",
      "Epoch 97/100\n",
      " - 12s - loss: 0.5931 - acc: 0.6483\n",
      "Epoch 98/100\n",
      " - 13s - loss: 0.5926 - acc: 0.6482\n",
      "Epoch 99/100\n",
      " - 13s - loss: 0.6004 - acc: 0.6413\n",
      "Epoch 100/100\n",
      " - 13s - loss: 0.5903 - acc: 0.6521\n",
      "0.643527089977082\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Dense, Embedding, embeddings, merge, Dropout, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=2000))\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(#optimizer='rmsprop',\n",
    "    optimizer='adadelta',\n",
    "              #loss='binary_crossentropy',\n",
    "    #optimizer=SGD(lr=0.2), \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vecs_w2v, y_train2,epochs=100, batch_size=50000, verbose=2)\n",
    "score = model.evaluate(test_vecs_w2v, y_test2, verbose=2)\n",
    "print (score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 308s - loss: 0.8742 - acc: 0.5350\n",
      "Epoch 2/100\n",
      " - 11s - loss: 0.7318 - acc: 0.5519\n",
      "Epoch 3/100\n",
      " - 11s - loss: 0.6888 - acc: 0.5632\n",
      "Epoch 4/100\n",
      " - 12s - loss: 0.6653 - acc: 0.5772\n",
      "Epoch 5/100\n",
      " - 12s - loss: 0.6516 - acc: 0.5846\n",
      "Epoch 6/100\n",
      " - 11s - loss: 0.6417 - acc: 0.5936\n",
      "Epoch 7/100\n",
      " - 12s - loss: 0.6342 - acc: 0.5994\n",
      "Epoch 8/100\n",
      " - 11s - loss: 0.6286 - acc: 0.6033\n",
      "Epoch 9/100\n",
      " - 11s - loss: 0.6243 - acc: 0.6072\n",
      "Epoch 10/100\n",
      " - 12s - loss: 0.6200 - acc: 0.6099\n",
      "Epoch 11/100\n",
      " - 11s - loss: 0.6166 - acc: 0.6128\n",
      "Epoch 12/100\n",
      " - 11s - loss: 0.6135 - acc: 0.6156\n",
      "Epoch 13/100\n",
      " - 12s - loss: 0.6103 - acc: 0.6189\n",
      "Epoch 14/100\n",
      " - 11s - loss: 0.6077 - acc: 0.6211\n",
      "Epoch 15/100\n",
      " - 11s - loss: 0.6051 - acc: 0.6235\n",
      "Epoch 16/100\n",
      " - 11s - loss: 0.6033 - acc: 0.6245\n",
      "Epoch 17/100\n",
      " - 12s - loss: 0.6014 - acc: 0.6259\n",
      "Epoch 18/100\n",
      " - 11s - loss: 0.5993 - acc: 0.6278\n",
      "Epoch 19/100\n",
      " - 11s - loss: 0.5979 - acc: 0.6284\n",
      "Epoch 20/100\n",
      " - 12s - loss: 0.5956 - acc: 0.6311\n",
      "Epoch 21/100\n",
      " - 12s - loss: 0.5941 - acc: 0.6322\n",
      "Epoch 22/100\n",
      " - 12s - loss: 0.5919 - acc: 0.6340\n",
      "Epoch 23/100\n",
      " - 12s - loss: 0.5912 - acc: 0.6345\n",
      "Epoch 24/100\n",
      " - 12s - loss: 0.5896 - acc: 0.6360\n",
      "Epoch 25/100\n",
      " - 11s - loss: 0.5876 - acc: 0.6387\n",
      "Epoch 26/100\n",
      " - 11s - loss: 0.5871 - acc: 0.6392\n",
      "Epoch 27/100\n",
      " - 11s - loss: 0.5854 - acc: 0.6403\n",
      "Epoch 28/100\n",
      " - 11s - loss: 0.5843 - acc: 0.6417\n",
      "Epoch 29/100\n",
      " - 12s - loss: 0.5828 - acc: 0.6429\n",
      "Epoch 30/100\n",
      " - 12s - loss: 0.5815 - acc: 0.6446\n",
      "Epoch 31/100\n",
      " - 12s - loss: 0.5804 - acc: 0.6446\n",
      "Epoch 32/100\n",
      " - 11s - loss: 0.5792 - acc: 0.6460\n",
      "Epoch 33/100\n",
      " - 12s - loss: 0.5780 - acc: 0.6476\n",
      "Epoch 34/100\n",
      " - 11s - loss: 0.5768 - acc: 0.6483\n",
      "Epoch 35/100\n",
      " - 11s - loss: 0.5764 - acc: 0.6477\n",
      "Epoch 36/100\n",
      " - 11s - loss: 0.5748 - acc: 0.6502\n",
      "Epoch 37/100\n",
      " - 11s - loss: 0.5742 - acc: 0.6511\n",
      "Epoch 38/100\n",
      " - 11s - loss: 0.5735 - acc: 0.6507\n",
      "Epoch 39/100\n",
      " - 12s - loss: 0.5721 - acc: 0.6530\n",
      "Epoch 40/100\n",
      " - 11s - loss: 0.5713 - acc: 0.6528\n",
      "Epoch 41/100\n",
      " - 11s - loss: 0.5704 - acc: 0.6536\n",
      "Epoch 42/100\n",
      " - 11s - loss: 0.5697 - acc: 0.6545\n",
      "Epoch 43/100\n",
      " - 12s - loss: 0.5686 - acc: 0.6548\n",
      "Epoch 44/100\n",
      " - 11s - loss: 0.5675 - acc: 0.6574\n",
      "Epoch 45/100\n",
      " - 11s - loss: 0.5665 - acc: 0.6566\n",
      "Epoch 46/100\n",
      " - 11s - loss: 0.5653 - acc: 0.6581\n",
      "Epoch 47/100\n",
      " - 11s - loss: 0.5649 - acc: 0.6589\n",
      "Epoch 48/100\n",
      " - 11s - loss: 0.5637 - acc: 0.6600\n",
      "Epoch 49/100\n",
      " - 12s - loss: 0.5624 - acc: 0.6604\n",
      "Epoch 50/100\n",
      " - 11s - loss: 0.5620 - acc: 0.6607\n",
      "Epoch 51/100\n",
      " - 12s - loss: 0.5610 - acc: 0.6616\n",
      "Epoch 52/100\n",
      " - 12s - loss: 0.5603 - acc: 0.6619\n",
      "Epoch 53/100\n",
      " - 12s - loss: 0.5594 - acc: 0.6622\n",
      "Epoch 54/100\n",
      " - 12s - loss: 0.5590 - acc: 0.6629\n",
      "Epoch 55/100\n",
      " - 12s - loss: 0.5577 - acc: 0.6643\n",
      "Epoch 56/100\n",
      " - 12s - loss: 0.5570 - acc: 0.6645\n",
      "Epoch 57/100\n",
      " - 12s - loss: 0.5561 - acc: 0.6648\n",
      "Epoch 58/100\n",
      " - 11s - loss: 0.5554 - acc: 0.6658\n",
      "Epoch 59/100\n",
      " - 12s - loss: 0.5544 - acc: 0.6669\n",
      "Epoch 60/100\n",
      " - 12s - loss: 0.5530 - acc: 0.6677\n",
      "Epoch 61/100\n",
      " - 12s - loss: 0.5523 - acc: 0.6680\n",
      "Epoch 62/100\n",
      " - 12s - loss: 0.5512 - acc: 0.6680\n",
      "Epoch 63/100\n",
      " - 12s - loss: 0.5512 - acc: 0.6689\n",
      "Epoch 64/100\n",
      " - 11s - loss: 0.5508 - acc: 0.6689\n",
      "Epoch 65/100\n",
      " - 11s - loss: 0.5496 - acc: 0.6705\n",
      "Epoch 66/100\n",
      " - 12s - loss: 0.5486 - acc: 0.6706\n",
      "Epoch 67/100\n",
      " - 11s - loss: 0.5473 - acc: 0.6718\n",
      "Epoch 68/100\n",
      " - 11s - loss: 0.5464 - acc: 0.6727\n",
      "Epoch 69/100\n",
      " - 11s - loss: 0.5457 - acc: 0.6720\n",
      "Epoch 70/100\n",
      " - 12s - loss: 0.5445 - acc: 0.6742\n",
      "Epoch 71/100\n",
      " - 11s - loss: 0.5435 - acc: 0.6743\n",
      "Epoch 72/100\n",
      " - 11s - loss: 0.5427 - acc: 0.6748\n",
      "Epoch 73/100\n",
      " - 11s - loss: 0.5417 - acc: 0.6759\n",
      "Epoch 74/100\n",
      " - 11s - loss: 0.5415 - acc: 0.6765\n",
      "Epoch 75/100\n",
      " - 11s - loss: 0.5408 - acc: 0.6757\n",
      "Epoch 76/100\n",
      " - 12s - loss: 0.5400 - acc: 0.6767\n",
      "Epoch 77/100\n",
      " - 11s - loss: 0.5393 - acc: 0.6770\n",
      "Epoch 78/100\n",
      " - 12s - loss: 0.5392 - acc: 0.6770\n",
      "Epoch 79/100\n",
      " - 12s - loss: 0.5369 - acc: 0.6785\n",
      "Epoch 80/100\n",
      " - 12s - loss: 0.5371 - acc: 0.6787\n",
      "Epoch 81/100\n",
      " - 12s - loss: 0.5356 - acc: 0.6801\n",
      "Epoch 82/100\n",
      " - 12s - loss: 0.5345 - acc: 0.6805\n",
      "Epoch 83/100\n",
      " - 12s - loss: 0.5333 - acc: 0.6814\n",
      "Epoch 84/100\n",
      " - 12s - loss: 0.5330 - acc: 0.6813\n",
      "Epoch 85/100\n",
      " - 11s - loss: 0.5323 - acc: 0.6819\n",
      "Epoch 86/100\n",
      " - 11s - loss: 0.5316 - acc: 0.6824\n",
      "Epoch 87/100\n",
      " - 12s - loss: 0.5311 - acc: 0.6826\n",
      "Epoch 88/100\n",
      " - 12s - loss: 0.5302 - acc: 0.6837\n",
      "Epoch 89/100\n",
      " - 12s - loss: 0.5292 - acc: 0.6838\n",
      "Epoch 90/100\n",
      " - 11s - loss: 0.5290 - acc: 0.6843\n",
      "Epoch 91/100\n",
      " - 11s - loss: 0.5279 - acc: 0.6839\n",
      "Epoch 92/100\n",
      " - 11s - loss: 0.5268 - acc: 0.6856\n",
      "Epoch 93/100\n",
      " - 11s - loss: 0.5258 - acc: 0.6855\n",
      "Epoch 94/100\n",
      " - 11s - loss: 0.5249 - acc: 0.6867\n",
      "Epoch 95/100\n",
      " - 12s - loss: 0.5248 - acc: 0.6869\n",
      "Epoch 96/100\n",
      " - 11s - loss: 0.5238 - acc: 0.6864\n",
      "Epoch 97/100\n",
      " - 11s - loss: 0.5230 - acc: 0.6880\n",
      "Epoch 98/100\n",
      " - 11s - loss: 0.5226 - acc: 0.6887\n",
      "Epoch 99/100\n",
      " - 11s - loss: 0.5215 - acc: 0.6892\n",
      "Epoch 100/100\n",
      " - 11s - loss: 0.5204 - acc: 0.6898\n",
      "Score: 0.8014\n",
      "Accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "mode2 = Sequential()\n",
    "mode2.add(Dense(64, activation='relu', input_dim=2000))\n",
    "mode2.add(Dropout(0.25))\n",
    "mode2.add(Dense(32, activation='relu'))\n",
    "mode2.add(Dropout(0.125))\n",
    "mode2.add(Dense(2, activation='softmax'))\n",
    "mode2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train model\n",
    "mode2.fit(train_vecs_w2v, y_train2,epochs=100, batch_size=50000, verbose=2)\n",
    "# Evaluate model\n",
    "score, acc = model.evaluate(test_vecs_w2v, y_test2, verbose=2)\n",
    "\n",
    "\n",
    "print('Score: %1.4f' % score)\n",
    "print('Accuracy: %1.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=len(list(model2.docvecs)),\n",
    "                           output_dim = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py:1993: UserWarning: RNN dropout is no longer supported with the Theano backend due to technical limitations. You can either set `dropout` and `recurrent_dropout` to 0, or use the TensorFlow backend.\n",
      "  'RNN dropout is no longer supported with the Theano backend '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "\nApply node that caused the error: AdvancedSubtensor1(embedding_1/embeddings, Elemwise{Cast{int32}}.0)\nToposort index: 85\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(2, 2000), (50000000,)]\nInputs strides: [(8000, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(AdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-64-942622cb4a8c>\", line 3, in <module>\n    nn_model.add(embedding_layer)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\", line 489, in gather\n    y = reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-942622cb4a8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                  metrics=['accuracy'])\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_vecs_w2v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m# Evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_vecs_w2v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    918\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: \nApply node that caused the error: AdvancedSubtensor1(embedding_1/embeddings, Elemwise{Cast{int32}}.0)\nToposort index: 85\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(2, 2000), (50000000,)]\nInputs strides: [(8000, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(AdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-64-942622cb4a8c>\", line 3, in <module>\n    nn_model.add(embedding_layer)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\models.py\", line 467, in add\n    layer(x)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\layers\\embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\keras\\backend\\theano_backend.py\", line 489, in gather\n    y = reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation\n",
    "nn_model = Sequential()\n",
    "nn_model.add(embedding_layer)\n",
    "nn_model.add(LSTM(2))\n",
    "nn_model.add(Dense(2))\n",
    "nn_model.add(Activation('sigmoid'))\n",
    "nn_model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Train...')\n",
    "nn_model.fit(train_vecs_w2v, y_train2,epochs=10, batch_size=25000)\n",
    "# Evaluate model\n",
    "score, acc = nn_model.evaluate(test_vecs_w2v, y_test2, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
