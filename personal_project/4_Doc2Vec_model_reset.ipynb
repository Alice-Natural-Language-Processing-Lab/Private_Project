{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec model\n",
    "> * Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "def Make_Doc2Vec_Model(data, size, dm, dm_concat, dm_mean, hs, negative, epoch, window, alpha, min_alpha, workers, tagger):\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas(desc=\"progress-bar\")\n",
    "    from datetime import datetime\n",
    "    from gensim.models import doc2vec\n",
    "    start = datetime.now()\n",
    "    modelPath = './model/'\n",
    "    modelName = 'doc2vec_size-{}_epoch-{}_window-{}_negative-{}_hs-{}_dm-{}_dm_concat-{}_dm_mean-{}_by-{}.model'.format(\n",
    "        size, epoch, window, negative, hs, dm, dm_concat, dm_mean, tagger)\n",
    "    modelName = modelPath+modelName\n",
    "    print (modelName)\n",
    "    d2v_model = doc2vec.Doc2Vec(vector_size = size, dm = dm, dm_concat = dm_concat,\n",
    "                   dm_mean = dm_mean, negative = negative, hs = hs, window = window,\n",
    "                   alpha = alpha, min_alpha = min_alpha, workers = workers, epochs= epoch)\n",
    "    d2v_model.build_vocab(tqdm(data))\n",
    "    d2v_model.train(tqdm(train), total_examples=d2v_model.corpus_count, epochs=d2v_model.iter)\n",
    "    \n",
    "    end = datetime.now()\n",
    "    d2v_model.save(modelName)\n",
    "    print (\"Total running time: \", end-start)\n",
    "    return d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* vector size\n",
    " [ 1000, 2000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491510, 2)\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_csv('./data/sentiment_data/raw_data_for_sentiment.txt',header=None,encoding='utf-8')\n",
    "print (rawdata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tagging twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "ct = ctwitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter\n",
    "def tokenize1(doc):\n",
    "    return ['/'.join(t) for t in ct.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "raw_doc_ct = [(tokenize1(rawdata.loc[idx][0]), rawdata.loc[idx][1]) for idx in tqdm(rawdata.index)]\n",
    "pickle.dump(raw_doc_ct, open('./data/pre_data/tagged_data/pre_data_by_ct_for_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "tagged_ct = [TaggedDocument(d, [c]) for d, c in tqdm(raw_doc_ct)]\n",
    "pickle.dump(tagged_ct, open('./data/pre_data/tagged_data/pre_by_ct_data_tagged_run_docs.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_doc_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 있을 때\n",
    "tagged_ct = pickle.load(open('./data/pre_data/tagged_data/pre_by_ct_data_tagged_run_docs.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "train, test = train_test_split(tagged_ct, test_size=0.1, random_state=42)\n",
    "del tagged_ct\n",
    "pickle.dump(train, open('./data/pre_data/train_test_Data/pre_by_ct_train.pickled','wb'))\n",
    "pickle.dump(test, open('./data/pre_data/train_test_Data/pre_by_ct_test.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 있을 때\n",
    "train = pickle.load(open('./data/pre_data/train_test_Data/pre_by_ct_train.pickled','rb'))\n",
    "test = pickle.load(open('./data/pre_data/train_test_Data/pre_by_ct_test.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 2000, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 2000, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train, size = 2000, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "pprint(d2v_model.most_similar('문재인/Noun'))\n",
    "pprint(d2v_model.most_similar('노무현/Noun'))\n",
    "pprint(d2v_model.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test\n",
    "del d2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tagging mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab\n",
    "def tokenize2(doc):\n",
    "    return ['/'.join(t) for t in mecab.pos(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "raw_doc_mecab = [(tokenize2(rawdata.loc[idx][0]), rawdata.loc[idx][1]) for idx in tqdm(rawdata.index)]\n",
    "pickle.dump(raw_doc_mecab, open('./data/pre_data/tagged_data/pre_data_by_mecab_for_sentiment_analysis.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "tagged_mecab = [TaggedDocument(d, [c]) for d, c in raw_doc_mecab]\n",
    "pickle.dump(tagged_mecab, open('./data/pre_data/tagged_data/pre_by_mecab_data_tagged_run_docs.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_doc_mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 있을 때\n",
    "tagged_mecab = pickle.load(open('./data/pre_data/tagged_data/pre_by_mecab_data_tagged_run_docs.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 없을 때\n",
    "train2, test2 = train_test_split(tagged_mecab, test_size=0.1, random_state=42)\n",
    "del tagged_ct\n",
    "pickle.dump(train2, open('./data/pre_data/train_test_Data/pre_by_mecab_train.pickled','wb'))\n",
    "pickle.dump(test2, open('./data/pre_data/train_test_Data/pre_by_mecab_test.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle로 저장된 파일이 있을 때\n",
    "train2 = pickle.load(open('./data/pre_data/train_test_Data/pre_by_mecab_train.pickled','rb'))\n",
    "test2 = pickle.load(open('./data/pre_data/train_test_Data/pre_by_mecab_test.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 2000, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 2000, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(data=train2, size = 2000, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'mecab')\n",
    "pprint(d2v_model.most_similar('문재인/NNP'))\n",
    "pprint(d2v_model.most_similar('노무현/NNP'))\n",
    "pprint(d2v_model.most_similar('박근혜/NNP'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test\n",
    "del d2v_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
