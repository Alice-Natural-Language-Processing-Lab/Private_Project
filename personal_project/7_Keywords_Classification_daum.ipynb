{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import html\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.cluster import KMeans, k_means_, DBSCAN, AgglomerativeClustering\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import hdbscan\n",
    "from gensim import models\n",
    "from gensim.corpora import mmcorpus, Dictionary\n",
    "from gensim.models import lsimodel, ldamodel, tfidfmodel, rpmodel, logentropy_model, TfidfModel, LsiModel, LdaModel\n",
    "from gensim import matutils, corpora\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import doc2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sys\n",
    "sys.path.append('~/Documents/GitHub/Private_Project/personal_project/')\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import chat_bot as cb\n",
    "import Database_Handler as dh\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import functools\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "mecab = Mecab()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722\n"
     ]
    }
   ],
   "source": [
    "dataDict = pickle.load(open('./data/pre_data/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "print (len(dataDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsDict = pickle.load(open('./data/pre_data/keywords_daum.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dataDict:\n",
    "    dataDict[idx]['extracted_keywords'] = keywordsDict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4722, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a2a61bf588c13481c229d1e</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>1093</td>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>\"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소</td>\n",
       "      <td>주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...</td>\n",
       "      <td>[부작용, 비아그라, 아일랜드]</td>\n",
       "      <td>{건강, 부작용, 세보 효과, 지역, 공장, 남성들, 연기}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a2a61bf588c13481c229d1f</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헬스조선</td>\n",
       "      <td>603</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지</td>\n",
       "      <td>점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...</td>\n",
       "      <td>[커피, 낮잠, 음식물]</td>\n",
       "      <td>{건강, 점심 식사, 철분, 자세, 입냄새, 커피, 디스크, 식후, 치아, 낮잠}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a2a61bf588c13481c229d20</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1067</td>\n",
       "      <td>811</td>\n",
       "      <td>3</td>\n",
       "      <td>'십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"</td>\n",
       "      <td>(성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...</td>\n",
       "      <td>[살인혐의, 철원, 검찰송치]</td>\n",
       "      <td>{앙심, 남편, 성관계, 진술, 경찰, 아들, 범행, 주변, 철원, 지인}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a2a61bf588c13481c229d21</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>신영자, 억 소리나는 갑질</td>\n",
       "      <td>신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...</td>\n",
       "      <td>[신영자, 갑질, 롯데백화점]</td>\n",
       "      <td>{유통업체, 롯데, 매장, 네이처리퍼블릭, 검찰, 신영자 이사장, 혐의, 징역}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a2a61bf588c13481c229d22</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>434</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>\"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지</td>\n",
       "      <td>(청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...</td>\n",
       "      <td>[공범, 살인, 과자]</td>\n",
       "      <td>{쪽지, 경찰, 폭행, 유치장, 과자, 남자친구, 범행, 혐의}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id category        date  press  number_of_comment  \\\n",
       "0  5a2a61bf588c13481c229d1e       뉴스  2017-12-07   세계일보               1093   \n",
       "1  5a2a61bf588c13481c229d1f       뉴스  2017-12-07   헬스조선                603   \n",
       "2  5a2a61bf588c13481c229d20       뉴스  2017-12-07   연합뉴스               1067   \n",
       "3  5a2a61bf588c13481c229d21       뉴스  2017-12-07  헤럴드경제                418   \n",
       "4  5a2a61bf588c13481c229d22       뉴스  2017-12-07   연합뉴스                434   \n",
       "\n",
       "   number_of_crawled_comment rank                                title  \\\n",
       "0                        911    1     \"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소   \n",
       "1                        386    2  식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지   \n",
       "2                        811    3  '십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"   \n",
       "3                        369    4                       신영자, 억 소리나는 갑질   \n",
       "4                        368    5   \"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지   \n",
       "\n",
       "                                            mainText           keywords  \\\n",
       "0   주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...  [부작용, 비아그라, 아일랜드]   \n",
       "1   점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...      [커피, 낮잠, 음식물]   \n",
       "2   (성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...   [살인혐의, 철원, 검찰송치]   \n",
       "3  신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...   [신영자, 갑질, 롯데백화점]   \n",
       "4  (청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...       [공범, 살인, 과자]   \n",
       "\n",
       "                              extracted_keywords  \n",
       "0              {건강, 부작용, 세보 효과, 지역, 공장, 남성들, 연기}  \n",
       "1  {건강, 점심 식사, 철분, 자세, 입냄새, 커피, 디스크, 식후, 치아, 낮잠}  \n",
       "2      {앙심, 남편, 성관계, 진술, 경찰, 아들, 범행, 주변, 철원, 지인}  \n",
       "3   {유통업체, 롯데, 매장, 네이처리퍼블릭, 검찰, 신영자 이사장, 혐의, 징역}  \n",
       "4            {쪽지, 경찰, 폭행, 유치장, 과자, 남자친구, 범행, 혐의}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daum = pd.DataFrame.from_dict(dataDict, orient='index')\n",
    "df_daum['date'] = pd.to_datetime(df_daum['date']).dt.date\n",
    "df_daum.reset_index(inplace = True)\n",
    "df_daum.rename(columns={'index':'id'}, inplace=True)\n",
    "print (df_daum.shape)\n",
    "df_daum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "textInfo = df_daum.title.values + df_daum.mainText.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nav_tokenizer(corpus):\n",
    "    pos = mecab.pos(corpus)\n",
    "    res = [x[0] for x in pos if (x[1] == u'VV' or x[1] == u'VA' or x[1] == u'NNB' or x[1] == u'NNP' or x[1] == u'NNG')]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words, stopwords):\n",
    "    res = [x for x in words if x not in stopwords]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_docs = [nav_tokenizer(x) for x in textInfo]\n",
    "d2v_docs = [remove_stopwords(x, (stopwords)) for x in d2v_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_d2v_docs = [TaggedDocument(doc, [idx]) for idx, doc in enumerate(d2v_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = doc2vec.Doc2Vec(size=500, window=5, alpha=0.025, min_alpha=0.025, seed=0)\n",
    "d2v_model.build_vocab(tagged_d2v_docs)\n",
    "d2v_model.train_lbls = False # do not train labels of words\n",
    "d2v_model.train_words = True # only train relations among words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(30):\n",
    "    d2v_model.train(tagged_d2v_docs, total_examples=len(d2v_docs), epochs=epoch)\n",
    "    d2v_model.alpha -= 0.002 # decrease the learning rate\n",
    "    d2v_model.min_alpha = d2v_model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d2v = [d2v_model.infer_vector(x.words) for x in tagged_d2v_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('text: 화성서 발견된 포탄 모양 둥근 물체, 정체는?(지디넷코리아=이정현 미디어연구소)화성에서 포탄처럼 생긴 둥근 모양의 물체가 '\n",
      " '발견됐다. 미국 항공우주국(NASA)은 6일(현지시간) 화성 탐사 로봇 큐리오시티 로버 공식 트위터 계정을 통해 화성에서 발견된 그란 '\n",
      " '모양의 물체 사진을 공개했다고 주요 외신들이 보도했다. 공개된 사진 속에는 먼지로 뒤덮인 화성의 지표면에 놓여있는 동그란 모양의 물체가 '\n",
      " '눈에 띈다. 마치 포탄처럼 보이기도 한다.  이 사진은 원래 올해 초 큐리오시티 로버가 촬영한 사진이지만 최근 한 UFO 학자의 블로그에 '\n",
      " '새롭게 게시돼 화제를 모았다. 이 사진을 올린 UFO 학자는 이 동그란 모양의 물체는 포탄처럼 생겼다며, 이는 화성에서 전쟁이 일어났던 '\n",
      " '증거라고 밝혔다. 하지만 NASA는 이 물체의 크기는 실제로 5mm 미만으로 황산칼슘, 나트륨 및 마그네슘으로 구성된 암석이라고 밝히며, '\n",
      " '이 학자의 이론은 틀렸다고 밝혔다. NASA는 화성에서 동그랗게 생긴 암석이 발견된 것은 이번이 처음이 아니라며, 2014년 공개됐던 '\n",
      " '사진도 함께 공개했다. 이 때 공개된 블루베리를 닮은 동그란 암석의 크기는 약 3cm 정도였다.  당시, 이 동그란 암석의 정체를 두고 '\n",
      " '화산 폭발설, 암석 내부에 수분이 결집되면서 생성된 것이라며 화성에 물이 있었다는 증거라는 의견, 운석이 충돌해 생긴 것이라는 설 등 '\n",
      " '다양한 주장이 제기되기도 했다. 이정현 미디어연구소(jh7253@zdnet.co.kr)')\n",
      "\n",
      "('샤이니 종현, 오늘(18일) 숨진 채 발견그룹 샤이니 종현(27)이 18일 숨진 채 발견됐다. 18일 관계자에 따르면 종현은 이날 오후 '\n",
      " '서울 청담동 한 오피스텔에서 숨진 채 발견됐다. 문완식 기자 munwansik@<저작권자 ⓒ ‘리얼타임 연예스포츠 속보,스타의 모든 것’ '\n",
      " '스타뉴스, 무단전재 및 재배포 금지> (0.944849)')\n",
      "'5년 만에 출근하는 이용마 MBC 기자[CBS노컷뉴스 이한형 기자] goodlh2@cbs.co.kr (0.925952)'\n",
      "('제천 화재 현장 찾은 문 대통령(제천=연합뉴스) 배재만 기자 = 문재인 대통령이 22일 오후 29명의 사망자를 낸 충북 제천 스포츠센터 '\n",
      " '화재 참사 현장을 방문하고 있다. 2017.12.22 scoop@yna.co.kr (0.858716)')\n",
      "(\"이민아 '유니폼 벗고 여성미 물씬~' [MK포토][매경닷컴 MK스포츠(서울)=천정환 기자] 2017 대한축구협회 시상식이 19일 오후 \"\n",
      " '서울 서초구 반포동 세빛섬에서 개최됐다. 이민아가 시상식에 참석하고 있다. jh1000@maekyung.com (0.857575)')\n",
      "('문 대통령 내외와 인사하는 추자현 부부(베이징=연합뉴스) 김주형 기자 = 문재인 대통령과 부인 김정숙 여사가 13일 오후 중국 국빈방문 '\n",
      " '첫 일정으로 베이징 완다 소피텔 호텔에서 열린 재중국 한국인 오찬 간담회에 입장하며 추자현 부부와 인사하고 있다. 2017.12.13 '\n",
      " 'kjhpress@yna.co.kr (0.732779)')\n",
      "(\"'싸움닭' 조계현 수석코치, KIA 신임 단장 승진 [OSEN=이선호 기자] KIA타이거즈가 6일 신임 단장 인사를 단행했다. KIA는 \"\n",
      " '이날 조계현(53) 수석코치를 신임 단장으로 임명했다. 조계현 신임 단장은 군산상고-연세대를 졸업하고 프로 무대에 데뷔했으며, 선수와 '\n",
      " '지도자로 다양한 경험을 쌓았다. KIA 관계자는 “야구인 출신 단장 선임으로 전문성을 강화한 인사”라며 “풍부한 지도자 경력을 바탕으로 '\n",
      " '장기적 관점에서 팀을 운영해줄 것으로 기대한다”고 밝혔다. /sunny@osen.co.kr (0.728158)')\n",
      "('샤이니 종현, 청담동 레지던스서 쓰러진 채 발견[텐아시아=김하진 기자] 그룹 샤이니 종현이 쓰러진 채 발견돼 병원으로 옮겨졌다. 18일 '\n",
      " '한 매체에 따르면 종현은 이날 오후 6시께 서울 청담동 한 레지던스 방에서 쓰러진 채 발견됐다. 병원으로 이송됐으나 중태에 빠졌다고 '\n",
      " '전해졌다. 현재 소속사 SM엔터테인먼트는 연락을 받지 않고 있다. 김하진 기자 hahahajin@tenasia.co.kr '\n",
      " '(0.718465)')\n",
      "('경찰 \"샤이니 종현 숨진 채 발견..현장조사중\"그룹 샤이니 종현(27)이 18일 숨진 채 발견된 가운데 경찰이 조사를 진행 중이다. '\n",
      " '18일 관계자에 따르면 종현은 이날 오후 서울 청담동 한 오피스텔에서 숨진 채 발견됐다. 서울강남경찰서 관계자는 스타뉴스와 전화통화에서 '\n",
      " '\"종현이 강남 오피스텔에서 숨진 채 발견됐다\"며 \"현재 현장에서 경찰 조사가 진행 중이다\"라고 밝혔다. 윤상근 기자 '\n",
      " 'sgyoon@<저작권자 ⓒ ‘리얼타임 연예스포츠 속보,스타의 모든 것’ 스타뉴스, 무단전재 및 재배포 금지> (0.712387)')\n",
      "('\"MBC 뉴스 거듭나겠습니다\"[뉴스데스크] 저희 MBC는 신임 최승호 사장의 취임에 맞춰, 오늘(8일)부터 뉴스데스크 앵커를 교체하고 '\n",
      " '당분간 뉴스를 임시체제로 진행합니다. 저희들은 재정비 기간 동안 MBC 보도가 시청자 여러분께 남긴 상처들을 거듭 되새기며, 철저히 '\n",
      " '반성하는 시간을 갖겠습니다. 치밀한 준비를 거쳐 빠른 시일 안에 정확하고 겸손하고 따뜻한 뉴스데스크로 시청자 여러분께 다시 '\n",
      " '인사드리겠습니다. (0.696325)')\n",
      "('샤이니 종현, 숨진채 발견..경찰 \"조사중\" SM \"상황파악중\"그룹 샤이니 종현(27)이 18일 숨진 채 발견됐다. 18일 관계자에 '\n",
      " '따르면 종현은 이날 오후 서울 청담동 한 오피스텔에서 숨진 채 발견됐다. 119구급대가 심정지 상태의 종현을 병원으로 이송했으며, 이날 '\n",
      " '오후 7시 현재 경찰이 현장 조사를 진행 중이다. 서울강남경찰서 관계자는 스타뉴스와 전화통화에서 \"종현이 강남 오피스텔에서 숨진 채 '\n",
      " '발견됐다\"며 \"현재 현장에서 경찰 조사가 진행 중이다\"라고 밝혔다. 소속사 SM엔터테인먼트 관계자는 스타뉴스에 \"상황 파악 중\"이라고 '\n",
      " '밝혔다. 종현은 지난 2008년 그룹 샤이니 멤버로 가요계 데뷔했다. 문완식 기자 munwansik@<저작권자 ⓒ ‘리얼타임 연예스포츠 '\n",
      " '속보,스타의 모든 것’ 스타뉴스, 무단전재 및 재배포 금지> (0.689079)')\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "pprint('text: '+ textInfo[idx])\n",
    "print(\"\")\n",
    "for x in d2v_model.docvecs.most_similar(positive=[X_d2v[idx]]):\n",
    "    pprint(textInfo[x[0]] + ' (%3f)' % x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"text: 텍사스-마이너 계약 조건 공개.. '3년-2800만 달러' 최근 텍사스 레인저스와 자유계약(FA) 선수 자격을 얻은 왼손 투수 \"\n",
      " '마이크 마이너(30) 사이에 체결된 계약 조건이 공개됐다. 메이저리그 공식 홈페이지 MLB.com은 7일(이하 한국시각) 텍사스와 '\n",
      " '마이너의 계약은 3년-2800만 달러라고 전했다. 이는 연평균 933만 달러. 마이너가 선발 투수로 재기한다면, 적은 금액이다. 또한 '\n",
      " '선발 투수로 실패한 뒤 불펜 투수로 좋은 모습을 보인다면, 최상급의 대우다. 텍사스는 마이너를 구원 투수가 아닌 선발 투수로 기용할 '\n",
      " '전망이다. 이에 이번 시즌 구원으로 재기에 성공한 마이너가 다시 한 번 선발 투수로 거듭날 수 있을지 관심거리다. 마이너는 메이저리그 '\n",
      " '6년차의 왼손 투수. 지난 2014년 이후 어깨 수술로 두 시즌 동안 단 1경기에도 나서지 못했다. 이후 마이너는 이번 시즌 캔자스시티 '\n",
      " '소속으로 65경기에서 77 2/3이닝을 던지며, 6승 6패 17홀드 6세이브와 평균자책점 2.55 등을 기록했다. 부상이 없다면, 제 '\n",
      " '몫을 해줄 수 있는 투수. 지난 2013년에는 애틀란타 브레이브스 소속으로 200이닝을 넘게 던졌다. 텍사스는 마이너에게 2013시즌과 '\n",
      " '같은 모습을 기대할 것으로 보인다. 마이너의 두 번째 재기 여부가 주목된다. 동아닷컴 조성운 기자 madduxly@donga.com')\n",
      "\n",
      "('\"중국, 한국 단체관광 다시 금지?\"..문체부 \"사실 확인 중\"【서울=뉴시스】최동준 기자 = 4일 서울 명동 거리에서 외국인 관광객들이 '\n",
      " '관광을 하고 있다. 2017.12.04. photocdj@newsis.com 【서울=뉴시스】김정환 기자 = 중국 정부가 한국행 단체관광을 '\n",
      " '다시 금지했다는 20일 국내 일부 언론 보도에 대해 문화체육관광부, 한국관광공사 등 관계 기관은 조심스러운 반응을 보이고 있다. 이날 '\n",
      " '국내 일부 언론은 중국 베이징과 산둥 지역 국가여유국이 지난 19일(현지시간) 오후부터 한국 단체관광 출국 허가를 접수하지 않고 있다고 '\n",
      " '전했다. 중국 국가여유국은 지난 11월28일 베이징과 산둥 지역 여행사들에 한해 한국행 단체관광을 허용했다. 한국의 '\n",
      " '사드(고고도미사일방어체계·THAAD)와 관련해 앞서 5월 금지한 중국 단체관광을 제한적이나마 허용한 것이다. 여기에 최근 문재인 대통령이 '\n",
      " '중국 국빈 방문 기간 중국이 사드 보복을 사실상 철회하겠다고 밝혀 중국 단체관광 재개에 기대감이 고조했다. 이런 가운데 나온 보도여서 '\n",
      " '국내 관광 및 유통업계가 받는 충격은 더욱 크다. 이에 대해 문체부 한 관계자는 \"관련 보도를 접하고 현재 사실 확인 중이다\"고 전했다. '\n",
      " '관광공사 한 관계자 역시 \"아직 정확한 내막을 알 수 없어 파악 중이다\"고 말했다. 관광업계 고위 인사는 \"이번 조치가 중국 단체관광을 '\n",
      " '전체적으로 다시 금지한 것인지, 현지 일부 업체에 국한한 것인지는 아직 알 수 없다\"면서 \"중국 측이 앞서 한국 단체관광을 금지할 때도 '\n",
      " '구두로 여행사들에 지시한 것이었고, 허가할 때도 역시 구두로 허가한 것이어서 이번 조치의 사실 여부를 확인하는 데 적잖은 시간이 걸릴 '\n",
      " '듯하다\"고 귀띔했다. 이 인사는 \"당황스러운 소식임은 분명하지만, 사태가 정확히 드러날 때까지 성급한 판단을 자제했으면 한다. 오히려 '\n",
      " '중국 측을 자극할 수 있기 때문이다\"고 지적했다. ace@newsis.com (0.165115)')\n",
      "('샤이니 종현 비보..외신 \"최고의 가수 중 한 명\" 애도[스포츠투데이 박혜미 기자] 그룹 샤이니 종현의 갑작스러운 사망 소식에 일본 중국 '\n",
      " '등 아시아권 역시 충격에 빠졌다. 18일 중국 일본 인도네시아 베트남 등 외신은 샤이니 종현의 사망 소식을 긴급 보도했다. 이 매체들은 '\n",
      " '한국의 보도를 인용해 종현의 사망 소식을 속보로 전하고 있다. 샤이니가 한류 열풍을 이끌며 아시아권에서 활발한 활동을 펼쳐온 그룹이기에 '\n",
      " '이들 역시 큰 충격에 빠진 모습이다. 특히 일본은 각종 포털사이트 최상단에 종현 소식을 배치했다. 일본 대표 포털 중 하나인 라이브도어는 '\n",
      " '톱뉴스로 종현의 사망소식을 다루며 그의 사망 과정에 대해서 상세하게 전했다. 베트남 매체 ZING은 \"K POP 팬들을 기절시킨 '\n",
      " '장본인\"이라고 종현을 설명하며 \"2008년 샤이니 리드 싱어로 데뷔해 \\'SM의 골든보이\\'란 별명을 얻은 최고의 가수 중 한 명\"이라고 '\n",
      " '애도했다. 영어권 외신도 일제히 소식을 전했으며 그의 사망 소식에 국내 팬들은 물론 해외 팬들 역시 애도를 표하고 있다. 박혜미 기자 '\n",
      " 'ent@stoo.com (0.163692)')\n",
      "('샤이니 온유 성추행 논란 후 첫 심경고백 \"끝없이 자책\"(전문)  [뉴스엔 이민지 기자] 온유가 자필 사과문을 게재했다. 샤이니 온유는 '\n",
      " '12월 4일 오후 샤이니 공식 홈페이지에 \"온유입니다\"라는 제목으로 자필 사과문을 게재했다. 온유는 이 글에서 \"지난 4개월 동안 쉬면서 '\n",
      " '깊이 반성하고 돌아보게 됐고 스스로를 원망하고 자책했다\"며 \"더 철저하게 사적인 시간에도 책임감 있게 행동했어야 했는데 실망스러운 모습 '\n",
      " '보여드려 죄송한 마음 뿐\"이라고 사과했다. 또 \"앞으로 대외적인 일이든 개인적인 일이든 샤이니라는 팀의 이름에 걸맞는 사람이 될 수 '\n",
      " '있도록 정말 최선의 노력을 다할 것을 약속드린다\"고 전했다. 한편 온유는 지난 8월 서울 강남에 위치한 한 클럽에서 20대 여성의 신체 '\n",
      " '부위를 만진 혐의로 경찰 조사를 받았다. 당시 SM엔터테인먼트 측은 \"술에 취한 상태에서 춤을 추다가 주변 사람과 의도치 않게 신체 '\n",
      " '접촉이 발생하여 오해를 받아 경찰에서 조사를 받았다\"고 해명했다. 온유는 이후 촬영 중이던 JTBC 드라마 \\'청춘시대2\\'에서 '\n",
      " '하차했으며 활동을 전면 중단했다. 다음은 온유 자필 사과문 전문이다. 안녕하세요. 온유입니다. 저를 응원해주시고 사랑해주신 팬 여러분께 '\n",
      " '안 좋은 소식으로 실망시켜드려 진심으로 죄송합니다. 지난 4개월 동안 활동을 쉬면서 부족한 저를 아껴주신 팬 여러분께 얼마나 큰 실망을 '\n",
      " '드렸는지 깊이 반성하고 돌아보게 되었고 제 스스로를 끝없이 원망하고 자책하기도 했습니다. 어떻게 사과를 드려야 할지, 어떤 단어로 '\n",
      " '표현해야 좋을지 고민하고 또 고민했고, 죄송한 마음이 넘 커서 글을 쓰는 것 조차 조심스러웠기에 너무 늦었지만 이제서야 글을 올립니다. '\n",
      " '많이 사랑받고 주목을 받을수록 더 철저하게 사적인 시간에도 책임감 있게 행동했어야 했는데 실망스러운 모습 보여드려 죄송한 마음 뿐입니다. '\n",
      " '9년 넘는 시간동안 함께 열심히 달려온 우리 멤버들에게 정말 미안하고 저 때문에 놀라셨을 부모님과 회사 여러분들께도 이 글을 통해 다시 '\n",
      " '한번 죄송하다는 말씀 드리고 싶습니다. 늘 반성하며 제 자신을 더 엄격하게 관리하고 노력하겠습니다. 앞으로 대외적인 일이든 개인적인 '\n",
      " '일이든 SHNEE라는 팀의 이름에 걸맞는 사람이 될 수 있도록 정말 최선의 노력을 다할 것을 약속드립니다. 온유 올림 뉴스엔 이민지 '\n",
      " 'oing@ 기사제보 및 보도자료 newsen@newsen.com copyrightⓒ 뉴스엔. 무단전재 & 재배포 금지 (0.155895)')\n",
      "('[엑\\'s 현장] \"상주 넷 모였다\"..샤이니 키, 故 종현 빈소 도착[엑스포츠뉴스 전아람 기자] 샤이니 키가 故 종현의 빈소에 뒤늦게 '\n",
      " '도착했다. 19일 서울 송파구에 위치한 서울아산병원 장례식장 2층 20호실에는 종현의 유족, 친지들이 참석한 가운데 조문이 시작됐다. '\n",
      " '상주에는 샤이니 김기범(키), 이진기(온유), 최민호(민호), 이태민(태민)이 이름을 올려 고인의 마지막을 함께 지킨다. 샤이니 온유, '\n",
      " '민호, 태민은 이날 일찌감치 빈소를 찾아 10년이 넘는 기간동안 가족처럼 지낸 故 종현의 곁을 지키며 상주 역할을 했다. 키는 지난 '\n",
      " '17일 화보 촬영을 위해 포르투갈 리스본으로 출국한 탓에 급히 귀국했다. 갑작스러운 비보를 접하고 일정을 중단한 채 바로 한국으로 돌아온 '\n",
      " '키는 귀국하자마자 빈소를 찾아 상주 자리를 함께 했다. 이날 오후 늦게 도착한 키의 합류로 비로소 샤이니 멤버 모두가 故 종현의 마지막 '\n",
      " '길을 배웅할 수 있었다.  故 종현은 지난 18일 서울 청담동의 한 레지던스에서 쓰러진 채 발견, 인근 대학병원으로 이송됐지만 사망 '\n",
      " '판정을 받았다. 소속사 SM 엔터테인먼트 측은 \"유가족들의 뜻에 따라 장례는 가족 친지들과 회사 동료들이 참석하여 최대한 조용하게 치를 '\n",
      " '예정\"이라고 밝혔다. 빈소는 서울아산병원에 마련됐으며 유가족의 뜻에 따라 지하 1층 3호실에는 팬들을 위한 별도 조문 공간이 자리했다. '\n",
      " '발인은 오는 21일 오전 9시. kindbelle@xportsnews.com / 사진=사진공동취재단, 엑스포츠뉴스DB (0.151227)')\n",
      "('고은미, 둘째 출산 \"건강하게 태어나줘서 고마워, 최고의 선물\"[엑스포츠뉴스 김유진 기자] 배우 고은미가 둘째를 출산했다. 고은미는 '\n",
      " '24일 자신의 인스타그램에 갓 태어난 둘째의 발 사진과 함께 \"건강하게 태어나줘서 고마워 아가. 넌 크리스마스 최고의 선물이구나\"라는 '\n",
      " '글을 게재하며 출산 소식을 전했다. 또 고은미는 \"비록 이 엄마는 생사를 넘나들었지만 네가 건강하니 그걸로 됐다. \\'이런 일이 나에게도 '\n",
      " '생기는구나\\' 했지만 고난이 유익이라. 고난은 인생의 참 의미를 알게 하고. 이렇게 감사한 새해를 맞이 할 수 있게 됐다\"고 둘째를 품에 '\n",
      " \"안은 소감을 전했다. 고은미는 지난 11월 24일 종영한 MBC 일일드라마 '돌아온 복단지'에 출연했다. 지난 2015년 8살 연상의 \"\n",
      " '사업가와 결혼해 지난해 5월 첫 딸을 낳았으며, 올해 12월 둘째까지 품에 안으면서 두 아이의 엄마가 됐다. '\n",
      " 'slowlife@xportsnews.com / 사진 = 엑스포츠뉴스DB, 고은미 인스타그램 (0.145931)')\n",
      "('[Oh!쎈 톡] \\'효리네민박2\\', 신청 벌써 15만건 돌파..PD \"사랑 감사\" [OSEN=강서정 기자] ‘효리네 민박’ 시즌2가 '\n",
      " '오픈 전부터 ‘핫’하다. 벌써 신청 건수가 15만건이 넘었다. JTBC는 ‘효리네 민박’ 시즌2 제작을 확정지었다. ‘효리네 민박’은 '\n",
      " '이효리와 남편인 가수 이상순이 출연하는 리얼리티 예능프로그램으로 실제로 제주도에서 거주하고 있는 두 사람이 현지에서 민박집의 호스트 '\n",
      " '역할을 하며 손님을 맞이한다. 시즌1에서 이효리, 이상순 부부와 직원 아이유가 민박객들과 함께 소통하고 제주도에서 살아가는 모습이 '\n",
      " '시청자들에게 힐링을 선사하며 호응을 얻었다. 이 예능은 올해 JTBC 역대 예능프로그램 최고시청률을 기록하기도. 시즌1 종영 후 '\n",
      " '시청자들의 시즌2 요청이 이어졌고 제작진은 가을 내내 이효리, 이상순 부부와 지속적으로 깊은 논의를 나눠 왔다. 그 결과 제주의 겨울을 '\n",
      " '담은 시즌2를 제작하기로 결정하고 민박 예약 신청을 받기 시작했다. ‘효리네 민박’ 제작진은 지난 8일 시즌2 공식 홈페이지를 오픈하고 '\n",
      " '민박 신청을 받았다. 시즌2 제작 소식이 전해지자마자 포털사이트 실시간 검색어 1위를 한 것은 물론 민박 신청도 쏟아졌다. ‘효리네 '\n",
      " '민박’은 지난 8일 오전부터 민박 신청을 받았는데 4일이 지난 오늘(12일) 신청 건수가 무려 15만 건을 돌파했고, 계속해서 네티즌들의 '\n",
      " '신청 사연이 이어지고 있다. ‘효리네 민박’의 정효민 PD는 OSEN에 “많은 관심을 가져줘서 감사하다. 시즌1에서 많은 분들이 '\n",
      " '프로그램을 사랑해줬다는 걸 알기 때문에 감사한 마음이다”며 “신청자들의 사연을 읽어보고 ‘효리네 민박’ 민박객들을 선정할 계획이다”고 '\n",
      " '전했다. 한편 ‘효리네 민박’은 내년 1월 촬영을 시작할 예정이다. /kangsj@osen.co.kr [사진] JTBC 제공 '\n",
      " '(0.145517)')\n",
      "('\"스타벅스에서 컵라면 후루룩\".. 도넘은 \\'외부음식\\'서울 중구의 한 PC방에 \\'외부음료 반입금지\\'라는 표지판이 붙어 '\n",
      " '있다./사진=남형도 기자  #지난 10일 한 온라인 커뮤니티에는 경기 남양주에 위치한 스타벅스에서 컵라면을 먹는 손님을 봤다는 게시글이 '\n",
      " '올라왔다. 게시자는 \"스타벅스는 외부음식 반입이 가능한 것으로 아는데, 그래도 컵라면을 먹어도 되느냐\"며 \"냄새는 많이 안나는 것 '\n",
      " '같았다\"고 말했다. 이와 관련, 누리꾼들은 \"스타벅스에서 햄버거·피자·떡볶이를 먹는 손님도 봤다\"는 목격담을 덧붙이며 \"매너가 없는 것 '\n",
      " '같다\"고 비판했다. 카페·음식점에서 파는 음식이 아닌 \\'외부음식\\'을 가져와 먹는 손님이 여전히 많아 자영업자들이 골치를 앓고 있는 '\n",
      " '것으로 나타났다. 영업에 지장을 주는 데다 치우는 것도 주인 몫이고 다른 손님들에 피해까지 끼칠 때가 많아서다. 하지만 이를 매번 '\n",
      " '적발하기 힘들고 마땅히 제지할 방법도 없어 손님 스스로 매너를 지켜야한다는 지적이 나온다. 28일 오후 서울 중구 일대의 '\n",
      " '음식점·패스트푸드점·카페·PC방 등을 살펴본 결과 외부음식을 가져와 먹는 손님이 다수 발견됐다. 카페에서는 대부분 외부 음료나 케이크를 '\n",
      " '가져와 먹거나, 삼각김밥 등을 먹는 경우도 발견됐다. 패스트푸드점에서도 편의점 도시락 등을 먹는 손님이 있었고, PC방에서는 커피 등 '\n",
      " \"외부음료나 라면을 먹는 사례를 찾을 수 있었다. 이들이 발견된 카페·음식점 입구에는 '외부음식 금지'라는 표시가 붙어 있기도 했다. 이를 \"\n",
      " '운영하는 사장이나 관리하는 아르바이트생들의 외부음식 목격 사례는 더했다. 샌드위치 전문점 관계자 A씨는 \"케이크를 제일 많이 사오고 '\n",
      " '베이커리에서 빵을 사오거나 핫도그를 먹으면서 냄새를 풍기는 경우도 봤다\"며 \"더이상 제재할 수 없는 지경\"이라고 푸념했다. 프랜차이즈 '\n",
      " '카페 관계자 B씨도 \"케이크를 가져와서 생일파티를 하는 경우가 많고 초밥 같은 음식을 사와서 먹는 것도 봤다\"고 말했다. 또 프랜차이즈 '\n",
      " '분식집 관계자 C씨는 \"햄버거를 사와서 아이에게 먹이거나 편의점 도시락 같은 것을 사와서 같이 먹는 경우가 대다수\"라고 밝혔다. 한 '\n",
      " '스타벅스 매장. 스타벅스는 기본적으로 외부음식 반입이 제한돼 있지만, 향이 나지 않는 음식에 대해서는 대체로 허용한다고 '\n",
      " '밝혔다./사진=뉴스1  앞서 사례로 든 스타벅스의 경우도 원칙적으로는 외부음식을 제한하고 있다. 스타벅스 관계자는 \"외부음식을 기본적으로 '\n",
      " '제한하지만 햄버거 등 향이 강한 음식이 아니면 파트너(직원)가 별다르게 제재하지 않는 것일 뿐\"이라고 말했다. 또 다른 관계자는 '\n",
      " '\"김밥이나 떡볶이를 먹는 경우가 다수 발견됐다\"며 \"다 함께 이용하는 매장이니 자제를 부탁 드린다\"고 당부했다. 자영업자들은 외부음식 '\n",
      " '반입으로 인한 피해가 크다고 호소했다. 카페사장 D씨는 \"매장에서 케이크나 음료를 파는데 다른데서 사와서 버젓이 먹는 것을 보면 혈압이 '\n",
      " '오른다\"며 \"임대료·전기세 등을 내며 장소를 제공하는 것인데 자선사업을 하는 것도 아니지 않느냐\"고 비판했다. 외부음료만 제한하고 있는 '\n",
      " 'PC방 사장 E씨는 \"더러 외부음료를 가지고 들어와서 키보드에 흘리거나 하면 처리하기도 골치아픈데, 우격다짐으로 가지고 들어가는 경우도 '\n",
      " '있다\"며 \"술집에 술을 가져가고, 음식점에 가서 싸간 것 먹겠다고 하면 아무래도 불쾌하지 않겠느냐\"고 토로했다. 레스토랑 사장 '\n",
      " 'F씨(42)는 \"외부음식을 일일이 감시하기도 힘들고 손님들 스스로 매너를 지켜줬으면 좋겠다\"고 말했다. 반면 손님들 중에서는 매장에서 '\n",
      " '음식을 사먹을 경우 외부음식을 반입시켜줘야 한다는 의견도 있었다. 직장인 G씨(31)는 \"한 번은 술집에 가서 술·안주를 많이 시킨 '\n",
      " '다음에 친구 생일파티 때문에 케이크를 꺼냈는데, 외부음식이라며 막아서 불쾌했다\"며 \"많이 팔아주는데 어느 정도는 허용해줘야 하는 게 '\n",
      " '아닌가 싶었다\"고 말했다. 한편 외부음식을 적극 허용해 매출을 더 많이 올리는 사례도 있었다. 강서구에 위치한 H횟집의 경우 술은 물론 '\n",
      " '다른 안주까지 가져와서 회와 함께 먹을 수 있다. 해당 횟집 단골인 직장인 I씨(37)는 \"술과 안주를 사가서 먹을 수 있으니 항상 '\n",
      " '손님이 바글바글하다\"며 \"외부음식 허용이라는 역발상 전략이 잘 통한 사례 같다\"고 말했다. 남형도 기자 human@mt.co.kr '\n",
      " '(0.145095)')\n",
      "('[Oh!쎈 초점] \"라면도 쉽쥬?\"..백종원, \\'강식당\\' 최고 시청률 숨은 조력자영상 바로보기 [OSEN=김나희 기자] \\'강식당\\' '\n",
      " '백종원이 제주도에 깜짝 방문해 시선을 모았다. 특히 강호동과 멤버들은 갑작스러운 백종원의 등장에 안절부절못하는 모습을 보여 폭소를 '\n",
      " \"유발했다. 지난 20일 방송된 tvN 예능 '신서유기 외전 강식당'(이하 강식당) 3회에서는 영업 이틀째를 맞이하는 멤버들의 모습이 \"\n",
      " '전파를 탔다. 이날 멤버들은 만반의 준비를 한 채 손님들을 맞이했다. 하지만 예상치 못한 변수가 발생했으니, 어린이용으로 만든 수근이 '\n",
      " '가스의 인기와 준비하지 않고 있던 포장 요청 때문이었다. 여기에 수프가 다 떨어진 데다 \"고기가 다 안 익었다\"는 컴플레인까지 들어온 '\n",
      " '상황. \\'멘붕\\'에 빠진 멤버들은 \"미워하지 말아요\", \"당황하지 말아요\"를 외치면서도 때때로 격한 반응을 보여 웃음을 선사했다. '\n",
      " '그래도 어느 정도 주방과 홀이 정리되던 찰나, 백종원이 깜짝 방문해 모두를 긴장시켰다. 강호동과 안재현의 요리사부인 백종원은 처음엔 '\n",
      " '무게를 잡았지만 이들의 음식을 맛보고 칭찬을 해줘 훈훈함을 안겼다. 특히 백종원은 떠나기 전 강호동에게 신메뉴 레시피를 알려줘 눈길을 '\n",
      " \"끌었다. 이를 맛본 멤버들은 감탄을 금치 못했고 탕수육과 라면을 결합시킨 이 신메뉴에 '제주 많은 돼지 라면'이라는 이름을 붙여줬다. \"\n",
      " \"그리고 드디어 영업 3일째를 맞이한 '강식당'. 이날 송민호와 이수근은 위치를 바꿔 각각 주방과 홀에서 일을 시작했다. 하지만 이날도 \"\n",
      " '멤버들은 밥이 되지 않은 위기에 처해 다음화를 궁금하게 만들었다. 이날 백종원은 바쁜 스케줄이 있음에도 제주도까지 방문해 제자들의 음식를 '\n",
      " \"맛보는 정성으로 긴장감과 웃음, 감동을 동시에 안겼다. 그의 존재만으로도 '강식당' 멤버들의 집중력이 달라졌기 때문. '신서유기4' \"\n",
      " \"멤버들 고유의 케미스트리와 그의 숨은 조력이 더해져 이날 방송된 '강식당'은 평균 6.9%, 최고 7.8%를 기록, 전 시즌 자체 최고 \"\n",
      " '시청률(이하 닐슨코리아 유료플랫폼가구 전국기준)을 경신했다. 남녀 2049세 타깃시청률 역시 평균 5.6%, 최고 6.2%를 기록하며 '\n",
      " \"지상파 포함 동시간대 1위를 달성했고 말이다. 그동안 '신서유기' 시리즈가 높은 화제성에 비해 낮은 시청률을 기록했던 점을 감안하면 \"\n",
      " \"'강식당'의 이러한 성과가 더욱 뜻깊게 다가오고 있는 상황. 무엇보다 백종원이 신메뉴를 개발해준 '강식당'의 활약은 아직 더 남아있기에, \"\n",
      " \"이들이 또 어떤 '멘붕'으로 웃음을 선사할지 많은 기대가 모아지고 있다. / nahee@osen.co.kr [사진] '강식당' 방송화면 \"\n",
      " '캡처 (0.145077)')\n",
      "('김구라 \"故 종현, 30~40대가 더 멋지겠다 생각했는데\"영상 바로보기 [뉴스엔 이민지 기자] 김구라가 고 종현의 소식에 안타까워했다. '\n",
      " \"12월 26일 방송된 SBS '본격연예 한밤'에서 샤이니 멤버 고(故) 종현의 발인 현장을 공개했다. 고 종현은 최근 청담동 한 \"\n",
      " '레지던스에서 쓰러진 채 발견됐고 세상을 떠났다. 2008년 샤이니로 데뷔한 종현은 국내는 물론 해외에서도 큰 사랑을 받은 스타다. 빛나는 '\n",
      " '아이돌로 재능있는 뮤지션으로 큰 사랑을 받았던 종현의 비보에 많은 사람들이 안타까워하고 있다. 김구라는 \"저 친구는 30대, 40대가 더 '\n",
      " '멋지겠구나 생각했데 빨리가서 마음이 아프다\"고 안타까움을 드러냈다. (사진=SBS \\'본격연예 한밤\\' 캡처) 뉴스엔 이민지 oing@ '\n",
      " '기사제보 및 보도자료 newsen@newsen.com copyrightⓒ 뉴스엔. 무단전재 & 재배포 금지 (0.144053)')\n",
      "(\"[포토엔HD] 방탄 키워낸, 방시혁 '대통령표창 받고 뿌듯한 미소' [뉴스엔 윤다희 기자] 제9회 ‘2017 대한민국 콘텐츠 \"\n",
      " '대상(Korea Content Awards 2017)’이 12월 5일 오후 서울 강남구 삼성동 코엑스 컨퍼런스룸에서 진행됐다. 이날 '\n",
      " '빅히트엔터테인먼트 방시혁 대표가 대통령표창을 수상했다. 뉴스엔 윤다희 dahee@ 기사제보 및 보도자료 newsen@newsen.com '\n",
      " 'copyrightⓒ 뉴스엔. 무단전재 & 재배포 금지 (0.143975)')\n"
     ]
    }
   ],
   "source": [
    "idx = 121\n",
    "pprint('text: '+ textInfo[idx])\n",
    "print(\"\")\n",
    "for x in d2v_model.docvecs.most_similar(positive=[X_d2v[idx]]):\n",
    "    pprint(textInfo[x[0]] + ' (%3f)' % x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.cluster import k_means_ \n",
    "\n",
    "def euc2cos_distance(X, Y=None, Y_norm_squared=None, squared=False):\n",
    "    return cosine_distances(X,Y)\n",
    "\n",
    "k_means_.euclidean_distances = euc2cos_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.656\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=cnum, init='k-means++', max_iter=300, n_init=20, tol=0.0001)\n",
    "km.fit(X_d2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_d2v, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label0: 3326\n",
      "label1: 18\n",
      "label2: 4\n",
      "label3: 26\n",
      "label4: 202\n",
      "label5: 1\n",
      "label6: 2\n",
      "label7: 141\n",
      "label8: 3\n",
      "label9: 47\n",
      "label10: 2\n",
      "label11: 52\n",
      "label12: 33\n",
      "label13: 78\n",
      "label14: 37\n",
      "label15: 1\n",
      "label16: 2\n",
      "label17: 46\n",
      "label18: 1\n",
      "label19: 1\n",
      "label20: 1\n",
      "label21: 1\n",
      "label22: 2\n",
      "label23: 58\n",
      "label24: 2\n",
      "label25: 1\n",
      "label26: 39\n",
      "label27: 1\n",
      "label28: 1\n",
      "label29: 1\n",
      "label30: 51\n",
      "label31: 1\n",
      "label32: 1\n",
      "label33: 1\n",
      "label34: 1\n",
      "label35: 29\n",
      "label36: 1\n",
      "label37: 1\n",
      "label38: 1\n",
      "label39: 2\n",
      "label40: 16\n",
      "label41: 29\n",
      "label42: 402\n",
      "label43: 1\n",
      "label44: 1\n",
      "label45: 3\n",
      "label46: 2\n",
      "label47: 47\n",
      "label48: 1\n",
      "label49: 1\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(textInfo, columns=['text'])\n",
    "dfRes['label'] = km.labels_\n",
    "\n",
    "for i in range(cnum):\n",
    "    print('label{}: {}'.format(i, len(dfRes[dfRes.label == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top keywords\n",
    "def print_topwords(df, num, bar):\n",
    "    try:\n",
    "        temp_cor = df.text.values\n",
    "        temp_vec = TfidfVectorizer(tokenizer=nav_tokenizer, stop_words=stopwords + mask1)\n",
    "\n",
    "        temp_vec.fit(temp_cor)\n",
    "\n",
    "        temp = pd.DataFrame(list(temp_vec.vocabulary_.keys()), columns=['word'])\n",
    "        temp['idx'] = temp_vec.vocabulary_.values()\n",
    "        temp.sort_values(by='idx', inplace=True)\n",
    "        temp['count'] = temp_vec.transform(temp_cor).toarray().sum(axis=0)\n",
    "\n",
    "        topwords = temp.sort_values(['count'], ascending=False)[:num]    \n",
    "    \n",
    "        for i in range(num):\n",
    "            print(topwords['word'].values[i]),\n",
    "\n",
    "        if bar == True:\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.bar(range(num), topwords['count'].values, align='center')\n",
    "            plt.xticks([x for x in range(num)], topwords['word'].values)\n",
    "            ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "cluster 9:\n",
      "\n",
      "cluster 10:\n",
      "\n",
      "cluster 11:\n",
      "\n",
      "cluster 12:\n",
      "\n",
      "cluster 13:\n",
      "\n",
      "cluster 14:\n",
      "\n",
      "cluster 15:\n",
      "\n",
      "cluster 16:\n",
      "\n",
      "cluster 17:\n",
      "\n",
      "cluster 18:\n",
      "\n",
      "cluster 19:\n",
      "\n",
      "cluster 20:\n",
      "\n",
      "cluster 21:\n",
      "\n",
      "cluster 22:\n",
      "\n",
      "cluster 23:\n",
      "\n",
      "cluster 24:\n",
      "\n",
      "cluster 25:\n",
      "\n",
      "cluster 26:\n",
      "\n",
      "cluster 27:\n",
      "\n",
      "cluster 28:\n",
      "\n",
      "cluster 29:\n",
      "\n",
      "cluster 30:\n",
      "\n",
      "cluster 31:\n",
      "\n",
      "cluster 32:\n",
      "\n",
      "cluster 33:\n",
      "\n",
      "cluster 34:\n",
      "\n",
      "cluster 35:\n",
      "\n",
      "cluster 36:\n",
      "\n",
      "cluster 37:\n",
      "\n",
      "cluster 38:\n",
      "\n",
      "cluster 39:\n",
      "\n",
      "cluster 40:\n",
      "\n",
      "cluster 41:\n",
      "\n",
      "cluster 42:\n",
      "\n",
      "cluster 43:\n",
      "\n",
      "cluster 44:\n",
      "\n",
      "cluster 45:\n",
      "\n",
      "cluster 46:\n",
      "\n",
      "cluster 47:\n",
      "\n",
      "cluster 48:\n",
      "\n",
      "cluster 49:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: -0.356\n"
     ]
    }
   ],
   "source": [
    "cnum = 50\n",
    "agg = AgglomerativeClustering(n_clusters=cnum, affinity='cosine', linkage='complete')\n",
    "agg.fit(X_d2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_d2v, agg.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 81\n",
      "label 1: 66\n",
      "label 2: 55\n",
      "label 3: 66\n",
      "label 4: 54\n",
      "label 5: 78\n",
      "label 6: 69\n",
      "label 7: 64\n",
      "label 8: 64\n",
      "label 9: 51\n",
      "label 10: 70\n",
      "label 11: 62\n",
      "label 12: 51\n",
      "label 13: 49\n",
      "label 14: 54\n",
      "label 15: 60\n",
      "label 16: 81\n",
      "label 17: 60\n",
      "label 18: 56\n",
      "label 19: 42\n",
      "label 20: 44\n",
      "label 21: 52\n",
      "label 22: 50\n",
      "label 23: 54\n",
      "label 24: 47\n",
      "label 25: 65\n",
      "label 26: 34\n",
      "label 27: 51\n",
      "label 28: 49\n",
      "label 29: 55\n",
      "label 30: 47\n",
      "label 31: 52\n",
      "label 32: 39\n",
      "label 33: 34\n",
      "label 34: 38\n",
      "label 35: 2243\n",
      "label 36: 56\n",
      "label 37: 36\n",
      "label 38: 71\n",
      "label 39: 38\n",
      "label 40: 41\n",
      "label 41: 35\n",
      "label 42: 33\n",
      "label 43: 31\n",
      "label 44: 31\n",
      "label 45: 38\n",
      "label 46: 28\n",
      "label 47: 33\n",
      "label 48: 33\n",
      "label 49: 31\n"
     ]
    }
   ],
   "source": [
    "dfRes = pd.DataFrame(textInfo, columns=['text'])\n",
    "dfRes['label'] = agg.labels_\n",
    "for i in range(len(dfRes.label.unique())):\n",
    "    print('label {}: {}'.format(i, len(dfRes.loc[dfRes['label'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "cluster 9:\n",
      "\n",
      "cluster 10:\n",
      "\n",
      "cluster 11:\n",
      "\n",
      "cluster 12:\n",
      "\n",
      "cluster 13:\n",
      "\n",
      "cluster 14:\n",
      "\n",
      "cluster 15:\n",
      "\n",
      "cluster 16:\n",
      "\n",
      "cluster 17:\n",
      "\n",
      "cluster 18:\n",
      "\n",
      "cluster 19:\n",
      "\n",
      "cluster 20:\n",
      "\n",
      "cluster 21:\n",
      "\n",
      "cluster 22:\n",
      "\n",
      "cluster 23:\n",
      "\n",
      "cluster 24:\n",
      "\n",
      "cluster 25:\n",
      "\n",
      "cluster 26:\n",
      "\n",
      "cluster 27:\n",
      "\n",
      "cluster 28:\n",
      "\n",
      "cluster 29:\n",
      "\n",
      "cluster 30:\n",
      "\n",
      "cluster 31:\n",
      "\n",
      "cluster 32:\n",
      "\n",
      "cluster 33:\n",
      "\n",
      "cluster 34:\n",
      "\n",
      "cluster 35:\n",
      "\n",
      "cluster 36:\n",
      "\n",
      "cluster 37:\n",
      "\n",
      "cluster 38:\n",
      "\n",
      "cluster 39:\n",
      "\n",
      "cluster 40:\n",
      "\n",
      "cluster 41:\n",
      "\n",
      "cluster 42:\n",
      "\n",
      "cluster 43:\n",
      "\n",
      "cluster 44:\n",
      "\n",
      "cluster 45:\n",
      "\n",
      "cluster 46:\n",
      "\n",
      "cluster 47:\n",
      "\n",
      "cluster 48:\n",
      "\n",
      "cluster 49:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=10, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.1, min_samples=10, algorithm='brute', metric='cosine')\n",
    "Y = db.fit_predict(X_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 1\n",
      "Silhouette Coefficient: 0.564\n"
     ]
    }
   ],
   "source": [
    "# Number of clusters in labels, ignoring noise if present.\n",
    "cnum = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % cnum)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_d2v, db.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfRes = pd.DataFrame(textInfo, columns=['text'])\n",
    "dfRes['label'] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label -1: 3514\n",
      "label 0: 1208\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfRes.label.unique())):\n",
    "    if i == 0 :\n",
    "        print('label -1: {}'.format(len(dfRes.loc[dfRes['label'] == i-1])))\n",
    "    else:\n",
    "        print('label {}: {}'.format(i-1, len(dfRes.loc[dfRes['label'] == i-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster -1:\n",
      "\n",
      "cluster 0:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1, cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_docs = [nav_tokenizer(x) for x in textInfo]\n",
    "lda_docs = [remove_stopwords(x, stopwords) for x in lda_docs]\n",
    "lda_dict = corpora.Dictionary(lda_docs)\n",
    "#calulate TF-IDF\n",
    "tf_ps = [lda_dict.doc2bow(x) for x in lda_docs]\n",
    "tf_model = models.TfidfModel(tf_ps)\n",
    "X_lda = tf_model[tf_ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.007*\"경찰\" + 0.007*\"데얀\" + 0.006*\"야산\" + 0.006*\"아파트\" + 0.005*\"전주\" + '\n",
      "  '0.004*\"강정호\" + 0.004*\"주민\"'),\n",
      " (1,\n",
      "  '0.012*\"박나래\" + 0.012*\"전현무\" + 0.011*\"기안84\" + 0.007*\"투표\" + 0.005*\"이경규\" + '\n",
      "  '0.004*\"한혜진\" + 0.004*\"낚시\"'),\n",
      " (2,\n",
      "  '0.005*\"연금\" + 0.004*\"캐나다\" + 0.002*\"청년\" + 0.002*\"김현수\" + 0.002*\"박용택\" + '\n",
      "  '0.002*\"당원\" + 0.002*\"골프\"'),\n",
      " (3,\n",
      "  '0.005*\"김영철\" + 0.003*\"자유한국당\" + 0.003*\"마녀\" + 0.003*\"홍\" + 0.003*\"의원\" + '\n",
      "  '0.003*\"정려원\" + 0.003*\"홍준표\"'),\n",
      " (4,\n",
      "  '0.004*\"김지원\" + 0.001*\"다희\" + 0.001*\"북구\" + 0.001*\"뇌출혈\" + 0.001*\"중부\" + '\n",
      "  '0.001*\"미터\" + 0.001*\"임정우\"'),\n",
      " (5,\n",
      "  '0.006*\"강호동\" + 0.005*\"한화\" + 0.005*\"코치\" + 0.005*\"강식당\" + 0.005*\"추자현\" + '\n",
      "  '0.004*\"우효광\" + 0.003*\"백종원\"'),\n",
      " (6,\n",
      "  '0.007*\"열애설\" + 0.005*\"자니윤\" + 0.004*\"베일\" + 0.003*\"원투펀치\" + 0.003*\"이서진\" + '\n",
      "  '0.003*\"아구에로\" + 0.003*\"엄정화\"'),\n",
      " (7,\n",
      "  '0.015*\"손흥민\" + 0.014*\"케인\" + 0.009*\"골\" + 0.008*\"토트넘\" + 0.007*\"시티\" + '\n",
      "  '0.005*\"프리미어리그\" + 0.004*\"맨시티\"'),\n",
      " (8,\n",
      "  '0.003*\"흑기사\" + 0.003*\"전인지\" + 0.003*\"정관용\" + 0.003*\"교회\" + 0.002*\"신세경\" + '\n",
      "  '0.002*\"담합\" + 0.002*\"발화\"'),\n",
      " (9,\n",
      "  '0.010*\"제천\" + 0.004*\"문수호\" + 0.003*\"독감\" + 0.003*\"로빈\" + 0.002*\"롯데시네마\" + '\n",
      "  '0.002*\"자백\" + 0.002*\"샤론\"'),\n",
      " (10,\n",
      "  '0.004*\"이승기\" + 0.004*\"가요대축제\" + 0.003*\"크레인\" + 0.003*\"집사부일체\" + 0.002*\"버스\" + '\n",
      "  '0.002*\"송중기\" + 0.002*\"모란시장\"'),\n",
      " (11,\n",
      "  '0.009*\"최우수상\" + 0.006*\"마고메도프\" + 0.004*\"김연아\" + 0.004*\"하빕\" + 0.003*\"전지현\" + '\n",
      "  '0.003*\"평창\" + 0.003*\"무라타\"'),\n",
      " (12,\n",
      "  '0.005*\"고모\" + 0.004*\"포수\" + 0.003*\"박종철\" + 0.003*\"니퍼트\" + 0.003*\"두산\" + '\n",
      "  '0.003*\"열사\" + 0.002*\"김윤석\"'),\n",
      " (13,\n",
      "  '0.004*\"조인성\" + 0.003*\"손호준\" + 0.002*\"수지\" + 0.002*\"장신영\" + 0.002*\"시어러\" + '\n",
      "  '0.002*\"앨런\" + 0.002*\"충재\"'),\n",
      " (14,\n",
      "  '0.003*\"프랑스\" + 0.003*\"하차\" + 0.002*\"피겨\" + 0.002*\"리원\" + 0.002*\"야식\" + 0.002*\"브\" '\n",
      "  '+ 0.002*\"스캇\"'),\n",
      " (15,\n",
      "  '0.014*\"종현\" + 0.007*\"우수상\" + 0.004*\"이상윤\" + 0.003*\"육성재\" + 0.003*\"샤이니\" + '\n",
      "  '0.003*\"집사부일체\" + 0.003*\"외국인\"'),\n",
      " (16,\n",
      "  '0.003*\"이정후\" + 0.003*\"스완슨\" + 0.003*\"입양\" + 0.002*\"정성훈\" + 0.002*\"한혜진\" + '\n",
      "  '0.002*\"유원상\" + 0.002*\"채태인\"'),\n",
      " (17,\n",
      "  '0.003*\"홍보대사\" + 0.003*\"조직위\" + 0.002*\"박용택\" + 0.002*\"SK텔레콤\" + 0.002*\"한희\" + '\n",
      "  '0.002*\"알바생\" + 0.001*\"이병규\"'),\n",
      " (18,\n",
      "  '0.028*\"희\" + 0.007*\"샤론\" + 0.007*\"윤정수\" + 0.004*\"문수호\" + 0.003*\"맥그리거\" + '\n",
      "  '0.003*\"방어\" + 0.003*\"송선미\"'),\n",
      " (19,\n",
      "  '0.004*\"커쇼\" + 0.004*\"송년\" + 0.004*\"다방\" + 0.003*\"양육\" + 0.002*\"사우디\" + '\n",
      "  '0.002*\"복당\" + 0.002*\"박원숙\"'),\n",
      " (20,\n",
      "  '0.008*\"계약\" + 0.007*\"오승환\" + 0.007*\"이준\" + 0.006*\"홈런\" + 0.005*\"한화\" + '\n",
      "  '0.005*\"선수\" + 0.005*\"타율\"'),\n",
      " (21,\n",
      "  '0.008*\"추신수\" + 0.005*\"텍사스\" + 0.004*\"신동엽\" + 0.003*\"이상우\" + 0.002*\"선박\" + '\n",
      "  '0.002*\"노회찬\" + 0.002*\"미니시리즈\"'),\n",
      " (22,\n",
      "  '0.006*\"태양\" + 0.006*\"무관\" + 0.003*\"지디\" + 0.002*\"적설\" + 0.002*\"르브론\" + '\n",
      "  '0.002*\"이승우\" + 0.002*\"백스윙\"'),\n",
      " (23,\n",
      "  '0.007*\"지드래곤\" + 0.004*\"미키타리안\" + 0.004*\"화재\" + 0.004*\"지섭\" + 0.003*\"양\" + '\n",
      "  '0.003*\"포그바\" + 0.003*\"빅뱅\"'),\n",
      " (24,\n",
      "  '0.005*\"신인상\" + 0.002*\"공로상\" + 0.002*\"기태영\" + 0.002*\"소방차\" + 0.002*\"분위\" + '\n",
      "  '0.002*\"여진구\" + 0.002*\"절단\"'),\n",
      " (25,\n",
      "  '0.005*\"이청용\" + 0.002*\"진선규\" + 0.002*\"할릴호지치\" + 0.002*\"새해\" + 0.002*\"김구라\" + '\n",
      "  '0.002*\"팰리스\" + 0.002*\"신성우\"'),\n",
      " (26,\n",
      "  '0.008*\"양\" + 0.005*\"커플\" + 0.005*\"이상민\" + 0.004*\"맨유\" + 0.004*\"내연녀\" + '\n",
      "  '0.004*\"다저스\" + 0.003*\"결혼\"'),\n",
      " (27,\n",
      "  '0.008*\"대상\" + 0.005*\"경찰\" + 0.004*\"친부\" + 0.004*\"상\" + 0.004*\"수상\" + 0.004*\"전화\" '\n",
      "  '+ 0.003*\"어머니\"'),\n",
      " (28,\n",
      "  '0.003*\"번리\" + 0.003*\"이치로\" + 0.002*\"노부부\" + 0.002*\"미씽\" + 0.002*\"실감\" + '\n",
      "  '0.002*\"생계형\" + 0.001*\"알베르토\"'),\n",
      " (29,\n",
      "  '0.013*\"고준희\" + 0.004*\"김승회\" + 0.004*\"양\" + 0.004*\"최재훈\" + 0.003*\"친모\" + '\n",
      "  '0.002*\"연휴\" + 0.002*\"헬멧\"'),\n",
      " (30,\n",
      "  '0.006*\"월드컵\" + 0.005*\"감독\" + 0.005*\"한국\" + 0.005*\"일본\" + 0.004*\"베스트\" + '\n",
      "  '0.004*\"축구\" + 0.004*\"윤균상\"'),\n",
      " (31,\n",
      "  '0.007*\"한현민\" + 0.005*\"배달\" + 0.004*\"강동원\" + 0.003*\"경리\" + 0.002*\"김정\" + '\n",
      "  '0.002*\"수형자\" + 0.002*\"유엔\"'),\n",
      " (32,\n",
      "  '0.003*\"포항\" + 0.003*\"무리뉴\" + 0.003*\"영하\" + 0.003*\"폭행\" + 0.003*\"유승민\" + '\n",
      "  '0.002*\"지지율\" + 0.002*\"마이웨이\"'),\n",
      " (33,\n",
      "  '0.010*\"실종\" + 0.008*\"다스\" + 0.005*\"얀\" + 0.003*\"특검\" + 0.002*\"독대\" + 0.002*\"월화극\" '\n",
      "  '+ 0.001*\"한끼\"'),\n",
      " (34,\n",
      "  '0.010*\"방송연예대상\" + 0.009*\"유재석\" + 0.007*\"무한도전\" + 0.005*\"김성령\" + 0.004*\"오상진\" + '\n",
      "  '0.003*\"세리\" + 0.003*\"장군\"'),\n",
      " (35,\n",
      "  '0.009*\"이주연\" + 0.008*\"김현수\" + 0.006*\"황금빛\" + 0.004*\"천호진\" + 0.004*\"박시후\" + '\n",
      "  '0.004*\"선수\" + 0.003*\"인생\"'),\n",
      " (36,\n",
      "  '0.007*\"화재\" + 0.005*\"미운우리새끼\" + 0.004*\"건물\" + 0.004*\"층\" + 0.004*\"불\" + '\n",
      "  '0.003*\"소방대원\" + 0.003*\"소방당국\"'),\n",
      " (37,\n",
      "  '0.008*\"정당\" + 0.007*\"통합\" + 0.007*\"국민의당\" + 0.006*\"안철수\" + 0.005*\"의원\" + '\n",
      "  '0.005*\"부문\" + 0.005*\"준호\"'),\n",
      " (38,\n",
      "  '0.006*\"정소민\" + 0.005*\"가르시아\" + 0.005*\"역적\" + 0.004*\"장나라\" + 0.004*\"투수\" + '\n",
      "  '0.003*\"연기\" + 0.003*\"이승우\"'),\n",
      " (39,\n",
      "  '0.011*\"연예대상\" + 0.003*\"가나\" + 0.003*\"슈퍼맨\" + 0.002*\"토니안\" + 0.002*\"화상\" + '\n",
      "  '0.002*\"재신임\" + 0.002*\"미우새\"'),\n",
      " (40,\n",
      "  '0.005*\"유시민\" + 0.003*\"특집\" + 0.003*\"남매\" + 0.003*\"학교\" + 0.003*\"데이비스\" + '\n",
      "  '0.002*\"장동선\" + 0.002*\"노홍철\"'),\n",
      " (41,\n",
      "  '0.004*\"애플\" + 0.003*\"최두호\" + 0.003*\"노르웨이\" + 0.002*\"아이폰\" + 0.002*\"스승\" + '\n",
      "  '0.002*\"크로캅\" + 0.002*\"김지민\"'),\n",
      " (42,\n",
      "  '0.005*\"화유기\" + 0.004*\"스완지\" + 0.003*\"이적료\" + 0.003*\"바르\" + 0.003*\"박준우\" + '\n",
      "  '0.002*\"사고\" + 0.002*\"제작\"'),\n",
      " (43,\n",
      "  '0.009*\"지성\" + 0.008*\"이보영\" + 0.004*\"뉴스데스크\" + 0.003*\"박지선\" + 0.003*\"귓속말\" + '\n",
      "  '0.003*\"공단\" + 0.003*\"빈소\"'),\n",
      " (44,\n",
      "  '0.010*\"호날두\" + 0.006*\"레알\" + 0.004*\"카르바할\" + 0.004*\"마드리드\" + 0.004*\"바르셀로나\" + '\n",
      "  '0.004*\"메시\" + 0.003*\"홈\"'),\n",
      " (45,\n",
      "  '0.003*\"채두\" + 0.003*\"미쓰에이\" + 0.002*\"종이\" + 0.002*\"유리창\" + 0.002*\"셰프\" + '\n",
      "  '0.002*\"경찰\" + 0.002*\"생일\"'),\n",
      " (46,\n",
      "  '0.004*\"하정우\" + 0.004*\"애틀랜타\" + 0.004*\"사면\" + 0.004*\"영화\" + 0.003*\"새해\" + '\n",
      "  '0.003*\"전당대회\" + 0.003*\"화재\"'),\n",
      " (47,\n",
      "  '0.006*\"연기\" + 0.005*\"박정진\" + 0.005*\"영화\" + 0.004*\"한국당\" + 0.004*\"배우\" + '\n",
      "  '0.003*\"의원\" + 0.003*\"드라마\"'),\n",
      " (48,\n",
      "  '0.021*\"양현종\" + 0.004*\"계약\" + 0.003*\"단장\" + 0.003*\"니퍼트\" + 0.003*\"감사\" + '\n",
      "  '0.003*\"타이거즈\" + 0.002*\"스태프\"'),\n",
      " (49,\n",
      "  '0.005*\"대통령\" + 0.004*\"시장\" + 0.004*\"정부\" + 0.003*\"김주찬\" + 0.003*\"청와대\" + '\n",
      "  '0.003*\"의혹\" + 0.003*\"스키장\"')]\n"
     ]
    }
   ],
   "source": [
    "# train topic model\n",
    "ntopics = 50\n",
    "nwords = 7\n",
    "\n",
    "np.random.seed(1)\n",
    "lda_model = models.ldamodel.LdaModel(X_lda, id2word=lda_dict, num_topics=ntopics)\n",
    "pprint(lda_model.print_topics(num_topics=ntopics, num_words=nwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'탈의실 몰카' 혐의 전현직 국가대표 수영선수 5명 전원 무죄 (수원=뉴스1) 최대호 기자 = 여자 수영선수 탈의실에 몰래 카메라를 \"\n",
      " '설치해 촬영한 혐의로 재판에 넘겨진 전·현직 국가대표 수영선수 5명이 모두 무죄를 선고 받았다. 범죄의 증명이 부족하다는 이유에서다. '\n",
      " '이들을 기소한 검찰은 판결문 검토 후 항소여부를 결정한다는 방침이다. 수원지법 형사9단독 반정모 판사는 7일 성폭력 범죄의 처벌 및 '\n",
      " '피해자보호 등에 관한 법률 위반(카메라 등 이용촬영) 혐의로 불구속 기소된 A씨(24)와 B씨(25) 등 전·현직 국가대표 수영선수 '\n",
      " '5명에 대해 무죄를 선고했다. A씨는 2009~2013년 경기지역 한 체고 수영장 여자 탈의실과 충북의 한 선수촌 여자 수영선수 탈의에 '\n",
      " '만년필 형태의 몰래 카메라를 놓아두고 6차례에 걸쳐 선수들의 탈의 장면을 촬영한 혐의로 기소됐다. B씨 등 4명은 A씨의 몰래 카메라 '\n",
      " '설치를 돕거나 망을 보는 등 범행에 가담한 혐의로 기소됐다. 반 판사는 \"피고인 A씨는 B씨 등 4명의 피고인이 자신의 범행에 가담했다고 '\n",
      " '진술하나 B씨 등 4명 모두 일관되게 혐의를 부인하고 있다\"며 \"당시 여러가지 처한 상황을 볼때 B씨 등이 A씨 범행에 가담할 이유가 '\n",
      " '없었던 것으로 판단된다\"고 판시했다. 이어 \"검사는 A씨의 진술에 기초해 B씨 등 4명을 기소했는데 유죄를 인정하려면 그 인과관계가 '\n",
      " '합리적인 의심의 여지가 없을 정도로 증명이 돼야 하는 데 그렇지 못하다\"며 무죄를 선고했다. 반 판사는 A씨에 대해서도 \"피고인은 자신이 '\n",
      " '범행했다고 진술하고 있지만 그를 입증할 다른 증언 등 보강증거가 없어 이 역시 범죄의 증명이 없는 경우에 해당한다\"며 B씨 등과 '\n",
      " '마찬가지로 무죄를 선고했다. 이와 관련 검찰 관계자는 \"판결문에 적시된 무죄 이유를 검토한 뒤 항소여부를 결정하겠다\"고 말했다. '\n",
      " 'sun0701@')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = 11\n",
    "pprint(textInfo[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 0.69215721), (34, 0.013114556), (47, 0.16727021), (48, 0.010923133)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[X_lda[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4722, 50)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_vec = np.zeros((len(textInfo), ntopics))\n",
    "lda_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: value array of shape (7,) could not be broadcast to indexing result of shape (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7c10f500194d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_lda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlda_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: value array of shape (7,) could not be broadcast to indexing result of shape (8,)"
     ]
    }
   ],
   "source": [
    "for i in range(len(lda_vec)):\n",
    "    idx = [x[0] for x in lda_model[X_lda[i]]]\n",
    "    prob = [x[1] for x in lda_model[X_lda[i]]]\n",
    "    lda_vec[i][idx] = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise small number to calculate cosine distances\n",
    "lda_vec = lda_vec + 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l2v = np.hstack((X_d2v, lda_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=cnum, init='k-means++', max_iter=300, n_init=20, tol=0.0001)\n",
    "km.fit(X_l2v)\n",
    "print(\"Silhouette Coefficient: %0.3f\" % silhouette_score(X_l2v, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRes = pd.DataFrame(textInfo, columns=['text'])\n",
    "dfRes['label'] = km.labels_\n",
    "\n",
    "for i in range(cnum):\n",
    "    print('label{}: {}'.format(i, len(dfRes[dfRes.label == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cnum):\n",
    "    print('cluster {}:'.format(i)),\n",
    "    print_topwords(df=dfRes.loc[dfRes['label'] == i], num=5, bar=False)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
