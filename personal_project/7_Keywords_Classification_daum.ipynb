{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import html\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.cluster import KMeans, k_means_, DBSCAN, AgglomerativeClustering\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import hdbscan\n",
    "from gensim import models\n",
    "from gensim.corpora import mmcorpus, Dictionary\n",
    "from gensim.models import lsimodel, ldamodel, tfidfmodel, rpmodel, logentropy_model, TfidfModel, LsiModel, LdaModel\n",
    "from gensim import matutils, corpora\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import doc2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sys\n",
    "sys.path.append('~/Documents/GitHub/Private_Project/personal_project/')\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import chat_bot as cb\n",
    "import Database_Handler as dh\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import functools\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "mecab = Mecab()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722\n"
     ]
    }
   ],
   "source": [
    "dataDict = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "print (len(dataDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordsDict = pickle.load(open('./data/pre_data/keywords/keywords_daum.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dataDict:\n",
    "    dataDict[idx]['extracted_keywords'] = keywordsDict[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4722, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a2a61bf588c13481c229d1e</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>1093</td>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>\"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소</td>\n",
       "      <td>주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...</td>\n",
       "      <td>[부작용, 비아그라, 아일랜드]</td>\n",
       "      <td>{공장, 세보 효과, 남성들, 지역, 건강, 연기, 부작용}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a2a61bf588c13481c229d1f</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헬스조선</td>\n",
       "      <td>603</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지</td>\n",
       "      <td>점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...</td>\n",
       "      <td>[커피, 낮잠, 음식물]</td>\n",
       "      <td>{철분, 입냄새, 커피, 낮잠, 자세, 디스크, 건강, 점심 식사, 식후, 치아}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a2a61bf588c13481c229d20</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1067</td>\n",
       "      <td>811</td>\n",
       "      <td>3</td>\n",
       "      <td>'십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"</td>\n",
       "      <td>(성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...</td>\n",
       "      <td>[살인혐의, 철원, 검찰송치]</td>\n",
       "      <td>{진술, 범행, 아들, 성관계, 앙심, 철원, 남편, 주변, 지인, 경찰}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a2a61bf588c13481c229d21</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>신영자, 억 소리나는 갑질</td>\n",
       "      <td>신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...</td>\n",
       "      <td>[신영자, 갑질, 롯데백화점]</td>\n",
       "      <td>{롯데, 징역, 검찰, 네이처리퍼블릭, 유통업체, 매장, 신영자 이사장, 혐의}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a2a61bf588c13481c229d22</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017-12-07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>434</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>\"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지</td>\n",
       "      <td>(청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...</td>\n",
       "      <td>[공범, 살인, 과자]</td>\n",
       "      <td>{남자친구, 범행, 유치장, 폭행, 쪽지, 혐의, 경찰, 과자}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id category        date  press  number_of_comment  \\\n",
       "0  5a2a61bf588c13481c229d1e       뉴스  2017-12-07   세계일보               1093   \n",
       "1  5a2a61bf588c13481c229d1f       뉴스  2017-12-07   헬스조선                603   \n",
       "2  5a2a61bf588c13481c229d20       뉴스  2017-12-07   연합뉴스               1067   \n",
       "3  5a2a61bf588c13481c229d21       뉴스  2017-12-07  헤럴드경제                418   \n",
       "4  5a2a61bf588c13481c229d22       뉴스  2017-12-07   연합뉴스                434   \n",
       "\n",
       "   number_of_crawled_comment rank                                title  \\\n",
       "0                        911    1     \"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소   \n",
       "1                        386    2  식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지   \n",
       "2                        811    3  '십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"   \n",
       "3                        369    4                       신영자, 억 소리나는 갑질   \n",
       "4                        368    5   \"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지   \n",
       "\n",
       "                                            mainText           keywords  \\\n",
       "0   주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...  [부작용, 비아그라, 아일랜드]   \n",
       "1   점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...      [커피, 낮잠, 음식물]   \n",
       "2   (성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...   [살인혐의, 철원, 검찰송치]   \n",
       "3  신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...   [신영자, 갑질, 롯데백화점]   \n",
       "4  (청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...       [공범, 살인, 과자]   \n",
       "\n",
       "                              extracted_keywords  \n",
       "0              {공장, 세보 효과, 남성들, 지역, 건강, 연기, 부작용}  \n",
       "1  {철분, 입냄새, 커피, 낮잠, 자세, 디스크, 건강, 점심 식사, 식후, 치아}  \n",
       "2      {진술, 범행, 아들, 성관계, 앙심, 철원, 남편, 주변, 지인, 경찰}  \n",
       "3   {롯데, 징역, 검찰, 네이처리퍼블릭, 유통업체, 매장, 신영자 이사장, 혐의}  \n",
       "4            {남자친구, 범행, 유치장, 폭행, 쪽지, 혐의, 경찰, 과자}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daum = pd.DataFrame.from_dict(dataDict, orient='index')\n",
    "df_daum['date'] = pd.to_datetime(df_daum['date']).dt.date\n",
    "df_daum.reset_index(inplace = True)\n",
    "df_daum.rename(columns={'index':'id'}, inplace=True)\n",
    "print (df_daum.shape)\n",
    "df_daum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nav_tokenizer(corpus):\n",
    "    pos = mecab.pos(corpus)\n",
    "    res = [x[0] for x in pos if (x[1] == u'VV' or x[1] == u'VA' or x[1] == u'NNB' or x[1] == u'NNP' or x[1] == u'NNG')]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words, stopwords):\n",
    "    res = [x for x in words if x not in stopwords]\n",
    "    res = [x for x in words if len(x) != 1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4722/4722 [01:35<00:00, 49.46it/s]\n"
     ]
    }
   ],
   "source": [
    "w2v_docs = list()\n",
    "for idx in tqdm(df_daum.index):\n",
    "    text = df_daum.loc[idx,'title']+'.\\n'+df_daum.loc[idx,'mainText']\n",
    "    pos = nav_tokenizer(text)\n",
    "    pos = remove_stopwords(pos, stopwords)\n",
    "    label = df_daum.loc[idx, 'category']\n",
    "    w2v_docs.append(TaggedDocument(pos, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(w2v_docs, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [ x.words for x in train] \n",
    "y_train = [ x.tags for x in train] \n",
    "x_test = [ x.words for x in test] \n",
    "y_test = [ x.tags for x in test] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4249/4249 [00:00<00:00, 6341.86it/s]\n",
      "100%|██████████| 4249/4249 [00:44<00:00, 94.77it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15310518"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(sg=1, size=3000,window=8, workers = 6, iter = 20)\n",
    "w2v_model.build_vocab(tqdm(x_train))\n",
    "w2v_model.train(tqdm(x_train), total_examples=w2v_model.corpus_count, epochs=w2v_model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('박시후', 0.7483072280883789), ('황금빛', 0.6838359832763672), ('내인생', 0.6692831516265869), ('서은수', 0.640835165977478), ('셰어하우스', 0.6082226037979126), ('나영희', 0.6053473353385925), ('재벌가', 0.6002784967422485), ('소현경', 0.5949802398681641), ('황금빛내인생', 0.5904324054718018), ('서지안', 0.582492470741272)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('신혜선'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('토트넘', 0.639374852180481), ('스토크시티', 0.5924640893936157), ('왓퍼드', 0.59075927734375), ('득점포', 0.5882641077041626), ('델레', 0.5849654674530029), ('사우스햄턴', 0.5846250057220459), ('에릭센', 0.5837652683258057), ('브라이튼', 0.579013466835022), ('마우리시오', 0.5676306486129761), ('유럽챔피언스리그', 0.5655679106712341)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('손흥민'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('이다인', 0.6932629942893982), ('빅픽처', 0.67424476146698), ('김형석', 0.666618824005127), ('나영희', 0.6655270457267761), ('재벌남', 0.6579344272613525), ('셰어하우스', 0.6488503813743591), ('내인생', 0.6413261890411377), ('소현경', 0.6400668621063232), ('이진', 0.6392889022827148), ('서은수', 0.6356393694877625)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('황금빛내인생'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('언론장악', 0.4950806498527527), ('반정부', 0.47899162769317627), ('박근혜정부', 0.4744024872779846), ('탈원전', 0.4701486825942993), ('김태효', 0.4650428891181946), ('박근혜', 0.46187707781791687), ('실소유주', 0.4520929157733917), ('정호영', 0.4490810036659241), ('노종면', 0.44388866424560547), ('정무수석', 0.44284212589263916)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('이명박'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('대통령', 0.48957154154777527), ('조원진', 0.4687511920928955), ('문재', 0.46677735447883606), ('조찬', 0.45316943526268005), ('대한애국당', 0.44852203130722046), ('국빈방문', 0.44844523072242737), ('방중', 0.4449848532676697), ('외교부장', 0.42320626974105835), ('케어', 0.4218031167984009), ('정책실장', 0.4030939042568207)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('문재인'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('김영삼', 0.6032348871231079), ('김대중', 0.564887523651123), ('이회창', 0.544792115688324), ('서거', 0.5171603560447693), ('박연차', 0.5082685947418213), ('장준하', 0.5071714520454407), ('안희정', 0.5023866891860962), ('현철', 0.500705361366272), ('박사모', 0.4894034266471863), ('문희상', 0.48821043968200684)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('노무현'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('탄핵', 0.5290473699569702), ('이명박', 0.4618770480155945), ('최순실', 0.456400990486145), ('탄핵심판', 0.44233542680740356), ('정권', 0.4398067593574524), ('박근혜정부', 0.43897557258605957), ('비선실세', 0.43826571106910706), ('지국장', 0.43732163310050964), ('친박', 0.4350965917110443), ('안봉근', 0.4348442554473877)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('박근혜'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아주대병원', 0.8215057253837585), ('중증외상센터', 0.7649655938148499), ('귀순병', 0.6857060194015503), ('아주대', 0.6851359605789185), ('오청', 0.6824158430099487), ('문종환', 0.6522502303123474), ('총상', 0.6439065933227539), ('권준식', 0.63106369972229), ('외상센터', 0.625391960144043), ('공동경비구역', 0.6198679208755493)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.most_similar('이국종'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 7479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "print ('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform(x_train)\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print ('vocab size :', len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += w2v_model[word].reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "4249it [00:28, 151.44it/s]\n",
      "473it [00:03, 155.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "train_vecs_w2v = np.concatenate([buildWordVector(z, 3000) for z in tqdm(map(lambda x: x, x_train))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, 3000) for z in tqdm(map(lambda x: x, x_test))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('./model/word2vec_category_size3000_window8_iter20_by_mecab.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('./model/word2vec_category_size3000_window8_iter20_by_mecab.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['뉴스', '스포츠', '연예'], dtype='<U3')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y_train)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: -4.6609e+00 - acc: 0.6451\n",
      "Epoch 2/100\n",
      " - 1s - loss: -4.9325e+00 - acc: 0.6620\n",
      "Epoch 3/100\n",
      " - 1s - loss: -4.9893e+00 - acc: 0.6667\n",
      "Epoch 4/100\n",
      " - 1s - loss: -5.0262e+00 - acc: 0.6700\n",
      "Epoch 5/100\n",
      " - 1s - loss: -5.0477e+00 - acc: 0.6712\n",
      "Epoch 6/100\n",
      " - 1s - loss: -5.0535e+00 - acc: 0.6733\n",
      "Epoch 7/100\n",
      " - 1s - loss: -5.0508e+00 - acc: 0.6740\n",
      "Epoch 8/100\n",
      " - 1s - loss: -5.0659e+00 - acc: 0.6745\n",
      "Epoch 9/100\n",
      " - 1s - loss: -5.0751e+00 - acc: 0.6747\n",
      "Epoch 10/100\n",
      " - 1s - loss: -5.0746e+00 - acc: 0.6750\n",
      "Epoch 11/100\n",
      " - 1s - loss: -5.0800e+00 - acc: 0.6752\n",
      "Epoch 12/100\n",
      " - 1s - loss: -5.0784e+00 - acc: 0.6755\n",
      "Epoch 13/100\n",
      " - 1s - loss: -5.0794e+00 - acc: 0.6752\n",
      "Epoch 14/100\n",
      " - 1s - loss: -5.0871e+00 - acc: 0.6762\n",
      "Epoch 15/100\n",
      " - 1s - loss: -5.0873e+00 - acc: 0.6759\n",
      "Epoch 16/100\n",
      " - 0s - loss: -5.0785e+00 - acc: 0.6759\n",
      "Epoch 17/100\n",
      " - 1s - loss: -5.0844e+00 - acc: 0.6757\n",
      "Epoch 18/100\n",
      " - 1s - loss: -5.0847e+00 - acc: 0.6757\n",
      "Epoch 19/100\n",
      " - 1s - loss: -5.0858e+00 - acc: 0.6757\n",
      "Epoch 20/100\n",
      " - 1s - loss: -5.0828e+00 - acc: 0.6759\n",
      "Epoch 21/100\n",
      " - 1s - loss: -5.0831e+00 - acc: 0.6759\n",
      "Epoch 22/100\n",
      " - 1s - loss: -5.0872e+00 - acc: 0.6759\n",
      "Epoch 23/100\n",
      " - 1s - loss: -5.0859e+00 - acc: 0.6759\n",
      "Epoch 24/100\n",
      " - 1s - loss: -5.0866e+00 - acc: 0.6759\n",
      "Epoch 25/100\n",
      " - 1s - loss: -5.0865e+00 - acc: 0.6759\n",
      "Epoch 26/100\n",
      " - 0s - loss: -5.0862e+00 - acc: 0.6759\n",
      "Epoch 27/100\n",
      " - 1s - loss: -5.0835e+00 - acc: 0.6757\n",
      "Epoch 28/100\n",
      " - 1s - loss: -5.0886e+00 - acc: 0.6759\n",
      "Epoch 29/100\n",
      " - 1s - loss: -5.0821e+00 - acc: 0.6757\n",
      "Epoch 30/100\n",
      " - 1s - loss: -5.0881e+00 - acc: 0.6762\n",
      "Epoch 31/100\n",
      " - 1s - loss: -5.0861e+00 - acc: 0.6759\n",
      "Epoch 32/100\n",
      " - 1s - loss: -5.0875e+00 - acc: 0.6759\n",
      "Epoch 33/100\n",
      " - 1s - loss: -5.0872e+00 - acc: 0.6759\n",
      "Epoch 34/100\n",
      " - 1s - loss: -5.0876e+00 - acc: 0.6759\n",
      "Epoch 35/100\n",
      " - 1s - loss: -5.0881e+00 - acc: 0.6759\n",
      "Epoch 36/100\n",
      " - 0s - loss: -5.0876e+00 - acc: 0.6762\n",
      "Epoch 37/100\n",
      " - 1s - loss: -5.0868e+00 - acc: 0.6759\n",
      "Epoch 38/100\n",
      " - 1s - loss: -5.0857e+00 - acc: 0.6759\n",
      "Epoch 39/100\n",
      " - 1s - loss: -5.0876e+00 - acc: 0.6759\n",
      "Epoch 40/100\n",
      " - 1s - loss: -5.0857e+00 - acc: 0.6759\n",
      "Epoch 41/100\n",
      " - 0s - loss: -5.0891e+00 - acc: 0.6759\n",
      "Epoch 42/100\n",
      " - 1s - loss: -5.0861e+00 - acc: 0.6759\n",
      "Epoch 43/100\n",
      " - 1s - loss: -5.0903e+00 - acc: 0.6762\n",
      "Epoch 44/100\n",
      " - 1s - loss: -5.0884e+00 - acc: 0.6759\n",
      "Epoch 45/100\n",
      " - 1s - loss: -5.0869e+00 - acc: 0.6759\n",
      "Epoch 46/100\n",
      " - 1s - loss: -5.0905e+00 - acc: 0.6762\n",
      "Epoch 47/100\n",
      " - 1s - loss: -5.0882e+00 - acc: 0.6759\n",
      "Epoch 48/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 49/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 50/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 51/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 52/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 53/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 54/100\n",
      " - 1s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 55/100\n",
      " - 0s - loss: -5.0914e+00 - acc: 0.6762\n",
      "Epoch 56/100\n",
      " - 0s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 57/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 58/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 59/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 60/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 61/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 62/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 63/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 64/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 65/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 66/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 67/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 68/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 69/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 70/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 71/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 72/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 73/100\n",
      " - 0s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 74/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 75/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 76/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 77/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 78/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 79/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 80/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 81/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 82/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 83/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 84/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 85/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 86/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 87/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 88/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 89/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 90/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 91/100\n",
      " - 0s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 92/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 93/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 94/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 95/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 96/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 97/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 98/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 99/100\n",
      " - 0s - loss: -5.0915e+00 - acc: 0.6762\n",
      "Epoch 100/100\n",
      " - 1s - loss: -5.0915e+00 - acc: 0.6762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18314e6def0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Embedding, embeddings, merge\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=3000))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vecs_w2v, le.transform(y_train), epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646934460131865\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_vecs_w2v, le.transform(y_test), verbose=2)\n",
    "print (score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
