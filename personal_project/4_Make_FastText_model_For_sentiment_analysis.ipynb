{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText model\n",
    "> * 페이스북에서 개발한 단어 임베딩 기술  \n",
    "> * 구글에서 개발한 fastText을 기본으로 하되 부분단어들을 Embedding하는 기법.  \n",
    "> * 단어가 가지는 형태 정보를 학습할 수 있어, 다양한 접사가 존재하는 한국어같은 언어에 대해서 잘 동작  \n",
    "> * The main principle behind fastText is that the morphological structure of a word carries important information about the meaning of the word, which is not taken into account by traditional word embeddings, which train a unique word embedding for every individual word. This is especially significant for morphologically rich languages (German, Turkish) in which a single word can have a large number of morphological forms, each of which might occur rarely, thus making it hard to train good word embeddings.\n",
    "> * fastText attempts to solve this by treating each word as the aggregation of its subwords. For the sake of simplicity and language-independence, subwords are taken to be the character ngrams of the word. The vector for a word is simply taken to be the sum of all vectors of its component char-ngrams.\n",
    "> * According to a detailed comparison of fastText and FastText in this notebook, fastText does significantly better on syntactic tasks as compared to the original fastText, especially when the size of the training corpus is small. fastText slightly outperforms FastText on semantic tasks though. The differences grow smaller as the size of training corpus increases. Training time for fastText is significantly higher than the Gensim version of word2vec (15min 42s vs 6min 42s on text8, 17 mil tokens, 5 epochs, and a vector size of 100).\n",
    "> * fastText can be used to obtain vectors for out-of-vocabulary (OOV) words, by summing up vectors for its component char-ngrams, provided at least one of the char-ngrams was present in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText model 생성을 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "def Make_FastText_Model(data, size, epoch, sg, window, min_count, cbow_mean,\n",
    "                        workers, negative,word_ngrams, hs, tagger):\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas(desc=\"progress-bar\")\n",
    "    from datetime import datetime\n",
    "    from gensim.models import FastText\n",
    "    start = datetime.now()\n",
    "    modelPath = './model/'\n",
    "    modelName = 'fastText_size-{}_epoch-{}_ngrams-{}_window-{}_negative-{}_hs-{}_sg-{}_cbow_mean-{}_min_count-{}_by-{}.model'.format(\n",
    "        size, epoch, word_ngrams, window, negative, hs, sg, cbow_mean, min_count, tagger)\n",
    "    modelName = modelPath+modelName\n",
    "    print (modelName)\n",
    "    fastText_model = FastText(size = size, sg = sg, cbow_mean = cbow_mean,\n",
    "                                  negative = negative, hs = hs, window = window, word_ngrams=word_ngrams, \n",
    "                                  workers = workers, iter=epoch, min_count = min_count)\n",
    "    fastText_model.build_vocab(tqdm(data))\n",
    "    fastText_model.train(tqdm(data), total_examples=fastText_model.corpus_count, epochs=fastText_model.iter) \n",
    "    fastText_model.init_sims(replace = True)\n",
    "    fastText_model.save(modelName)\n",
    "    end = datetime.now()\n",
    "    print (\"Total running time: \", end-start)\n",
    "    return fastText_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491510, 2)\n"
     ]
    }
   ],
   "source": [
    "rawdata = pd.read_csv('./data/sentiment_data/raw_data_for_sentiment.txt',header=None,encoding='utf-8')\n",
    "print (rawdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>주택조합 승인 자체가 몹시 어려웠던 시절 한국기자협회 주택조합 형식으로 추진된 이 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>서 의원은 여의도  회견을 열어 “압도적으로 승리할 것이고 국민, 당원이 주문하신 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>박근혜 대통령이 14일 열린 새누리당 전당대회에 참석한 것은 그만큼 아직 여권에서 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“살기 좋은 전북 만들기, 중앙정부와 연결고리 최선” “월드컵에 출전한 우리 국가대...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"여러분 너무나 고맙고 감사합니다. 도와주신 여러분께 저의 마음속의 큰 절을 받아주...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  주택조합 승인 자체가 몹시 어려웠던 시절 한국기자협회 주택조합 형식으로 추진된 이 ...  1\n",
       "1  서 의원은 여의도  회견을 열어 “압도적으로 승리할 것이고 국민, 당원이 주문하신 ...  1\n",
       "2  박근혜 대통령이 14일 열린 새누리당 전당대회에 참석한 것은 그만큼 아직 여권에서 ...  1\n",
       "3  “살기 좋은 전북 만들기, 중앙정부와 연결고리 최선” “월드컵에 출전한 우리 국가대...  1\n",
       "4  \"여러분 너무나 고맙고 감사합니다. 도와주신 여러분께 저의 마음속의 큰 절을 받아주...  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOPWORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 포맷으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tagging(sentence, tagger, stopwords):\n",
    "    pos = tagger.pos(sentence)\n",
    "    pos = [x[0] for x in pos]\n",
    "    pos = [x for x in pos if not x in stopwords]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def Tagging2(sentence, tagger, stopwords):\n",
    "    pos = pd.Series(tagger.pos(sentence)).str[0]\n",
    "    pos = pos[~pos.isin(stopwords)]\n",
    "    return pos.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Pre_Data_Sub(series, tagger, stopwords):\n",
    "    from gensim.models.doc2vec import TaggedDocument\n",
    "    pos = Tagging2(series[0], tagger, stopwords)\n",
    "    label = series[1]\n",
    "    return TaggedDocument(pos, [label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags sentiment')\n",
    "@jit\n",
    "def Make_Pre_Data(rawdata, tagger, stopwords):\n",
    "    outList = list()\n",
    "    for idx in tqdm(rawdata.index):\n",
    "        outList.append([Tagging2(rawdata.loc[idx, 0], tagger, stopwords), ['doc_'+str(idx)], [rawdata.loc[idx, 1]]])\n",
    "    return outList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "ct = ctwitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tqdm.pandas(desc=\"progress\")\n",
    "pre_data = Make_Pre_Data(rawdata, ct, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pre_data = [TaggedDocument(b, c, d) for b, c, d in tqdm(pre_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_ct.pickled'):\n",
    "    pre_data = pickle.load(open('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_ct.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(pre_data,open('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_ct.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(pre_data, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_ct.pickled'):\n",
    "    train = pickle.load(open('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_ct.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(train,open('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_ct.pickled','wb'))\n",
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_ct.pickled'):\n",
    "    test = pickle.load(open('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_ct.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(test,open('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_ct.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = [ x.words for x in tqdm(train)] \n",
    "y_senti_train = [ x.sentiment for x in tqdm(train)] \n",
    "y_tags_train = [x.tags for x in tqdm(train)]\n",
    "x_test = [ x.words for x in tqdm(test)] \n",
    "y_senti_test = [ x.sentiment for x in tqdm(test)] \n",
    "y_tags_test = [x.tags for x in tqdm(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=0, window=10, min_count=2, cbow_mean=1, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'ct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=0, window=10, min_count=2, cbow_mean=0, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'ct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=1, window=10, min_count=2, cbow_mean=0, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'ct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 491510/491510 [24:25<00:00, 335.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 46s, sys: 1min 57s, total: 23min 44s\n",
      "Wall time: 24min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tqdm.pandas(desc=\"progress\")\n",
    "pre_data = Make_Pre_Data(rawdata, mecab, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 491510/491510 [00:31<00:00, 15587.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.52 s, sys: 17.9 s, total: 23.4 s\n",
      "Wall time: 31.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pre_data = [TaggedDocument(b, c, d) for b, c, d in tqdm(pre_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_mecab.pickled'):\n",
    "    pre_data = pickle.load(open('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_mecab.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(pre_data,open('./data/pre_data/tagged_data/pre_data__for_fastText_sentiment_by_mecab.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(pre_data, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_mecab.pickled'):\n",
    "    train = pickle.load(open('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_mecab.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(train,open('./data/pre_data/train_test_Data/pre_data_train_for_fastText_sentiment_by_mecab.pickled','wb'))\n",
    "if os.path.isfile('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_mecab.pickled'):\n",
    "    test = pickle.load(open('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_mecab.pickled','rb'))\n",
    "else:\n",
    "    pickle.dump(test,open('./data/pre_data/train_test_Data/pre_data_test_for_fastText_sentiment_by_mecab.pickled','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [ x.words for x in tqdm(train)] \n",
    "y_senti_train = [ x.sentiment for x in tqdm(train)] \n",
    "y_tags_train = [x.tags for x in tqdm(train)]\n",
    "x_test = [ x.words for x in tqdm(test)] \n",
    "y_senti_test = [ x.sentiment for x in tqdm(test)] \n",
    "y_tags_test = [x.tags for x in tqdm(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=0, window=10, min_count=2, cbow_mean=1, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'mecab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=0, window=10, min_count=2, cbow_mean=0, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'mecab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Make_FastText_Model(data=x_train, size=1000, epoch=20, \n",
    "                    sg=1, window=10, min_count=2, cbow_mean=0, workers=cores, \n",
    "                   negative = 7, word_ngrams = 3, hs = 0 , tagger = 'mecab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
