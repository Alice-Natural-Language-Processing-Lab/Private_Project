{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "import sys \n",
    "import os\n",
    "import logging\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, ldaseqmodel, LdaMulticore, lda_dispatcher\n",
    "from gensim.models.wrappers import LdaMallet, DtmModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer(doc, tagger, stopwords):\n",
    "    pos = tagger.pos(doc)\n",
    "    pos = [word[0] for word in pos if (len(word[0])>1) & (not word[0] in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer_noun(doc, tagger, stopwords):\n",
    "    pos = tagger.nouns(doc)\n",
    "    pos = [word for word in pos if (len(word)>1) & (not word in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictNaver = pickle.load(open('./data/pre_data/stastics/for_statistics_Naver_from_mongodb.pickled','rb'))\n",
    "dfNaver = pd.DataFrame.from_dict(dictNaver, orient='index')\n",
    "print (dfNaver.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictDaum = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "dfDaum = pd.DataFrame.from_dict(dictDaum, orient='index')\n",
    "print (dfDaum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 기사 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedDf = pd.concat([dfNaver, dfDaum])\n",
    "combinedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extKeywords = combinedDf.extracted_keywords.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform =='darwin':\n",
    "    clusteringPath ='/Volumes/disk1/Clustering/'\n",
    "    clusteringModelPath = '/Volumes/disk1/Clustering_model/'\n",
    "elif sys.platform =='win32':\n",
    "    clusteringPath = 'd:/Clustering/' \n",
    "    clusteringModelPath = 'd:/Clustering_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 데이터 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_keywords_name = clusteringModelPath + 'dictionary_keywords'\n",
    "if not os.path.isfile(dict_keywords_name):\n",
    "    dict_keywords = Dictionary(extKeywords)\n",
    "    dict_keywords.save(dict_keywords_name)\n",
    "else:\n",
    "    dict_keywords = Dictionary.load(dict_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_keywords_name = clusteringModelPath + 'corpus_keywords.pickled'\n",
    "if not os.path.isfile(corpus_keywords_name):\n",
    "    corpus_keywords = [ dict_keywords.doc2bow(text) for text in tqdm(extKeywords)]\n",
    "    pickle.dump(corpus_keywords, open(corpus_keywords_name, 'wb'))\n",
    "else:\n",
    "    corpus_keywords = pickle.load(open(corpus_keywords_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique tokens: %d' % len(dict_keywords))\n",
    "print('Number of documents: %d' % len(corpus_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI (  Latent Semantic Indexing )\n",
    "* an indexing and retrieval method that uses a mathematical technique called singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsimodel_keywords_name = clusteringModelPath + 'lsimodel_keywords'\n",
    "if not os.path.isfile(lsimodel_keywords_name):\n",
    "    lsimodel_keywords = LsiModel(corpus = corpus_keywords, num_topics = 20, id2word = dict_keywords)\n",
    "    lsimodel_keywords.save(lsimodel_keywords_name)\n",
    "else:\n",
    "    lsimodel_keywords = LsiModel.load(lsimodel_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel_keywords.show_topics(num_topics = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsitopics_keywords = lsimodel_keywords.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP (Hierarchical Dirichlet Process)\n",
    "* a non-parametric bayesian method (note the missing number of requested topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdpmodel_keywords_name = clusteringModelPath+'hdpmodel_keywords'\n",
    "if not os.path.isfile(hdpmodel_keywords_name):\n",
    "    hdpmodel_keywords = HdpModel(corpus = corpus_keywords, id2word = dict_keywords)\n",
    "    hdpmodel_keywords.save(clusteringModelPath+'hdpmodel_keywords')\n",
    "else:\n",
    "    hdpmodel_keywords = HdpModel.load(hdpmodel_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdpmodel_keywords.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdptopics_keywords = hdpmodel_keywords.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (Latent Dirichlet allocation)\n",
    "* a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA model1\n",
    "* basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_keywords = PerplexityMetric(corpus = corpus_keywords, logger = 'shell', \n",
    "                        title = 'Perplexity (twitter)')\n",
    "ch_umass_keywords = CoherenceMetric(corpus = corpus_keywords, coherence = 'u_mass', \n",
    "                             logger = 'shell', title = ' Coherence (u_mass)')\n",
    "ch_cv_keywords = CoherenceMetric(corpus = corpus_keywords, logger = 'shell', \n",
    "                          texts = extKeywords, coherence = 'c_v', \n",
    "                          title = 'Coherence (c_v)')\n",
    "diff_kl_keywords = DiffMetric(distance = 'kullback_leibler', \n",
    "                       logger = 'shell', title = 'Diff (kullback_leibler)')\n",
    "convergence_kl_keywords = ConvergenceMetric(distance = 'jaccard', logger = 'shell', \n",
    "                                     title = 'Convergence (jaccard)')\n",
    "callbacks_keywords = [pl_keywords, ch_umass_keywords, ch_cv_keywords, diff_kl_keywords, convergence_kl_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ldamodel_keywords_name = clusteringModelPath + 'ldamodel_keywords'\n",
    "if not os.path.isfile(ldamodel_keywords_name):\n",
    "    ldamodel_keywords = LdaModel(corpus = corpus_keywords, num_topics = 20,\n",
    "                           id2word = dict_keywords, passes = 50,\n",
    "                           chunksize = 6123, iterations = 250,\n",
    "                           alpha='auto', callbacks = callbacks_keywords)\n",
    "    ldamodel_keywords.save(ldamodel_keywords_name)\n",
    "else:\n",
    "    ldamodel_keywords = LdaModel.load(ldamodel_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_um_keywords_name = clusteringModelPath + 'coherence1_keywords_u_mass'\n",
    "if not os.path.isfile(coherence1_um_keywords_name):\n",
    "    cm_keywords = CoherenceModel(model = ldamodel_keywords, \n",
    "                      corpus = corpus_keywords, \n",
    "                      dictionary = dict_keywords,\n",
    "                      coherence = 'u_mass')\n",
    "    cm_keywords.save(coherence1_um_keywords_name)\n",
    "else:\n",
    "    cm_keywords = CoherenceModel.load(coherence1_um_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_keywords.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_cv_keywords_name = clusteringModelPath + 'coherence1_keywords_c_v'\n",
    "if not os.path.isfile(coherence1_cv_keywords_name):\n",
    "    cm_keywords_cv = CoherenceModel(model = ldamodel_keywords, \n",
    "                         texts = extKeywords,\n",
    "                         dictionary = dict_keywords, \n",
    "                         coherence = 'c_v')\n",
    "    cm_keywords_cv.save(coherence1_cv_keywords_name)\n",
    "else:\n",
    "    cm_keywords_cv = CoherenceModel.load(coherence1_cv_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_extKeywords_cv.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyLDAvis.gensim.prepare(ldamodel_keywords, corpus_extKeywords, dict_extKeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_keywords = ldamodel_keywords.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### display num_topics - LDA graph using c_v coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_keywords, c_v_keywords = evaluate_graph(dictionary = dict_keywords, corpus = corpus_keywords, texts = extKeywords, limit = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* The constructor estimates Dynamic Topic Model parameters based on a training corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_keywords_name = clusteringModelPath + 'ldaseqmodel_keywords'\n",
    "if not os.path.isfile(ldaseq_keywords_name):\n",
    "    ldaseq_keywords = ldaseqmodel.LdaSeqModel(corpus = corpus_keywords, \n",
    "                                   id2word = dict_keywords,\n",
    "                                   time_slice= [8164, 8164, 8164], \n",
    "                                   num_topics = 20)\n",
    "    ldaseq_keywords.save(ldaseq_keywords_name)\n",
    "else:\n",
    "    ldaseq_keywords = ldaseqmodel.LdaSeqModel.load(ldaseq_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_keywords, topic_term_keywords, doc_lengths_keywords, term_freq_keywords, vocab_keywords = ldaseq_keywords.dtm_vis(time = 0, corpus = corpus_keywords)\n",
    "vis_wrapper_keywords = pyLDAvis.prepare(topic_term_dists = topic_term_keywords,\n",
    "                               doc_topic_dists = doc_topic_keywords,\n",
    "                              doc_lengths = doc_lengths_keywords,\n",
    "                              vocab = vocab_keywords, \n",
    "                              term_frequency = term_freq_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* chain_variance : 0.05  \n",
    "> * a constant which dictates how the beta values evolve - it is a gaussian parameter defined in the beta distribution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_chain_keywords_name = clusteringModelPath + 'ldaseqmodel_chain_keywords'\n",
    "if not os.path.isfile(ldaseq_chain_keywords_name):\n",
    "    ldaseq_chain_keywords = ldaseqmodel.LdaSeqModel(corpus = corpus_keywords, \n",
    "                                         id2word = dict_keywords, \n",
    "                                         time_slice = [8164, 8164, 8164],\n",
    "                                         num_topics = 20, \n",
    "                                         chain_variance = 0.05)\n",
    "    ldaseq_chain_keywords.save(ldaseq_chain_keywrods_name)\n",
    "else:\n",
    "    ldaseq_chain_keywords = ldaseqmodel.LdaSeqModel.load(ldaseq_chain_keywords_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = '/Users/hyunyoun/Documents/GitHub/Private_Project/dtm-darwin64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtm_model_keywords_name = clusteringModelPath + 'dtm_keywords'\n",
    "if not os.path.isfile(dtm_model_keywords_name):\n",
    "    dtm_model_keywords = DtmModel(dtm_path, corpus = corpus_keywords,  \n",
    "                       num_topics = 20, \n",
    "                       id2word = dict_keywords, \n",
    "                       initialize_lda = True)\n",
    "    dtm_model_keywords.save(dtm_model_keywords_name)\n",
    "else:\n",
    "    dtm_model_keywords = DtmModel.load(dtm_model_keywords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_keywords, topic_term_keywords, doc_lengths_keywords, term_freq_keywords,vocab_keywords = dtm_model_keywords.dtm_vis(time = 0, corpus = corpus_keywords)\n",
    "vis_wrapper_keywords = pyLDAvis.prepare(topic_term_dists = topic_term_keywords,\n",
    "                               doc_topic_dists = doc_topic_keywords,\n",
    "                              doc_lengths = doc_lengths_keywords,\n",
    "                              vocab = vocab_keywords, \n",
    "                              term_frequency = term_freq_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topics_wrapper_keywords = dtm_model_keywords.dtm_coherence(time = 0)\n",
    "topics_dtm_keywords = ldaseq_keywords.dtm_coherence(time = 2)\n",
    "topics_dtm2_keywords = ldaseq_chain_keywords.dtm_coherence( time = 2)\n",
    "\n",
    "cm_wrapper_keywords = CoherenceModel(topics = topics_wrapper_keywords, corpus = corpus_keywords,\n",
    "                            dictionary = dict_keywords, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm_keywords = CoherenceModel(topics = topics_dtm_keywords, corpus = corpus_keywords,\n",
    "                            dictionary = dict_keywords, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm2_keywords = CoherenceModel(topics = topics_dtm2_keywords, corpus = corpus_keywords,\n",
    "                            dictionary = dict_keywords, coherence = 'u_mass')\n",
    "\n",
    "print ('U_mass topic coherence')\n",
    "print ('Wrapper coherence is {}'.format(cm_wrapper_keywords.get_coherence()))\n",
    "print ('DTM Python coherence is {}'.format(cm_dtm_keywords.get_coherence()))\n",
    "print ('DTM (chain variance) Python coherence is {}'.format(cm_dtm2_keywords.get_coherence()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
