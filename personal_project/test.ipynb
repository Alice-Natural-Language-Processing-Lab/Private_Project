{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Mecab, Twitter\n",
    "from konlpy.utils import pprint\n",
    "def Stopwords(file):\n",
    "    stopwords = open(file,'r',  encoding='utf-8').readlines()\n",
    "    stopwords = list(map(lambda x:x.strip(), stopwords))\n",
    "    return stopwords\n",
    "stopwords = Stopwords('./data/koreanStopwords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path6 = './data/news/have_negative_positive/constitution/'\n",
    "path7 = './data/news/have_negative_positive/household_debt/'\n",
    "path8 = './data/news/have_negative_positive/olymphic/'\n",
    "path9 = './data/news/have_negative_positive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathlist = [path6, path7, path8, path9,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "def Check_Sentiment(pos, neg, x):\n",
    "    y = list(chunker(x.split(), 2))\n",
    "    y = list(filter(lambda x: len(x) !=1, y))\n",
    "    for i,a in y:\n",
    "        if i == 'NEGATIVE':neg.append(a.strip())\n",
    "        else:\n",
    "            pos.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos = [] ; neg = []\n",
    "pos_word = open('./data/positive_sentiment_word_from_news.csv','w')\n",
    "neg_word = open('./data/negative_sentiment_word_from_news.csv','w')\n",
    "pos_sentence = './data/positive_sentiment_sentence_from_news.csv'\n",
    "neg_sentence = './data/negative_sentiment_sentence_from_news.csv'\n",
    "for path in pathlist:\n",
    "    from glob import glob\n",
    "    fileList = glob(path+'*.csv')\n",
    "    listIs =list()\n",
    "    for i in fileList:\n",
    "        df = pd.read_csv(i,engine='python',encoding='utf-8')\n",
    "        f = list(filter(lambda x: x[1] in ['감성분석','감성 분석','긍정문장','긍정 문장','부정 문장', '부정문장'], enumerate(df.columns.values)))\n",
    "        redf = df.loc[:, df.columns[f[0][0]:]]\n",
    "        redf.dropna(thresh=1, inplace = True)\n",
    "        xc = redf['감성분석']\n",
    "        xc = xc[xc.notnull()]\n",
    "        xc = xc[xc != 'NEUTRAL']\n",
    "        xc = xc.apply(lambda x: Check_Sentiment(pos, neg, x))\n",
    "        xc2 = redf['긍정 문장']\n",
    "        xc2 = xc2[xc2.notnull()]\n",
    "        xc2 = xc2[xc2 != 'NEUTRAL']\n",
    "        xc3 = redf['부정 문장']\n",
    "        xc3 = xc3[xc3.notnull()]\n",
    "        xc3 = xc3[xc3 != 'NEUTRAL']\n",
    "        with open(pos_sentence,'a') as f:\n",
    "            xc2.to_csv(f, header = False)\n",
    "        with open(neg_sentence, 'a') as g:\n",
    "            xc3.to_csv(g, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pos_word.write('\\n'.join(pos))\n",
    "pos_word.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_word.write('\\n'.join(neg))\n",
    "neg_word.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        [[NEGATIVE, 경계], [NEGATIVE, 극우]]\n",
       "1       [[POSITIVE, 신뢰], [POSITIVE, 평화], [POSITIVE, 회복...\n",
       "2                      [[POSITIVE, 발전], [POSITIVE, 증강하다]]\n",
       "3                                        [[POSITIVE, 공헌]]\n",
       "4       [[NEGATIVE, 걸림돌], [NEGATIVE, 좌절], [NEGATIVE, 의...\n",
       "5       [[NEGATIVE, 진통], [NEGATIVE, 함정], [NEGATIVE, 모자...\n",
       "6       [[NEGATIVE, 해임], [POSITIVE, 평화], [NEGATIVE, 못하...\n",
       "7       [[POSITIVE, 생생하다], [POSITIVE, 쉽게해결되다], [NEGATI...\n",
       "9       [[POSITIVE, 발전], [NEGATIVE, 불법], [NEGATIVE, 부당...\n",
       "11      [[POSITIVE, 특수], [POSITIVE, 특수], [POSITIVE, 특수...\n",
       "12      [[POSITIVE, 지원], [NEGATIVE, 까지], [NEGATIVE, 고자...\n",
       "13      [[POSITIVE, 특수], [POSITIVE, 쉽다], [POSITIVE, 절약...\n",
       "14      [[NEGATIVE, 미치], [NEGATIVE, 까지], [POSITIVE, 지원...\n",
       "15                                       [[POSITIVE, 도움]]\n",
       "16      [[POSITIVE, 탄탄], [POSITIVE, 관심], [POSITIVE, 완전...\n",
       "17                       [[POSITIVE, 효과], [POSITIVE, 장점]]\n",
       "19                                       [[POSITIVE, 비전]]\n",
       "20      [[POSITIVE, 탄탄], [POSITIVE, 비전], [POSITIVE, 흥미...\n",
       "21                      [[POSITIVE, 효과], [POSITIVE, 우수한]]\n",
       "22      [[POSITIVE, 비전], [POSITIVE, 효과], [POSITIVE, 우수한]]\n",
       "23      [[POSITIVE, 비전], [POSITIVE, 극복], [POSITIVE, 효과...\n",
       "24      [[POSITIVE, 최고], [NEGATIVE, 우스꽝스럽], [POSITIVE,...\n",
       "25      [[POSITIVE, 기대], [POSITIVE, 특수], [POSITIVE, 특수...\n",
       "26      [[POSITIVE, 지원], [POSITIVE, 재미], [POSITIVE, 흥미...\n",
       "28                                     [[POSITIVE, 유용하다]]\n",
       "29      [[POSITIVE, 재미있다], [POSITIVE, 관심], [POSITIVE, ...\n",
       "30                                      [[POSITIVE, 상받다]]\n",
       "32                                       [[POSITIVE, 위력]]\n",
       "33                                       [[POSITIVE, 지원]]\n",
       "38      [[POSITIVE, 최우수], [POSITIVE, 최우수], [POSITIVE, ...\n",
       "                              ...                        \n",
       "6874    [[POSITIVE, 화창], [POSITIVE, 즐기], [POSITIVE, 좋다...\n",
       "6875                  [[POSITIVE, 목표로하다], [POSITIVE, 발전]]\n",
       "6876    [[POSITIVE, 폭넓다], [POSITIVE, 혁신], [POSITIVE, 발전]]\n",
       "6877    [[NEGATIVE, 까지], [NEGATIVE, 유혹], [POSITIVE, 안녕...\n",
       "6878                                     [[POSITIVE, 쉽다]]\n",
       "6879    [[POSITIVE, 최선], [POSITIVE, 발전], [POSITIVE, 활력...\n",
       "6880    [[NEGATIVE, 모호하다], [NEGATIVE, 단절], [NEGATIVE, ...\n",
       "6881    [[NEGATIVE, 미관을해치다], [NEGATIVE, 방치되다], [POSITI...\n",
       "6882    [[NEGATIVE, 염려하다], [NEGATIVE, 지못하다], [NEGATIVE...\n",
       "6883                                     [[POSITIVE, 창의]]\n",
       "6885                   [[POSITIVE, 돕아주다], [POSITIVE, 성장]]\n",
       "6886    [[POSITIVE, 자랑하다], [POSITIVE, 강점이다], [NEGATIVE...\n",
       "6887                                     [[POSITIVE, 발전]]\n",
       "6888    [[POSITIVE, 폭넓다], [POSITIVE, 혁신], [POSITIVE, 발전]]\n",
       "6889                  [[POSITIVE, 목표로하다], [POSITIVE, 발전]]\n",
       "6890    [[POSITIVE, 창조하다], [POSITIVE, 개선하다], [POSITIVE...\n",
       "6891    [[POSITIVE, 살다], [NEGATIVE, 지적되다], [POSITIVE, ...\n",
       "6892    [[POSITIVE, 스마트], [POSITIVE, 기대], [POSITIVE, 신...\n",
       "6893                   [[POSITIVE, 기살리다], [POSITIVE, 특수]]\n",
       "6894    [[NEGATIVE, 문제], [NEGATIVE, 문제], [NEGATIVE, 심각...\n",
       "6895    [[POSITIVE, 생생하다], [POSITIVE, 창조하다], [NEGATIVE...\n",
       "6896    [[POSITIVE, 좋다], [POSITIVE, 지원], [POSITIVE, 밝다...\n",
       "6897    [[POSITIVE, 혁신], [POSITIVE, 최고], [POSITIVE, 인정...\n",
       "6898    [[NEGATIVE, 빠지다], [NEGATIVE, 울다], [POSITIVE, 노력]]\n",
       "6899    [[NEGATIVE, 줄어들다], [POSITIVE, 성공하다], [NEGATIVE...\n",
       "6900    [[POSITIVE, 성과], [POSITIVE, 긍정], [POSITIVE, 혁신...\n",
       "6901    [[POSITIVE, 발전], [POSITIVE, 즐기], [POSITIVE, 성과...\n",
       "6902                    [[NEGATIVE, 빠지다], [NEGATIVE, 울다]]\n",
       "6903    [[POSITIVE, 인정받다], [POSITIVE, 협력을통하다], [POSITI...\n",
       "6905    [[POSITIVE, 혜택을주다], [POSITIVE, 스마트], [POSITIVE...\n",
       "Name: 감성분석, Length: 6474, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileis = open('./data/news/have_negative_positive/증강현실 관련 뉴스메타데이터(19900101-2016.9.30).csv')\n",
    "while 1:\n",
    "    line = fileis.readline()\n",
    "    if not line:break\n",
    "    print (line)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(list(chunker(y2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_file2 = openpyxl.load_workbook('./data/NIADic.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file2.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excel_sheet2 = excel_file2.get_sheet_by_name('NIADic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outDict = dict()\n",
    "for row in excel_sheet2.rows:\n",
    "    if row[0].row ==1:pass\n",
    "    else:\n",
    "        x = row[1].value.upper()\n",
    "        if x in tagDict.keys():\n",
    "            x2 = tagDict[x]\n",
    "            if not x2 in outDict.keys():\n",
    "                outDict[x2] = []\n",
    "                outDict[x2].append(row[0].value)\n",
    "            else:\n",
    "                outDict[x2].append(row[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in outDict:\n",
    "    twitter.add_dictionary(outDict[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mongodb = dh.ToMongoDB(*dh.AWS_MongoDB_Information())\n",
    "dbname = 'hy_db'\n",
    "useDb = dh.Use_Database(mongodb, dbname)\n",
    "slack = cb.Slacker(cb.slacktoken())\n",
    "useCollection = dh.Use_Collection(useDb, 'newsDaum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = useCollection.find_one({'category':\"뉴스\"})\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Twitter as Original_Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tager_t = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tager_t.pos(rawdata['mainText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Extract_Keywords(text):\n",
    "    twitter = list(filter(\n",
    "            lambda x: x[1] =='Noun',\n",
    "            Twitter().pos(text)))\n",
    "    original_twitter = list(filter(\n",
    "        lambda x: x[1] =='Noun',\n",
    "        Original_Twitter().pos(text)))\n",
    "    f11=Counter(twitter).most_common(n=10)\n",
    "    f21=Counter(original_twitter).most_common(n=10)\n",
    "    return set(map(lambda x: x[0][0], f11)) & set(map(lambda x: x[0][0], f21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in useCollection.find({'site':'daum'}):\n",
    "    print (i['keywords'], Extract_Keywords(i['mainText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = list(filter(lambda x: x[1] =='Noun', Original_Twitter().pos(rawdata['mainText'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(f1) & set(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(map(lambda x: x[0][0], f11)) & set(map(lambda x: x[0][0], f21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f11[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
