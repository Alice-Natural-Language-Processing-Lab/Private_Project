{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "import sys \n",
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, ldaseqmodel, LdaMulticore, lda_dispatcher\n",
    "from gensim.models.wrappers import LdaMallet, DtmModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer(doc, tagger, stopwords):\n",
    "    pos = tagger.pos(doc)\n",
    "    pos = [word[0] for word in pos if (len(word[0])>1) & (not word[0] in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer_noun(doc, tagger, stopwords):\n",
    "    pos = tagger.nouns(doc)\n",
    "    pos = [word for word in pos if (len(word)>1) & (not word in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 10)\n"
     ]
    }
   ],
   "source": [
    "dictNaver = pickle.load(open('./data/pre_data/stastics/for_statistics_Naver_from_mongodb.pickled','rb'))\n",
    "dfNaver = pd.DataFrame.from_dict(dictNaver, orient='index')\n",
    "print (dfNaver.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9372, 10)\n"
     ]
    }
   ],
   "source": [
    "dictDaum = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "dfDaum = pd.DataFrame.from_dict(dictDaum, orient='index')\n",
    "print (dfDaum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 기사 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973a</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1713</td>\n",
       "      <td>1465</td>\n",
       "      <td>1</td>\n",
       "      <td>北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"</td>\n",
       "      <td>美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...</td>\n",
       "      <td>[외무성, 핵전쟁, 대변인]</td>\n",
       "      <td>{고위, 북한, 미국, 조선반도, 핵전쟁, 중앙, 대변인, 도화선}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973b</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>한국일보</td>\n",
       "      <td>2551</td>\n",
       "      <td>2062</td>\n",
       "      <td>2</td>\n",
       "      <td>예산전쟁, 예결위 간사ㆍ호남이 웃었다</td>\n",
       "      <td>예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...</td>\n",
       "      <td>[예산, 예결위, soc]</td>\n",
       "      <td>{의원, 국민의당, 지역구, 호남, 증액, 예산안, 정부안}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973c</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>610</td>\n",
       "      <td>536</td>\n",
       "      <td>3</td>\n",
       "      <td>혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나</td>\n",
       "      <td>【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...</td>\n",
       "      <td>[최경환, 구속영장, 국가정보원]</td>\n",
       "      <td>{혐의, 조사, 의원, 구속영장 청구, 국정원장, 검찰, 정기국회}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973d</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>145</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "      <td>최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"</td>\n",
       "      <td>감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...</td>\n",
       "      <td>[이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]</td>\n",
       "      <td>{감사원장, 후보자, 공직 사회, 생활, 법관, 지명}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973e</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>1074</td>\n",
       "      <td>932</td>\n",
       "      <td>5</td>\n",
       "      <td>B-1B 한반도에 뜨자, 평양 비운 김정은</td>\n",
       "      <td>[동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...</td>\n",
       "      <td>[김정은, b-1b, 한반도]</td>\n",
       "      <td>{삼지연, 김정은, 양강도, 사무차장, 훈련, 접경, 공장, 시찰, 펠트먼}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category        date press  number_of_comment  \\\n",
       "5a29c445588c132954d1973a       정치  2017.12.07  연합뉴스               1713   \n",
       "5a29c445588c132954d1973b       정치  2017.12.07  한국일보               2551   \n",
       "5a29c445588c132954d1973c       정치  2017.12.07   뉴시스                610   \n",
       "5a29c445588c132954d1973d       정치  2017.12.07  연합뉴스                145   \n",
       "5a29c445588c132954d1973e       정치  2017.12.07  동아일보               1074   \n",
       "\n",
       "                          number_of_crawled_comment rank  \\\n",
       "5a29c445588c132954d1973a                       1465    1   \n",
       "5a29c445588c132954d1973b                       2062    2   \n",
       "5a29c445588c132954d1973c                        536    3   \n",
       "5a29c445588c132954d1973d                        133    4   \n",
       "5a29c445588c132954d1973e                        932    5   \n",
       "\n",
       "                                                    title  \\\n",
       "5a29c445588c132954d1973a    北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"   \n",
       "5a29c445588c132954d1973b             예산전쟁, 예결위 간사ㆍ호남이 웃었다   \n",
       "5a29c445588c132954d1973c  혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나   \n",
       "5a29c445588c132954d1973d   최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"   \n",
       "5a29c445588c132954d1973e          B-1B 한반도에 뜨자, 평양 비운 김정은   \n",
       "\n",
       "                                                                   mainText  \\\n",
       "5a29c445588c132954d1973a  美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...   \n",
       "5a29c445588c132954d1973b  예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...   \n",
       "5a29c445588c132954d1973c  【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...   \n",
       "5a29c445588c132954d1973d  감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...   \n",
       "5a29c445588c132954d1973e  [동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...   \n",
       "\n",
       "                                                    keywords  \\\n",
       "5a29c445588c132954d1973a                     [외무성, 핵전쟁, 대변인]   \n",
       "5a29c445588c132954d1973b                      [예산, 예결위, soc]   \n",
       "5a29c445588c132954d1973c                  [최경환, 구속영장, 국가정보원]   \n",
       "5a29c445588c132954d1973d  [이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]   \n",
       "5a29c445588c132954d1973e                    [김정은, b-1b, 한반도]   \n",
       "\n",
       "                                                  extracted_keywords  \n",
       "5a29c445588c132954d1973a       {고위, 북한, 미국, 조선반도, 핵전쟁, 중앙, 대변인, 도화선}  \n",
       "5a29c445588c132954d1973b           {의원, 국민의당, 지역구, 호남, 증액, 예산안, 정부안}  \n",
       "5a29c445588c132954d1973c       {혐의, 조사, 의원, 구속영장 청구, 국정원장, 검찰, 정기국회}  \n",
       "5a29c445588c132954d1973d              {감사원장, 후보자, 공직 사회, 생활, 법관, 지명}  \n",
       "5a29c445588c132954d1973e  {삼지연, 김정은, 양강도, 사무차장, 훈련, 접경, 공장, 시찰, 펠트먼}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDf = pd.concat([dfNaver, dfDaum])\n",
    "combinedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData_text = combinedDf.title + '\\n' + combinedDf.mainText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"\\n美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민연환대회(평양 조선중앙통신=연합뉴스) 북한이 \\'화성-15형\\' 발사 성공을 축하하는 군민연환대회를 지난 5일 황해북도, 강원도, 양강도 등 각지에서 열었다고 6일 조선중앙통신이 보도했다. 2017.12.6 [국내에서만 사용가능. 재배포 금지. For Use Only in the Republic of Korea. No Redistribution] photo@yna.co.kr   (서울=연합뉴스) 홍국기 기자 = 북한은 6일 미국 고위인사들의 대북 강경 발언들을 문제 삼으며 \"미국은 매일과 같이 조선반도(한반도)에서의 핵전쟁을 광고하고 있다\"면서 \"우리는 전쟁을 바라지 않지만 결코 피하지 않을 것\"이라고 밝혔다.  북한 외무성 대변인은 이날 조선중앙통신 기자와의 문답에서 \"미국이 조선반도에서 우리를 겨냥한 사상 최대의 연합공중훈련을 강행하고 있는 가운데 최근 미국의 고위정객들이 줄줄이 나서서 호전적인 망발들을 늘어놓는 등 심상치 않은 움직임을 보이고 있다\"면서 이같이 말했다고 중앙통신이 전했다.  외무성 대변인은 \"조선반도에 언제 전쟁이 터질지 모를 일촉즉발의 초긴장상태가 조성되고있는 속에 미국의 고위정객들의 입에서 연달아 터져 나오는 전쟁 폭언으로 말미암아 조선반도에서의 전쟁은 기정사실화되고 이제 남은 것은 언제 전쟁이 터지는가 하는 시점상 문제\"라고 위협했다.  대변인은 \"백악관 국가안보보좌관과 공화당 소속 국회 상원의원이 북조선과의 전쟁 가능성이 매일 증대되고 있다느니, 선제공격 선택에 더욱 접근하고 있다느니, 남조선 주둔 미군 가족들을 철수시켜야 한다느니 하는 따위의 화약내 풍기는 대결 망발들을 늘어놓은 것은 우리에게 조선반도에서의 전쟁발발에 대비하라는 신호로밖에 달리 해석될 수 없다\"고 주장했다.  이어 \"지어(심지어) 미 중앙정보국장이란 놈이 우리의 심장인 최고 지도부까지 감히 걸고 들며 도발을 걸어온 것은 우리가 강경 대응조치를 취하게 하고 그를 빌미로 조선반도에서 핵전쟁의 도화선에 기어이 불을 달려는 미국의 간교한 흉심의 노출\"이라고 비난했다.  이는 마이크 폼페이오 미 중앙정보국(CIA) 국장이 지난 2일 한 포럼에서 \"김정은은 국내외에서 자신의 입지가 얼마나 취약한지 잘 알지 못하는 것으로 생각한다\"고 한 발언을 겨냥한 것으로 보인다.  대변인은 \"미국이 우리의 자제력을 오판하고 끝끝내 핵전쟁의 도화선에 불을 단다면 다지고 다져온 무진막강한 핵무력으로 반드시 그 대가를 치르게 할 것\"이라며 \"미국은 제가 지른 불에 타죽지 않으려거든 자중 자숙하는 것이 좋을 것\"이라고 밝혔다.  redflag@yna.co.kr  ▶기사제보 및 문의(클릭!)  ▶최신 유행 트렌드 총집결(클릭!)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform =='darwin':\n",
    "    clusteringPath ='/Volumes/disk1/Clustering/'\n",
    "    clusteringModelPath = '/Volumes/disk1/Clustering_model/'\n",
    "elif sys.platform =='win32':\n",
    "    clusteringPath = 'd:/Clustering/' \n",
    "    clusteringModelPath = 'd:/Clustering_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "ct = Twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 명사만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_ct = clusteringPath + 'nouns_taggerd_news_text_by_ct.pickled'\n",
    "if not os.path.isfile(outfile_ct):\n",
    "    tagged_text_ct = [Nav_tokenizer_noun(doc, ct, stopwords) for doc in tqdm(rawData_text)]\n",
    "    pickle.dump(tagged_text_ct, open(outfile_ct, 'wb'))\n",
    "else:\n",
    "    tagged_text_ct = pickle.load(open(outfile_ct, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_mecab = clusteringPath + 'nouns_taggerd_news_text_by_mecab.pickled'\n",
    "if not os.path.isfile(outfile_mecab):\n",
    "    tagged_text_mecab = [Nav_tokenizer_noun(doc, mecab, stopwords) for doc in tqdm(rawData_text)]\n",
    "    pickle.dump(tagged_text_mecab, open(outfile_mecab, 'wb'))\n",
    "else:\n",
    "    tagged_text_mecab = pickle.load(open(outfile_mecab, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['외무성',\n",
       " '전쟁',\n",
       " '바라지',\n",
       " '결코',\n",
       " '피하',\n",
       " '고위',\n",
       " '인사',\n",
       " '대북',\n",
       " '언급',\n",
       " '비난',\n",
       " '전쟁',\n",
       " '기정',\n",
       " '위협',\n",
       " '며칠',\n",
       " '북한',\n",
       " '군민',\n",
       " '연환',\n",
       " '대회',\n",
       " '평양',\n",
       " '조선',\n",
       " '중앙',\n",
       " '통신',\n",
       " '북한',\n",
       " '화성',\n",
       " '15',\n",
       " '발사',\n",
       " '성공',\n",
       " '군민',\n",
       " '연환',\n",
       " '대회',\n",
       " '황해북도',\n",
       " '강원도',\n",
       " '양강도',\n",
       " '각지',\n",
       " '조선중앙통신',\n",
       " '2017',\n",
       " '12',\n",
       " '국내',\n",
       " '사용',\n",
       " '가능',\n",
       " '배포',\n",
       " '금지',\n",
       " '서울',\n",
       " '국기',\n",
       " '북한',\n",
       " '미국',\n",
       " '고위',\n",
       " '인사',\n",
       " '대북',\n",
       " '강경',\n",
       " '발언',\n",
       " '미국',\n",
       " '매일',\n",
       " '조선반도',\n",
       " '한반도',\n",
       " '핵전쟁',\n",
       " '광고',\n",
       " '전쟁',\n",
       " '바라지',\n",
       " '결코',\n",
       " '피하',\n",
       " '북한',\n",
       " '외무성',\n",
       " '대변인',\n",
       " '조선중앙통신',\n",
       " '문답',\n",
       " '미국',\n",
       " '조선반도',\n",
       " '겨냥',\n",
       " '사상',\n",
       " '최대',\n",
       " '연합',\n",
       " '공중',\n",
       " '훈련',\n",
       " '강행',\n",
       " '미국',\n",
       " '고위',\n",
       " '정객',\n",
       " '줄줄이',\n",
       " '호전',\n",
       " '적인',\n",
       " '망발',\n",
       " '상치',\n",
       " '움직임',\n",
       " '중앙통신',\n",
       " '외무성',\n",
       " '대변인',\n",
       " '조선반도',\n",
       " '전쟁',\n",
       " '일촉즉발',\n",
       " '초긴장',\n",
       " '상태',\n",
       " '조성',\n",
       " '미국',\n",
       " '고위',\n",
       " '정객',\n",
       " '연달',\n",
       " '전쟁',\n",
       " '폭언',\n",
       " '조선반도',\n",
       " '서의',\n",
       " '전쟁',\n",
       " '기정',\n",
       " '전쟁',\n",
       " '위협',\n",
       " '대변인',\n",
       " '백악관',\n",
       " '국가',\n",
       " '안보',\n",
       " '보좌',\n",
       " '공화당',\n",
       " '국회',\n",
       " '상원의원',\n",
       " '북조선',\n",
       " '전쟁',\n",
       " '가능성',\n",
       " '매일',\n",
       " '증대',\n",
       " '선제공격',\n",
       " '선택',\n",
       " '접근',\n",
       " '남조선',\n",
       " '주둔',\n",
       " '미군',\n",
       " '가족',\n",
       " '철수',\n",
       " '화약',\n",
       " '풍기',\n",
       " '대결',\n",
       " '망발',\n",
       " '조선반도',\n",
       " '서의',\n",
       " '전쟁',\n",
       " '발발',\n",
       " '대비',\n",
       " '신호',\n",
       " '달리',\n",
       " '해석',\n",
       " '중앙',\n",
       " '정보',\n",
       " '국장',\n",
       " '심장',\n",
       " '최고',\n",
       " '지도부',\n",
       " '감히',\n",
       " '도발',\n",
       " '강경',\n",
       " '대응조치',\n",
       " '빌미',\n",
       " '조선반도',\n",
       " '핵전',\n",
       " '쟁의',\n",
       " '도화선',\n",
       " '기어이',\n",
       " '미국',\n",
       " '간교',\n",
       " '심의',\n",
       " '노출',\n",
       " '비난',\n",
       " '마이크',\n",
       " '폼페이',\n",
       " '중앙',\n",
       " '정보',\n",
       " '국장',\n",
       " '포럼',\n",
       " '김정은',\n",
       " '국내외',\n",
       " '입지',\n",
       " '취약',\n",
       " '한지',\n",
       " '발언',\n",
       " '겨냥',\n",
       " '대변인',\n",
       " '미국',\n",
       " '자제력',\n",
       " '판하',\n",
       " '끝내',\n",
       " '핵전',\n",
       " '쟁의',\n",
       " '도화선',\n",
       " '다지',\n",
       " '무진',\n",
       " '막강',\n",
       " '무력',\n",
       " '대가',\n",
       " '미국',\n",
       " '죽지',\n",
       " '자중',\n",
       " '자숙하',\n",
       " '제보',\n",
       " '문의',\n",
       " '클릭',\n",
       " '최신',\n",
       " '유행',\n",
       " '트렌드',\n",
       " '집결',\n",
       " '클릭']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text_ct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['외무성',\n",
       " '전쟁',\n",
       " '고위',\n",
       " '인사',\n",
       " '대북',\n",
       " '언급',\n",
       " '비난',\n",
       " '전쟁',\n",
       " '기정사실화',\n",
       " '위협',\n",
       " '며칠',\n",
       " '북한',\n",
       " '군민',\n",
       " '연환',\n",
       " '대회',\n",
       " '평양',\n",
       " '조선중앙통신',\n",
       " '북한',\n",
       " '화성',\n",
       " '발사',\n",
       " '성공',\n",
       " '축하',\n",
       " '군민',\n",
       " '연환',\n",
       " '대회',\n",
       " '황해북도',\n",
       " '강원도',\n",
       " '양강도',\n",
       " '각지',\n",
       " '조선중앙통신',\n",
       " '보도',\n",
       " '국내',\n",
       " '사용',\n",
       " '가능',\n",
       " '재배포',\n",
       " '금지',\n",
       " '서울',\n",
       " '홍국',\n",
       " '북한',\n",
       " '미국',\n",
       " '고위',\n",
       " '인사',\n",
       " '대북',\n",
       " '강경',\n",
       " '발언',\n",
       " '미국',\n",
       " '매일',\n",
       " '조선반도',\n",
       " '한반도',\n",
       " '핵전쟁',\n",
       " '광고',\n",
       " '전쟁',\n",
       " '북한',\n",
       " '외무성',\n",
       " '대변인',\n",
       " '조선중앙통신',\n",
       " '문답',\n",
       " '미국',\n",
       " '조선반도',\n",
       " '겨냥',\n",
       " '사상',\n",
       " '최대',\n",
       " '연합',\n",
       " '공중',\n",
       " '훈련',\n",
       " '강행',\n",
       " '미국',\n",
       " '고위',\n",
       " '정객',\n",
       " '호전',\n",
       " '망발',\n",
       " '움직임',\n",
       " '중앙통신',\n",
       " '외무성',\n",
       " '대변인',\n",
       " '조선반도',\n",
       " '전쟁',\n",
       " '일촉즉발',\n",
       " '초긴장',\n",
       " '상태',\n",
       " '조성',\n",
       " '미국',\n",
       " '고위',\n",
       " '정객',\n",
       " '전쟁',\n",
       " '폭언',\n",
       " '조선반도',\n",
       " '전쟁',\n",
       " '기정사실',\n",
       " '전쟁',\n",
       " '위협',\n",
       " '대변인',\n",
       " '백악관',\n",
       " '국가안보',\n",
       " '보좌관',\n",
       " '공화당',\n",
       " '국회',\n",
       " '상원',\n",
       " '의원',\n",
       " '북조선',\n",
       " '전쟁',\n",
       " '가능',\n",
       " '증대',\n",
       " '선제공격',\n",
       " '선택',\n",
       " '접근',\n",
       " '남조선',\n",
       " '주둔',\n",
       " '미군',\n",
       " '가족',\n",
       " '철수',\n",
       " '화약내',\n",
       " '대결',\n",
       " '망발',\n",
       " '조선반도',\n",
       " '전쟁',\n",
       " '발발',\n",
       " '대비',\n",
       " '신호',\n",
       " '해석',\n",
       " '주장',\n",
       " '지어',\n",
       " '중앙',\n",
       " '정보',\n",
       " '국장',\n",
       " '심장',\n",
       " '최고',\n",
       " '지도부',\n",
       " '도발',\n",
       " '강경',\n",
       " '대응',\n",
       " '조치',\n",
       " '빌미',\n",
       " '조선반도',\n",
       " '핵전쟁',\n",
       " '도화선',\n",
       " '미국',\n",
       " '간교',\n",
       " '흉심',\n",
       " '노출',\n",
       " '비난',\n",
       " '마이크',\n",
       " '폼페이',\n",
       " '중앙정보국',\n",
       " '국장',\n",
       " '포럼',\n",
       " '김정은',\n",
       " '국내외',\n",
       " '입지',\n",
       " '발언',\n",
       " '겨냥',\n",
       " '대변인',\n",
       " '미국',\n",
       " '자제력',\n",
       " '오판',\n",
       " '핵전쟁',\n",
       " '도화선',\n",
       " '단다',\n",
       " '무진',\n",
       " '막강',\n",
       " '무력',\n",
       " '대가',\n",
       " '미국',\n",
       " '자중',\n",
       " '자숙',\n",
       " '문의',\n",
       " '클릭',\n",
       " '최신',\n",
       " '유행',\n",
       " '트렌드',\n",
       " '총집결',\n",
       " '클릭']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text_mecab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 데이터 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 134 ms, sys: 37.8 ms, total: 172 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_ct_name = clusteringModelPath + 'dictionary_ct'\n",
    "dict_mecab_name = clusteringModelPath + 'dictionary_mecab'\n",
    "if not os.path.isfile(dict_ct_name):\n",
    "    dictionary_ct = Dictionary(tagged_text_ct)\n",
    "    dictionary_ct.save(dict_ct_name)\n",
    "else:\n",
    "    dictionary_ct = Dictionary.load(dict_ct_name)\n",
    "if not os.path.isfile(dict_mecab_name):\n",
    "    dictionary_mecab = Dictionary(tagged_text_mecab)\n",
    "    dictionary_mecab.save(dict_mecab_name)\n",
    "else:\n",
    "    dictionary_mecab = Dictionary.load(dict_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 419 ms, total: 1.67 s\n",
      "Wall time: 1.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_ct_name = clusteringModelPath + 'corpus_ct.pickled'\n",
    "corpus_mecab_name = clusteringModelPath + 'corpus_mecab.pickled'\n",
    "if not os.path.isfile(corpus_ct_name):\n",
    "    corpus_ct = [ dictionary_ct.doc2bow(text) for text in tqdm(tagged_text_ct)]\n",
    "    pickle.dump(corpus_ct, open(corpus_ct_name, 'wb'))\n",
    "else:\n",
    "    corpus_ct = pickle.load(open(corpus_ct_name, 'rb'))\n",
    "if not os.path.isfile(corpus_mecab_name):\n",
    "    corpus_mecab = [ dictionary_mecab.doc2bow(text) for text in tqdm(tagged_text_mecab)]\n",
    "    pickle.dump(corpus_mecab, open(corpus_mecab_name, 'wb'))\n",
    "else:\n",
    "    corpus_mecab = pickle.load(open(corpus_mecab_name, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 98356\n",
      "Number of documents: 24492\n",
      "Number of unique tokens: 102314\n",
      "Number of documents: 24492\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary_ct))\n",
    "print('Number of documents: %d' % len(corpus_ct))\n",
    "print('Number of unique tokens: %d' % len(dictionary_mecab))\n",
    "print('Number of documents: %d' % len(corpus_mecab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI (  Latent Semantic Indexing )\n",
    "* an indexing and retrieval method that uses a mathematical technique called singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 372 ms, sys: 125 ms, total: 497 ms\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lsimodel_ct_name = clusteringModelPath + 'lsimodel_ct'\n",
    "lsimodel_mecab_name = clusteringModelPath + 'lsimidel_mecab'\n",
    "if not os.path.isfile(lsimodel_ct_name):\n",
    "    lsimodel_ct = LsiModel(corpus = corpus_ct, num_topics = 20, id2word = dictionary_ct)\n",
    "    lsimodel_ct.save(lsimodel_ct_name)\n",
    "else:\n",
    "    lsimodel_ct = LsiModel.load(lsimodel_ct_name)\n",
    "if not os.path.isfile(lsimodel_mecab_name):\n",
    "    lsimodel_mecab = LsiModel(corpus = corpus_mecab, num_topics = 20, id2word = dictionary_mecab)\n",
    "    lsimodel_mecab.save(lsimodel_mecab_name)\n",
    "else:\n",
    "    lsimodel_mecab = LsiModel.load(lsimodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.240*\"대통령\" + 0.238*\"선수\" + 0.231*\"경기\" + 0.228*\"한국\" + 0.155*\"정부\" + 0.151*\"중국\" + 0.150*\"서울\" + 0.149*\"미국\" + 0.145*\"적인\" + 0.138*\"감독\"'),\n",
       " (1,\n",
       "  '-0.424*\"대통령\" + 0.379*\"경기\" + 0.354*\"선수\" + 0.212*\"득점\" + 0.203*\"감독\" + -0.163*\"정부\" + 0.139*\"기록\" + 0.118*\"리그\" + -0.109*\"중국\" + -0.106*\"미국\"'),\n",
       " (2,\n",
       "  '-0.874*\"게임\" + 0.178*\"대통령\" + -0.170*\"동아\" + -0.168*\"출처\" + -0.142*\"쉘룡\" + -0.108*\"딴지\" + -0.091*\"출시\" + -0.088*\"개발\" + -0.068*\"국산\" + 0.050*\"경기\"'),\n",
       " (3,\n",
       "  '-0.622*\"대통령\" + -0.210*\"게임\" + 0.166*\"거래\" + 0.155*\"가상화폐\" + -0.149*\"경기\" + 0.144*\"비트코인\" + -0.125*\"검찰\" + 0.121*\"한국\" + 0.117*\"시장\" + -0.113*\"득점\"'),\n",
       " (4,\n",
       "  '-0.459*\"중국\" + -0.365*\"북한\" + -0.267*\"미국\" + -0.244*\"한국\" + 0.173*\"서울\" + 0.167*\"의원\" + -0.150*\"선수\" + 0.149*\"검찰\" + -0.135*\"일본\" + 0.134*\"수사\"'),\n",
       " (5,\n",
       "  '-0.503*\"선수\" + 0.360*\"득점\" + 0.229*\"경기\" + 0.202*\"중국\" + -0.174*\"계약\" + -0.133*\"구단\" + -0.130*\"감독\" + 0.124*\"북한\" + 0.117*\"쿼터\" + 0.112*\"리바운드\"'),\n",
       " (6,\n",
       "  '-0.289*\"대통령\" + -0.280*\"거래\" + -0.279*\"가상화폐\" + 0.275*\"대표\" + 0.266*\"의원\" + -0.246*\"비트코인\" + 0.193*\"통합\" + -0.180*\"거래소\" + 0.168*\"북한\" + -0.150*\"선수\"'),\n",
       " (7,\n",
       "  '-0.375*\"대표\" + -0.357*\"의원\" + -0.277*\"통합\" + -0.192*\"국민의당\" + -0.169*\"가상화폐\" + -0.168*\"정당\" + -0.159*\"거래\" + -0.147*\"정부\" + 0.139*\"경찰\" + -0.132*\"비트코인\"'),\n",
       " (8,\n",
       "  '-0.418*\"한국\" + -0.297*\"감독\" + 0.233*\"북한\" + 0.219*\"미국\" + -0.210*\"일본\" + 0.181*\"계약\" + 0.175*\"선수\" + -0.140*\"중국\" + 0.129*\"트럼프\" + -0.125*\"축구\"'),\n",
       " (9,\n",
       "  '0.542*\"북한\" + -0.271*\"아이폰\" + -0.265*\"애플\" + -0.184*\"대통령\" + -0.177*\"한국\" + -0.134*\"배터리\" + 0.127*\"경찰\" + 0.125*\"거래\" + 0.122*\"가상화폐\" + 0.122*\"수사\"'),\n",
       " (10,\n",
       "  '-0.398*\"중국\" + -0.298*\"김현정\" + 0.273*\"서울\" + -0.238*\"검찰\" + -0.212*\"수사\" + -0.172*\"아이폰\" + -0.166*\"의원\" + -0.165*\"애플\" + 0.153*\"정부\" + -0.131*\"검사\"'),\n",
       " (11,\n",
       "  '0.447*\"중국\" + -0.304*\"김현정\" + -0.221*\"아이폰\" + -0.214*\"애플\" + -0.209*\"미국\" + -0.196*\"북한\" + -0.190*\"감독\" + 0.188*\"서울\" + -0.120*\"트럼프\" + 0.119*\"계약\"'),\n",
       " (12,\n",
       "  '0.692*\"김현정\" + -0.212*\"검찰\" + -0.177*\"수사\" + -0.147*\"아이폰\" + -0.146*\"애플\" + -0.144*\"감독\" + -0.142*\"북한\" + -0.120*\"혐의\" + -0.117*\"검사\" + 0.103*\"득점\"'),\n",
       " (13,\n",
       "  '0.412*\"한국\" + -0.385*\"중국\" + 0.253*\"득점\" + 0.242*\"일본\" + -0.170*\"감독\" + 0.159*\"쿼터\" + -0.158*\"손흥민\" + -0.157*\"토트넘\" + 0.147*\"리바운드\" + -0.142*\"시티\"'),\n",
       " (14,\n",
       "  '-0.303*\"정부\" + -0.247*\"아이폰\" + -0.241*\"김현정\" + -0.230*\"애플\" + -0.164*\"북한\" + 0.157*\"비트코인\" + -0.156*\"서울\" + 0.156*\"미국\" + 0.153*\"방송\" + 0.143*\"트럼프\"'),\n",
       " (15,\n",
       "  '0.359*\"감독\" + -0.264*\"미국\" + 0.188*\"아이폰\" + 0.175*\"득점\" + -0.172*\"기록\" + -0.171*\"한국\" + -0.168*\"손흥민\" + 0.166*\"애플\" + -0.149*\"경기\" + 0.148*\"중국\"'),\n",
       " (16,\n",
       "  '0.354*\"미국\" + 0.284*\"서울\" + 0.240*\"트럼프\" + 0.209*\"감독\" + 0.177*\"김현정\" + -0.175*\"북한\" + 0.171*\"지역\" + -0.161*\"일본\" + 0.159*\"이스라엘\" + 0.143*\"예루살렘\"'),\n",
       " (17,\n",
       "  '-0.312*\"감독\" + 0.304*\"서울\" + -0.241*\"정부\" + 0.207*\"한국\" + 0.189*\"비트코인\" + 0.148*\"아이폰\" + -0.148*\"기술\" + -0.133*\"미국\" + -0.129*\"기업\" + 0.124*\"정현\"'),\n",
       " (18,\n",
       "  '-0.338*\"만원\" + 0.253*\"정부\" + -0.212*\"북한\" + 0.196*\"화재\" + 0.175*\"사고\" + 0.163*\"일본\" + -0.160*\"비트코인\" + -0.153*\"가격\" + 0.146*\"경찰\" + 0.142*\"현장\"'),\n",
       " (19,\n",
       "  '0.421*\"만원\" + -0.332*\"기술\" + -0.170*\"서울\" + 0.158*\"아이폰\" + 0.140*\"트럼프\" + -0.134*\"시장\" + 0.131*\"인상\" + 0.128*\"애플\" + 0.117*\"최저임금\" + -0.114*\"로봇\"')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsimodel_ct.show_topics(num_topics = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.292*\"대통령\" + 0.249*\"선수\" + 0.213*\"한국\" + 0.209*\"경기\" + 0.175*\"정부\" + 0.169*\"중국\" + 0.163*\"미국\" + 0.146*\"서울\" + 0.143*\"대표\" + 0.139*\"감독\"'),\n",
       " (1,\n",
       "  '0.415*\"대통령\" + -0.408*\"선수\" + -0.389*\"경기\" + -0.220*\"감독\" + -0.199*\"득점\" + 0.148*\"정부\" + -0.144*\"기록\" + -0.111*\"리그\" + 0.100*\"청와대\" + 0.098*\"검찰\"'),\n",
       " (2,\n",
       "  '-0.600*\"대통령\" + 0.207*\"게임\" + 0.169*\"가상화폐\" + -0.163*\"경기\" + 0.146*\"중국\" + 0.140*\"비트코인\" + -0.135*\"검찰\" + 0.133*\"시장\" + 0.131*\"한국\" + -0.129*\"청와대\"'),\n",
       " (3,\n",
       "  '-0.490*\"중국\" + -0.356*\"북한\" + -0.275*\"미국\" + 0.212*\"의원\" + -0.187*\"한국\" + 0.179*\"게임\" + 0.168*\"대표\" + 0.155*\"서울\" + 0.150*\"검찰\" + 0.139*\"수사\"'),\n",
       " (4,\n",
       "  '-0.840*\"게임\" + -0.196*\"출처\" + -0.160*\"대통령\" + -0.127*\"꿀딴지\" + 0.111*\"가상화폐\" + -0.105*\"개발\" + -0.099*\"출시\" + 0.093*\"정부\" + -0.088*\"소개\" + 0.084*\"서울\"'),\n",
       " (5,\n",
       "  '0.452*\"선수\" + -0.367*\"득점\" + -0.303*\"경기\" + 0.215*\"대표\" + 0.169*\"계약\" + -0.140*\"시티\" + -0.136*\"가상화폐\" + -0.128*\"기록\" + 0.126*\"의원\" + 0.113*\"구단\"'),\n",
       " (6,\n",
       "  '-0.343*\"대표\" + -0.303*\"의원\" + 0.288*\"선수\" + 0.256*\"가상화폐\" + 0.251*\"대통령\" + -0.215*\"통합\" + 0.201*\"비트코인\" + 0.176*\"계약\" + -0.172*\"북한\" + -0.171*\"중국\"'),\n",
       " (7,\n",
       "  '-0.331*\"대표\" + -0.275*\"가상화폐\" + -0.248*\"의원\" + -0.205*\"통합\" + -0.204*\"비트코인\" + 0.167*\"경찰\" + -0.163*\"거래소\" + 0.156*\"수사\" + -0.147*\"거래\" + -0.141*\"정부\"'),\n",
       " (8,\n",
       "  '-0.360*\"한국\" + -0.252*\"감독\" + -0.251*\"중국\" + 0.201*\"미국\" + -0.201*\"일본\" + -0.178*\"검찰\" + -0.171*\"수사\" + -0.171*\"가상화폐\" + 0.163*\"북한\" + 0.151*\"계약\"'),\n",
       " (9,\n",
       "  '0.509*\"북한\" + -0.249*\"한국\" + -0.206*\"대통령\" + 0.174*\"가상화폐\" + 0.170*\"김현정\" + 0.170*\"수사\" + 0.167*\"검찰\" + -0.155*\"임금\" + -0.128*\"감독\" + 0.121*\"의원\"'),\n",
       " (10,\n",
       "  '-0.386*\"중국\" + 0.345*\"김현정\" + 0.259*\"북한\" + -0.185*\"검찰\" + -0.183*\"애플\" + -0.163*\"수사\" + 0.162*\"임금\" + 0.161*\"감독\" + 0.160*\"정부\" + -0.150*\"의원\"'),\n",
       " (11,\n",
       "  '0.746*\"김현정\" + 0.287*\"중국\" + -0.200*\"북한\" + -0.168*\"감독\" + -0.163*\"서울\" + 0.122*\"말씀\" + 0.105*\"득점\" + 0.100*\"정두언\" + 0.093*\"의원\" + 0.085*\"시장\"'),\n",
       " (12,\n",
       "  '-0.346*\"중국\" + 0.289*\"미국\" + -0.240*\"임금\" + -0.239*\"정부\" + 0.234*\"애플\" + -0.190*\"최저\" + 0.183*\"아이폰\" + -0.179*\"서울\" + 0.163*\"트럼프\" + -0.156*\"인상\"'),\n",
       " (13,\n",
       "  '0.255*\"애플\" + -0.216*\"중국\" + 0.196*\"아이폰\" + 0.170*\"검찰\" + -0.169*\"방송\" + 0.160*\"한국\" + 0.158*\"수사\" + 0.158*\"임금\" + 0.157*\"김현정\" + 0.149*\"북한\"'),\n",
       " (14,\n",
       "  '-0.363*\"한국\" + -0.332*\"득점\" + -0.260*\"일본\" + 0.257*\"중국\" + 0.211*\"감독\" + -0.195*\"쿼터\" + 0.187*\"손흥민\" + 0.179*\"토트넘\" + -0.179*\"리바운드\" + 0.176*\"시티\"'),\n",
       " (15,\n",
       "  '-0.346*\"감독\" + 0.235*\"미국\" + 0.211*\"한국\" + -0.200*\"득점\" + -0.199*\"애플\" + 0.165*\"기록\" + 0.160*\"손흥민\" + -0.159*\"아이폰\" + 0.144*\"일본\" + 0.132*\"의원\"'),\n",
       " (16,\n",
       "  '-0.366*\"임금\" + -0.305*\"미국\" + -0.279*\"최저\" + -0.216*\"인상\" + 0.202*\"정부\" + -0.196*\"트럼프\" + 0.192*\"서울\" + 0.174*\"일본\" + 0.171*\"애플\" + -0.156*\"감독\"'),\n",
       " (17,\n",
       "  '-0.368*\"서울\" + -0.204*\"지역\" + -0.178*\"미국\" + -0.161*\"트럼프\" + -0.155*\"김현정\" + -0.135*\"정현\" + 0.134*\"방송\" + 0.131*\"북한\" + 0.130*\"임금\" + -0.127*\"이스라엘\"'),\n",
       " (18,\n",
       "  '-0.278*\"서울\" + -0.270*\"비트코인\" + 0.248*\"기술\" + 0.224*\"정부\" + -0.197*\"애플\" + -0.195*\"한국\" + -0.168*\"아이폰\" + -0.165*\"북한\" + -0.164*\"가격\" + 0.161*\"감독\"'),\n",
       " (19,\n",
       "  '0.250*\"시장\" + -0.217*\"애플\" + 0.209*\"기술\" + -0.179*\"사고\" + -0.175*\"화재\" + -0.175*\"아이폰\" + 0.174*\"서울\" + -0.146*\"가상화폐\" + -0.142*\"임금\" + -0.134*\"경찰\"')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsimodel_mecab.show_topics(num_topics = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsitopics_ct = lsimodel_ct.show_topics(formatted = False)\n",
    "lsitopics_mecab = lsimodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP (Hierarchical Dirichlet Process)\n",
    "* a non-parametric bayesian method (note the missing number of requested topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 s, sys: 1.5 s, total: 3.54 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hdpmodel_ct_name = clusteringModelPath+'hdpmodel_ct'\n",
    "hdpmodel_mecab_name = clusteringModelPath+'hdpmodel_mecab'\n",
    "if not os.path.isfile(hdpmodel_ct_name):\n",
    "    hdpmodel_ct = HdpModel(corpus = corpus_ct, id2word = dictionary_ct)\n",
    "    hdpmodel_ct.save(clusteringModelPath+'hdpmodel_ct')\n",
    "else:\n",
    "    hdpmodel_ct = HdpModel.load(hdpmodel_ct_name)\n",
    "if not os.path.isfile(hdpmodel_mecab_name):\n",
    "    hdpmodel_mecab = HdpModel(corpus = corpus_mecab, id2word = dictionary_mecab)\n",
    "    hdpmodel_mecab.save(clusteringModelPath+'hdpmodel_mecab')\n",
    "else:\n",
    "    hdpmodel_mecab = HdpModel.load(hdpmodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.004*선수 + 0.004*한국 + 0.004*서울 + 0.003*사진 + 0.003*적인 + 0.003*경기 + 0.003*대통령 + 0.003*미국 + 0.002*금지 + 0.002*중국 + 0.002*감독 + 0.002*정부 + 0.002*12 + 0.002*배포 + 0.002*무단 + 0.002*상황 + 0.002*대표 + 0.002*모습 + 0.002*20 + 0.002*전재'),\n",
       " (1,\n",
       "  '0.007*대통령 + 0.005*정부 + 0.005*서울 + 0.005*북한 + 0.004*한국 + 0.003*중국 + 0.003*미국 + 0.003*사진 + 0.003*금지 + 0.003*적인 + 0.002*배포 + 0.002*무단 + 0.002*검찰 + 0.002*전재 + 0.002*12 + 0.002*대표 + 0.002*상황 + 0.002*혐의 + 0.002*조사 + 0.002*자들'),\n",
       " (2,\n",
       "  '0.020*경기 + 0.013*손흥민 + 0.011*토트넘 + 0.010*감독 + 0.010*선수 + 0.008*한국 + 0.007*기록 + 0.006*맨유 + 0.006*리그 + 0.005*케인 + 0.005*2017 + 0.005*전반 + 0.005*이적 + 0.005*공격 + 0.005*득점 + 0.005*맨체스터 + 0.005*맨시티 + 0.004*축구 + 0.004*레알 + 0.004*라운드'),\n",
       " (3,\n",
       "  '0.005*미국 + 0.005*북한 + 0.004*중국 + 0.004*정부 + 0.004*한국 + 0.004*예산 + 0.004*인상 + 0.003*지진 + 0.003*서울 + 0.003*대통령 + 0.003*규모 + 0.003*예산안 + 0.003*달러 + 0.003*원내대표 + 0.003*적인 + 0.003*의원 + 0.003*금지 + 0.003*금리 + 0.002*합의 + 0.002*경제'),\n",
       " (4,\n",
       "  '0.026*영하 + 0.026*서울 + 0.023*기온 + 0.019*날씨 + 0.015*한파 + 0.015*추위 + 0.013*아침 + 0.012*전국 + 0.010*지역 + 0.007*도로 + 0.007*미세먼지 + 0.006*대구 + 0.006*강원 + 0.006*호남 + 0.006*대부분 + 0.005*최고 + 0.005*지방 + 0.005*바람 + 0.005*중부 + 0.005*건조'),\n",
       " (5,\n",
       "  '0.005*의원 + 0.004*김현정 + 0.003*서울 + 0.003*정부 + 0.003*교수 + 0.002*한국 + 0.002*외상 + 0.002*금지 + 0.002*센터 + 0.002*정책 + 0.002*배포 + 0.002*원내대표 + 0.002*무단 + 0.002*방송 + 0.002*국회 + 0.002*학교 + 0.002*전재 + 0.002*환자 + 0.002*상황 + 0.002*예산'),\n",
       " (6,\n",
       "  '0.004*선수 + 0.004*한국 + 0.003*감독 + 0.003*경기 + 0.003*무단 + 0.003*영화 + 0.002*SK텔레콤 + 0.002*교수 + 0.002*서울 + 0.002*연구 + 0.002*미국 + 0.002*기록 + 0.002*금지 + 0.002*상태 + 0.002*배포 + 0.002*전재 + 0.002*적인 + 0.002*롯데 + 0.002*경제 + 0.002*올림픽'),\n",
       " (7,\n",
       "  '0.004*선수 + 0.004*한국 + 0.003*리그 + 0.003*식당 + 0.003*리즈 + 0.003*배우 + 0.003*로사리오 + 0.003*LG + 0.002*기록 + 0.002*투수 + 0.002*방송 + 0.002*사진 + 0.002*모습 + 0.002*보기 + 0.002*배포 + 0.002*무단 + 0.002*금지 + 0.002*전재 + 0.002*계약 + 0.002*오타니'),\n",
       " (8,\n",
       "  '0.009*사고 + 0.006*해경 + 0.005*낚싯배 + 0.005*인천 + 0.005*구조 + 0.004*상황 + 0.004*선창 + 0.003*급유선 + 0.003*대통령 + 0.003*전복 + 0.003*선장 + 0.003*영흥도 + 0.003*15 + 0.003*서울 + 0.003*해상 + 0.003*충돌 + 0.002*김현정 + 0.002*미국 + 0.002*산불 + 0.002*북한'),\n",
       " (9,\n",
       "  '0.008*사고 + 0.007*해경 + 0.005*낚싯배 + 0.005*인천 + 0.005*선창 + 0.004*구조 + 0.004*선장 + 0.004*급유선 + 0.003*해상 + 0.003*15 + 0.003*현장 + 0.003*충돌 + 0.003*미국 + 0.003*영흥도 + 0.002*전복 + 0.002*수색 + 0.002*대통령 + 0.002*명진 + 0.002*12 + 0.002*트럼프'),\n",
       " (10,\n",
       "  '0.004*사진 + 0.004*비트코인 + 0.004*북한 + 0.004*미국 + 0.003*가상화폐 + 0.003*한국 + 0.003*투자 + 0.003*훈련 + 0.002*22 + 0.002*서울 + 0.002*무단 + 0.002*금지 + 0.002*배포 + 0.002*18 + 0.002*동사 + 0.002*촬영 + 0.002*교수 + 0.002*적인 + 0.001*논문 + 0.001*상황'),\n",
       " (11,\n",
       "  '0.003*고용 + 0.003*파리바게뜨 + 0.003*직접 + 0.002*임신 + 0.002*사진 + 0.002*물가 + 0.002*서울 + 0.002*낙태죄 + 0.002*상승 + 0.002*제빵 + 0.002*사장 + 0.002*금지 + 0.002*여성 + 0.001*무단 + 0.001*노조 + 0.001*교수 + 0.001*방송 + 0.001*12 + 0.001*배포 + 0.001*조사'),\n",
       " (12,\n",
       "  '0.002*감독 + 0.002*결혼 + 0.002*일본 + 0.002*머리 + 0.002*촉새 + 0.002*아스널 + 0.001*적인 + 0.001*줄리아 + 0.001*한국 + 0.001*무리뉴 + 0.001*왕실 + 0.001*금지 + 0.001*단장 + 0.001*피부 + 0.001*중국 + 0.001*선수 + 0.001*기술 + 0.001*이구 + 0.001*무단 + 0.001*배포'),\n",
       " (13,\n",
       "  '0.007*트럼프 + 0.004*대통령 + 0.004*플린 + 0.003*이스라엘 + 0.003*미국 + 0.003*정부 + 0.003*러시아 + 0.002*예루살렘 + 0.002*수용 + 0.002*달러 + 0.002*개발 + 0.002*지역 + 0.002*특검 + 0.002*주민 + 0.002*쿠슈너 + 0.002*백악관 + 0.002*지구 + 0.001*진술 + 0.001*접촉 + 0.001*중동'),\n",
       " (14,\n",
       "  '0.004*검찰 + 0.003*영어 + 0.003*할인 + 0.002*의원 + 0.002*멤버십 + 0.002*수사 + 0.002*수업 + 0.002*금지 + 0.002*서울 + 0.002*혐의 + 0.002*한국 + 0.002*특수 + 0.002*조사 + 0.002*국정원 + 0.002*경찰 + 0.002*사건 + 0.002*특활비 + 0.002*만원 + 0.001*방과후 + 0.001*혜택'),\n",
       " (15,\n",
       "  '0.009*북한 + 0.008*화성 + 0.007*15 + 0.006*발사 + 0.005*미국 + 0.004*훈련 + 0.004*미사일 + 0.003*공군 + 0.003*기술 + 0.002*한국 + 0.002*엔진 + 0.002*한미 + 0.002*14 + 0.002*22 + 0.002*비행 + 0.002*타격 + 0.002*연합 + 0.002*분석 + 0.002*지방 + 0.002*압박'),\n",
       " (16,\n",
       "  '0.004*러시아 + 0.004*비트코인 + 0.003*선수 + 0.003*세계 + 0.002*도핑 + 0.002*삼성 + 0.002*정성훈 + 0.002*미국 + 0.002*11 + 0.002*수당 + 0.002*아동 + 0.002*중국 + 0.002*스포츠 + 0.001*러시 + 0.001*금지 + 0.001*정부 + 0.001*올림픽 + 0.001*구단 + 0.001*한국 + 0.001*00'),\n",
       " (17,\n",
       "  '0.005*로봇 + 0.004*펄서 + 0.003*연구 + 0.002*바퀴 + 0.002*혐의 + 0.002*수석 + 0.002*우주 + 0.002*적인 + 0.002*기술 + 0.002*블랙홀 + 0.002*교수 + 0.001*발견 + 0.001*중력파 + 0.001*자들 + 0.001*염기 + 0.001*분야 + 0.001*시스템 + 0.001*개발 + 0.001*검찰 + 0.001*구속영장'),\n",
       " (18,\n",
       "  '0.003*리그 + 0.003*규제 + 0.003*LG + 0.003*포털 + 0.003*롯데 + 0.003*선수 + 0.002*경기 + 0.002*허프 + 0.002*계약 + 0.002*가와사키 + 0.002*린드블럼 + 0.002*재계약 + 0.002*리즈 + 0.002*외국인 + 0.002*일본 + 0.002*투수 + 0.002*정성룡 + 0.002*두산 + 0.001*구단 + 0.001*협상'),\n",
       " (19,\n",
       "  '0.009*한국 + 0.007*월드컵 + 0.005*독일 + 0.004*포트 + 0.004*감독 + 0.004*러시아 + 0.004*스페인 + 0.003*경기 + 0.003*16 + 0.003*멕시코 + 0.003*본선 + 0.003*스웨덴 + 0.002*일본 + 0.002*상대 + 0.002*대회 + 0.002*축구 + 0.002*선수 + 0.002*랭킹 + 0.002*손흥민 + 0.002*신태용')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdpmodel_ct.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*대통령 + 0.005*서울 + 0.004*정부 + 0.003*미국 + 0.003*중국 + 0.003*사진 + 0.003*한국 + 0.003*대표 + 0.003*금지 + 0.003*가능 + 0.002*무단 + 0.002*조사 + 0.002*북한 + 0.002*의원 + 0.002*재배포 + 0.002*시장 + 0.002*전재 + 0.002*상황 + 0.002*검찰 + 0.002*경찰'),\n",
       " (1,\n",
       "  '0.013*선수 + 0.010*경기 + 0.007*감독 + 0.007*한국 + 0.005*계약 + 0.005*기록 + 0.004*사진 + 0.003*손흥민 + 0.003*리그 + 0.003*대표 + 0.003*모습 + 0.003*구단 + 0.003*상황 + 0.003*정현 + 0.003*일본 + 0.003*방송 + 0.003*가능 + 0.002*토트넘 + 0.002*영입 + 0.002*우승'),\n",
       " (2,\n",
       "  '0.005*방송 + 0.004*무단 + 0.004*화유기 + 0.003*금지 + 0.003*사건 + 0.003*재배포 + 0.003*서울 + 0.003*드라마 + 0.003*영화 + 0.003*전재 + 0.002*사진 + 0.002*수사 + 0.002*손오공 + 0.002*혐의 + 0.002*사용 + 0.002*배우 + 0.002*진선미 + 0.002*SK텔레콤 + 0.002*검찰 + 0.002*이유'),\n",
       " (3,\n",
       "  '0.008*한국 + 0.006*경기 + 0.006*감독 + 0.005*선수 + 0.005*맨유 + 0.004*호날두 + 0.004*월드컵 + 0.004*레알 + 0.004*독일 + 0.003*영입 + 0.003*마드리드 + 0.003*사진 + 0.003*기록 + 0.003*네이마르 + 0.003*스페인 + 0.003*금지 + 0.003*코치 + 0.002*무단 + 0.002*상대 + 0.002*재배포'),\n",
       " (4,\n",
       "  '0.003*서울 + 0.003*교수 + 0.003*한국 + 0.003*사진 + 0.002*금지 + 0.002*증가 + 0.002*연구 + 0.002*발생 + 0.002*오타니 + 0.002*재배포 + 0.002*무단 + 0.002*선수 + 0.002*경기 + 0.002*전재 + 0.002*지진 + 0.002*소득 + 0.002*달러 + 0.002*기록 + 0.002*미국 + 0.002*가능'),\n",
       " (5,\n",
       "  '0.029*영하 + 0.028*서울 + 0.027*기온 + 0.022*날씨 + 0.018*한파 + 0.015*아침 + 0.015*추위 + 0.014*전국 + 0.011*지역 + 0.008*지방 + 0.007*특보 + 0.007*서해안 + 0.007*중부 + 0.007*건조 + 0.007*도로 + 0.007*미세먼지 + 0.007*대구 + 0.007*시작 + 0.007*호남 + 0.007*최고'),\n",
       " (6,\n",
       "  '0.004*미국 + 0.004*서울 + 0.004*김현정 + 0.004*대통령 + 0.003*택시 + 0.003*정부 + 0.003*이국종 + 0.002*금지 + 0.002*이스라엘 + 0.002*무단 + 0.002*트럼프 + 0.002*최승호 + 0.002*예루살렘 + 0.002*재배포 + 0.002*전재 + 0.002*조사 + 0.002*북한 + 0.002*교수 + 0.002*지역 + 0.002*대표'),\n",
       " (7,\n",
       "  '0.006*계약 + 0.005*한국 + 0.004*선수 + 0.004*롯데 + 0.004*일본 + 0.004*린드블럼 + 0.003*감독 + 0.003*경기 + 0.003*로사리오 + 0.003*구단 + 0.003*투수 + 0.003*협상 + 0.003*달러 + 0.002*북한 + 0.002*리즈 + 0.002*미국 + 0.002*리그 + 0.002*금지 + 0.002*외국인 + 0.002*규제'),\n",
       " (8,\n",
       "  '0.014*북한 + 0.008*발사 + 0.008*화성 + 0.008*미국 + 0.006*미사일 + 0.006*중국 + 0.004*가능 + 0.002*기술 + 0.002*한국 + 0.002*정보 + 0.002*압박 + 0.002*금지 + 0.002*대북 + 0.002*화장실 + 0.002*평가 + 0.002*사용 + 0.002*제재 + 0.002*재진입 + 0.002*분석 + 0.002*보도'),\n",
       " (9,\n",
       "  '0.004*대통령 + 0.004*미국 + 0.004*교수 + 0.003*사진 + 0.003*서울 + 0.002*로봇 + 0.002*음악 + 0.002*방탄소년단 + 0.002*시장 + 0.002*트럼프 + 0.002*북한 + 0.002*연구 + 0.002*상황 + 0.001*그룹 + 0.001*스마트폰 + 0.001*분석 + 0.001*정부 + 0.001*한국 + 0.001*시작 + 0.001*대표'),\n",
       " (10,\n",
       "  '0.003*영하 + 0.003*서울 + 0.002*탈모 + 0.002*사진 + 0.002*북한 + 0.002*금지 + 0.002*조사 + 0.002*기온 + 0.002*무단 + 0.002*재배포 + 0.002*전재 + 0.002*배터리 + 0.002*모습 + 0.002*미국 + 0.002*백제 + 0.001*혐의 + 0.001*지진 + 0.001*강정호 + 0.001*날씨 + 0.001*지역'),\n",
       " (11,\n",
       "  '0.008*북한 + 0.006*주택 + 0.004*중국 + 0.004*미국 + 0.004*대통령 + 0.003*훈련 + 0.003*연금 + 0.003*에너지 + 0.003*주거 + 0.002*가능 + 0.002*서울 + 0.002*공군 + 0.002*임대 + 0.002*정부 + 0.002*매입 + 0.002*전투기 + 0.002*셰어하우스 + 0.002*한반도 + 0.002*트럼프 + 0.002*한미'),\n",
       " (12,\n",
       "  '0.003*브로드컴 + 0.003*인수 + 0.003*선수 + 0.003*미국 + 0.002*퀄컴 + 0.002*기업 + 0.002*한국 + 0.002*서울 + 0.002*반도체 + 0.002*배우 + 0.002*감독 + 0.002*삼성 + 0.002*트럼프 + 0.002*가능 + 0.002*사업 + 0.002*중국 + 0.002*대통령 + 0.002*야구 + 0.002*스포츠 + 0.001*업계'),\n",
       " (13,\n",
       "  '0.007*가상화폐 + 0.005*투자 + 0.003*김현정 + 0.002*윤계상 + 0.002*서민정 + 0.002*강민호 + 0.002*유포자 + 0.002*선수 + 0.002*롯데 + 0.002*이방인 + 0.002*투자자 + 0.002*소장 + 0.002*미국 + 0.002*비케이 + 0.002*정관용 + 0.002*대통령 + 0.001*정부 + 0.001*한국 + 0.001*사진 + 0.001*거래소'),\n",
       " (14,\n",
       "  '0.010*월드컵 + 0.009*독일 + 0.008*한국 + 0.008*경기 + 0.007*스웨덴 + 0.006*멕시코 + 0.005*감독 + 0.005*상대 + 0.005*선수 + 0.004*러시아 + 0.004*대표 + 0.003*대회 + 0.003*본선 + 0.003*축구 + 0.003*유럽 + 0.002*전술 + 0.002*예선 + 0.002*준비 + 0.002*우승 + 0.002*지진'),\n",
       " (15,\n",
       "  '0.003*특수 + 0.003*검찰 + 0.003*변호사 + 0.002*예루살렘 + 0.002*대통령 + 0.002*이스라엘 + 0.002*활동비 + 0.002*트럼프 + 0.002*미국 + 0.002*조사 + 0.002*국정원 + 0.002*사용 + 0.002*여단 + 0.002*연구 + 0.002*수사 + 0.001*혐의 + 0.001*인정 + 0.001*서울 + 0.001*대사관 + 0.001*이전'),\n",
       " (16,\n",
       "  '0.003*의원 + 0.002*정관용 + 0.002*합의 + 0.002*사고 + 0.002*예산안 + 0.002*공무원 + 0.002*서울 + 0.002*증원 + 0.002*윤민 + 0.002*태연 + 0.002*국가 + 0.002*곽수종 + 0.002*정부 + 0.002*총회 + 0.002*기관사 + 0.002*금지 + 0.002*상황 + 0.002*처리 + 0.002*안진걸 + 0.002*여야'),\n",
       " (17,\n",
       "  '0.006*의원 + 0.005*검찰 + 0.004*혐의 + 0.003*구속 + 0.003*서울 + 0.002*국정원 + 0.002*출석 + 0.002*국회 + 0.002*무한도전 + 0.002*국민 + 0.002*조사 + 0.002*특수 + 0.001*주장 + 0.001*차관 + 0.001*예능 + 0.001*강식당 + 0.001*강호동 + 0.001*최씨 + 0.001*영재센터 + 0.001*사진'),\n",
       " (18,\n",
       "  '0.004*멤버 + 0.004*무한도전 + 0.003*박명수 + 0.003*수능 + 0.003*모습 + 0.002*예산 + 0.002*유재석 + 0.002*조세호 + 0.002*상승 + 0.002*물가 + 0.002*방송 + 0.002*파퀴아오 + 0.002*양세형 + 0.002*영역 + 0.002*공개 + 0.002*코빅 + 0.002*예능 + 0.001*도전 + 0.001*대표 + 0.001*점수'),\n",
       " (19,\n",
       "  '0.004*사진 + 0.002*예루살렘 + 0.002*시민 + 0.002*혐의 + 0.002*트럼프 + 0.002*촬영 + 0.002*사진첩 + 0.002*대통령 + 0.002*이스라엘 + 0.001*한국 + 0.001*할머니 + 0.001*계엄군 + 0.001*금지 + 0.001*어머니 + 0.001*수도 + 0.001*대사관 + 0.001*미국 + 0.001*조사 + 0.001*이유 + 0.001*국제')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdpmodel_mecab.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdptopics_ct = hdpmodel_ct.show_topics(formatted = False)\n",
    "hdptopics_mecab = hdpmodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (Latent Dirichlet allocation)\n",
    "* a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA model1\n",
    "* basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ct = PerplexityMetric(corpus = corpus_ct, logger = 'shell', \n",
    "                        title = 'Perplexity (twitter)')\n",
    "ch_umass_ct = CoherenceMetric(corpus = corpus_ct, coherence = 'u_mass', \n",
    "                             logger = 'shell', title = ' Coherence (u_mass)')\n",
    "ch_cv_ct = CoherenceMetric(corpus = corpus_ct, logger = 'shell', \n",
    "                          texts = tagged_text_ct, coherence = 'c_v', \n",
    "                          title = 'Coherence (c_v)')\n",
    "diff_kl_ct = DiffMetric(distance = 'kullback_leibler', \n",
    "                       logger = 'shell', title = 'Diff (kullback_leibler)')\n",
    "convergence_kl_ct = ConvergenceMetric(distance = 'jaccard', logger = 'shell', \n",
    "                                     title = 'Convergence (jaccard)')\n",
    "callbacks_ct = [pl_ct, ch_umass_ct, ch_cv_ct, diff_kl_ct, convergence_kl_ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:using autotuned alpha, starting with [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.05\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (multi-pass) LDA training, 20 topics, 50 passes over the supplied corpus of 24492 documents, updating model once every 12246 documents, evaluating perplexity every 24492 documents, iterating 200x with a convergence threshold of 0.001000\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #12246/24492\n",
      "INFO:gensim.models.ldamodel:optimized alpha [0.04113103, 0.044442922, 0.041740872, 0.042542383, 0.04247296, 0.04590621, 0.036615603, 0.042415425, 0.040266722, 0.03936632, 0.041400168, 0.044339057, 0.04098651, 0.041123882, 0.04512896, 0.04370206, 0.043665458, 0.041070648, 0.039178677, 0.038598057]\n",
      "INFO:gensim.models.ldamodel:merging changes from 12246 documents into a model of 24492 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.037): 0.005*\"서울\" + 0.004*\"자들\" + 0.003*\"지역\" + 0.003*\"사진\" + 0.003*\"12\" + 0.003*\"만원\" + 0.003*\"북한\" + 0.002*\"연구\" + 0.002*\"부산\" + 0.002*\"2018\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.039): 0.005*\"북한\" + 0.005*\"미국\" + 0.004*\"서울\" + 0.003*\"발사\" + 0.003*\"화성\" + 0.003*\"적인\" + 0.003*\"15\" + 0.003*\"사진\" + 0.003*\"경기\" + 0.002*\"금지\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.044): 0.006*\"대표\" + 0.004*\"한국\" + 0.004*\"서울\" + 0.004*\"금지\" + 0.004*\"중국\" + 0.003*\"손흥민\" + 0.003*\"미국\" + 0.003*\"정부\" + 0.003*\"적인\" + 0.003*\"무단\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.045): 0.007*\"한국\" + 0.007*\"북한\" + 0.005*\"사진\" + 0.004*\"일본\" + 0.004*\"경찰\" + 0.004*\"정부\" + 0.004*\"금지\" + 0.004*\"서울\" + 0.004*\"경기\" + 0.003*\"배포\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.046): 0.006*\"서울\" + 0.005*\"한국\" + 0.004*\"게임\" + 0.004*\"무단\" + 0.003*\"금지\" + 0.003*\"배포\" + 0.003*\"보기\" + 0.003*\"전재\" + 0.003*\"대표\" + 0.003*\"계약\"\n",
      "INFO:gensim.models.ldamodel:topic diff=14.667729, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:-9.741 per-word bound, 855.8 perplexity estimate based on a held-out corpus of 12246 documents with 2384177 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #24492/24492\n",
      "INFO:gensim.models.ldamodel:optimized alpha [0.04185968, 0.043578885, 0.039456453, 0.041383218, 0.0433336, 0.047433816, 0.034794413, 0.041940827, 0.03890001, 0.04600085, 0.03914895, 0.04470354, 0.0379265, 0.03894248, 0.04916478, 0.040734597, 0.042614214, 0.04065841, 0.037093733, 0.036146842]\n",
      "INFO:gensim.models.ldamodel:merging changes from 12246 documents into a model of 24492 documents\n",
      "INFO:gensim.models.ldamodel:topic #6 (0.035): 0.005*\"자들\" + 0.005*\"서울\" + 0.005*\"사진\" + 0.004*\"화재\" + 0.004*\"모습\" + 0.003*\"지역\" + 0.003*\"공개\" + 0.003*\"생활\" + 0.003*\"민박\" + 0.003*\"참사\"\n",
      "INFO:gensim.models.ldamodel:topic #19 (0.036): 0.005*\"미국\" + 0.004*\"북한\" + 0.003*\"사진\" + 0.003*\"방송\" + 0.003*\"환자\" + 0.003*\"서울\" + 0.003*\"발사\" + 0.003*\"적인\" + 0.003*\"15\" + 0.003*\"훈련\"\n",
      "INFO:gensim.models.ldamodel:topic #9 (0.046): 0.021*\"선수\" + 0.014*\"경기\" + 0.007*\"정현\" + 0.007*\"감독\" + 0.007*\"계약\" + 0.006*\"한국\" + 0.005*\"기록\" + 0.005*\"리그\" + 0.004*\"구단\" + 0.004*\"사진\"\n",
      "INFO:gensim.models.ldamodel:topic #5 (0.047): 0.006*\"서울\" + 0.006*\"한국\" + 0.004*\"게임\" + 0.003*\"방송\" + 0.003*\"계약\" + 0.003*\"사진\" + 0.003*\"적인\" + 0.003*\"기록\" + 0.003*\"대표\" + 0.003*\"선수\"\n",
      "INFO:gensim.models.ldamodel:topic #14 (0.049): 0.009*\"한국\" + 0.007*\"사진\" + 0.006*\"감독\" + 0.006*\"북한\" + 0.005*\"일본\" + 0.004*\"방송\" + 0.004*\"모습\" + 0.004*\"영화\" + 0.004*\"베트남\" + 0.003*\"경찰\"\n",
      "INFO:gensim.models.ldamodel:topic diff=1.756664, rho=0.707107\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ldamodel_ct_name = clusteringModelPath + 'ldamodel_ct'\n",
    "if not os.path.isfile(ldamodel_ct_name):\n",
    "    ldamodel_ct = LdaModel( corpus = corpus_ct, num_topics = 20,\n",
    "                           id2word = dictionary_ct, passes = 50,\n",
    "                           chunksize = 12246, iterations = 200,\n",
    "                           alpha='auto', callbacks = callbacks_ct)\n",
    "    ldamodel_ct.save(ldamodel_ct_name)\n",
    "else:\n",
    "    ldamodel_ct = LdaModel.load(ldamodel_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_um_ct_name = clusteringModelPath + 'coherence1_ct_u_mass'\n",
    "if not os.path.isfile(coherence1_um_ct_name):\n",
    "    cm_ct = CoherenceModel(model = ldamodel_ct, \n",
    "                      corpus = corpus_ct, \n",
    "                      dictionary = dictionary_ct,\n",
    "                      coherence = 'u_mass')\n",
    "    cm_ct.save(coherence1_um_ct_name)\n",
    "else:\n",
    "    cm_ct = CoherenceModel.load(coherence1_um_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_ct.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_cv_ct_name = clusteringModelPath + 'coherence1_ct_c_v'\n",
    "if not os.path.isfile(coherence1_cv_ct_name):\n",
    "    cm_ct_cv = CoherenceModel(model = ldamodel_ct, \n",
    "                         texts = tagged_text_ct,\n",
    "                         dictionary = dictionary_ct, \n",
    "                         coherence = 'c_v')\n",
    "    cm_ct_cv.save(coherence1_cv_ct_name)\n",
    "else:\n",
    "    cm_ct_cv = CoherenceModel.load(coherence1_cv_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_ct_cv.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyLDAvis.gensim.prepare(ldamodel_ct, corpus_ct, dictionary_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_ct = ldamodel_ct.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_mecab = PerplexityMetric(corpus = corpus_mecab, logger = 'shell', \n",
    "                           title = 'Perplexity (Mecab)')\n",
    "ch_umass_mecab = CoherenceMetric(corpus = corpus_mecab, coherence = 'u_mass', \n",
    "                             logger = 'shell', title = ' Coherence (u_mass)')\n",
    "ch_cv_mecab = CoherenceMetric(corpus = corpus_mecab, logger = 'shell', \n",
    "                          texts = tagged_text_mecab, coherence = 'c_v', \n",
    "                          title = 'Coherence (c_v)')\n",
    "diff_kl_mecab = DiffMetric(distance = 'kullback_leibler', \n",
    "                       logger = 'shell', title = 'Diff (kullback_leibler)')\n",
    "convergence_kl_mecab = ConvergenceMetric(distance = 'jaccard', logger = 'shell', \n",
    "                                     title = 'Convergence (jaccard)')\n",
    "callbacks_mecab = [pl_mecab, ch_umass_mecab, ch_cv_mecab, diff_kl_mecab, convergence_kl_mecab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ldamodel_mecab_name = clusteringModelPath + 'ldamodel_mecab'\n",
    "if not os.path.isfile(ldamodel_mecab_name):\n",
    "    ldamodel_mecab = LdaModel( corpus = corpus_mecab, num_topics = 20,\n",
    "                              id2word = dictionary_mecab, passes = 50,\n",
    "                           chunksize = 12246, iterations = 200,\n",
    "                           alpha='auto', callbacks = callbacks_mecab)\n",
    "    ldamodel_mecab.save(ldamodel_mecab_name)\n",
    "else:\n",
    "    ldamodel_mecab = LdaModel.load(ldamodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_um_mecab = clusteringModelPath + 'coherence1_mecab_u_mass'\n",
    "if not os.path.isfile(coherence1_um_mecab):\n",
    "    cm_mecab = CoherenceModel(model = ldamodel_mecab, \n",
    "                      corpus = corpus_mecab, \n",
    "                      dictionary = dictionary_mecab,\n",
    "                      coherence = 'u_mass')\n",
    "    cm_mecab.save(coherence1_um_mecab)\n",
    "else:\n",
    "    cm_mecab = CoherenceModel.load(coherence1_um_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_mecab.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_cv_mecab = clusteringModelPath + 'coherence1_mecab_c_v'\n",
    "if not os.path.isfile(coherence1_cv_mecab):\n",
    "    cm_mecab_cv = CoherenceModel(model = ldamodel_mecab, \n",
    "                         texts = tagged_text_mecab,\n",
    "                         dictionary = dictionary_mecab, \n",
    "                         coherence = 'c_v')\n",
    "    cm_mecab_cv.save(coherence1_cv_mecab)\n",
    "else:\n",
    "    cm_mecab_cv = CoherenceModel.load(coherence1_cv_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_mecab_cv.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyLDAvis.gensim.prepare(ldamodel_mecab, corpus_mecab, dictionary_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_mecab = ldamodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### display num_topics - LDA graph using c_v coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_ct, c_v_ct = evaluate_graph(dictionary = dictionary_ct, corpus = corpus_ct, texts = tagged_text_ct, limit = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_mecab, c_v_mecab = evaluate_graph(dictionary = dictionary_mecab, corpus = corpus_mecab, texts = tagged_text_mecab, limit = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* The constructor estimates Dynamic Topic Model parameters based on a training corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_ct_name = clusteringModelPath + 'ldaseqmodel_ct'\n",
    "if not os.path.isfile(ldaseq_ct_name):\n",
    "    ldaseq_ct = ldaseqmodel.LdaSeqModel(corpus = corpus_ct, \n",
    "                                   id2word = dictionary_ct,\n",
    "                                   time_slice= [8164, 8164, 8164], \n",
    "                                   num_topics = 20)\n",
    "    ldaseq_ct.save(ldaseq_ct_name)\n",
    "else:\n",
    "    ldaseq_ct = ldaseqmodel.LdaSeqModel.load(ldaseq_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_ct, topic_term_ct, doc_lengths_ct, term_freq_ct,vocab_ct = ldaseq_ct.dtm_vis(time = 0, corpus = corpus_ct)\n",
    "vis_wrapper_ct = pyLDAvis.prepare(topic_term_dists = topic_term_ct,\n",
    "                               doc_topic_dists = doc_topic_ct,\n",
    "                              doc_lengths = doc_lengths_ct,\n",
    "                              vocab = vocab_ct, \n",
    "                              term_frequency = term_freq_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_mecab_name = clusteringModelPath + 'ldaseqmodel_mecab'\n",
    "if not os.path.isfile(ldaseq_mecab_name):\n",
    "    ldaseq_mecab = ldaseqmodel.LdaSeqModel(corpus = corpus_mecab, \n",
    "                                   id2word = dictionary_mecab,\n",
    "                                   time_slice = [8164, 8164, 8164], \n",
    "                                   num_topics = 20)\n",
    "    ldaseq_mecab.save(ldaseq_mecab_name)\n",
    "else:\n",
    "    ldaseq_mecab = ldaseqmodel.LdaSeqModel.load(ldaseq_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_mecab, topic_term_mecab, doc_lengths_mecab, term_freq_mecab,vocab_mecab = ldaseq_mecab.dtm_vis(time = 0, corpus = corpus_mecab)\n",
    "vis_wrapper_mecab = pyLDAvis.prepare(topic_term_dists = topic_term_mecab,\n",
    "                               doc_topic_dists = doc_topic_mecab,\n",
    "                              doc_lengths = doc_lengths_mecab,\n",
    "                              vocab = vocab_mecab, \n",
    "                              term_frequency = term_freq_mecab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* chain_variance : 0.05  \n",
    "> * a constant which dictates how the beta values evolve - it is a gaussian parameter defined in the beta distribution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_chain_ct_name = clusteringModelPath + 'ldaseqmodel_chain_ct'\n",
    "if not os.path.isfile(ldaseq_chain_ct_name):\n",
    "    ldaseq_chain_ct = ldaseqmodel.LdaSeqModel(corpus = corpus_ct, \n",
    "                                         id2word = dictionary_ct, \n",
    "                                         time_slice = [8164, 8164, 8164],\n",
    "                                         num_topics = 20, \n",
    "                                         chain_variance = 0.05)\n",
    "    ldaseq_chain_ct.save(ldaseq_chain_ct_name)\n",
    "else:\n",
    "    ldaseq_chain_ct = ldaseqmodel.LdaSeqModel.load(ldaseq_chain_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_chain_mecab_name = clusteringModelPath + 'ldaseqmodel_chain_mecab'\n",
    "if not os.path.isfile(ldaseq_chain_mecab_name):\n",
    "    ldaseq_chain_mecab = ldaseqmodel.LdaSeqModel(corpus = corpus_mecab, \n",
    "                                         id2word = dictionary_mecab, \n",
    "                                         time_slice = [8164, 8164, 8164],\n",
    "                                         num_topics = 20, \n",
    "                                         chain_variance = 0.05)\n",
    "    ldaseq_chain_mecab.save(ldaseq_chain_mecab_name)\n",
    "else:\n",
    "    ldaseq_chain_mecab = ldaseqmodel.LdaSeqModel.load(ldaseq_chain_mecab_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = '/Users/hyunyoun/Documents/GitHub/Private_Project/dtm-darwin64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtm_model_ct_name = clusteringModelPath + 'dtm_ct'\n",
    "if not os.path.isfile(dtm_model_ct_name):\n",
    "    dtm_model_ct = DtmModel(dtm_path, corpus = corpus_ct,  \n",
    "                       num_topics = 20, \n",
    "                       id2word = dictionary_ct, \n",
    "                       initialize_lda = True)\n",
    "    dtm_model_ct.save(dtm_model_ct_name)\n",
    "else:\n",
    "    dtm_model_ct = DtmModel.load(dtm_model_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_ct, topic_term_ct, doc_lengths_ct, term_freq_ct,vocab_ct = dtm_model_ct.dtm_vis(time = 0, corpus = corpus_ct)\n",
    "vis_wrapper_ct = pyLDAvis.prepare(topic_term_dists = topic_term_ct,\n",
    "                               doc_topic_dists = doc_topic_ct,\n",
    "                              doc_lengths = doc_lengths_ct,\n",
    "                              vocab = vocab_ct, \n",
    "                              term_frequency = term_freq_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtm_model_mecab_name = clusteringModelPath + 'dtm_mecab'\n",
    "if not os.path.isfile(dtm_model_mecab_name):\n",
    "    dtm_model_mecab = DtmModel(dtm_path, corpus = corpus_mecab, \n",
    "                       num_topics = 20, \n",
    "                       id2word = dictionary_mecab, \n",
    "                       initialize_lda = True)\n",
    "    \n",
    "    dtm_model_mecab.save(dtm_model_mecab_name)\n",
    "else:\n",
    "    dtm_model_mecab = DtmModel.load(dtm_model_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_mecab, topic_term_mecab, doc_lengths_mecab, term_freq_mecab,vocab_mecab = dtm_model_mecab.dtm_vis(time = 0, corpus = corpus_mecab)\n",
    "vis_wrapper_mecab = pyLDAvis.prepare(topic_term_dists = topic_term_mecab,\n",
    "                               doc_topic_dists = doc_topic_mecab,\n",
    "                              doc_lengths = doc_lengths_mecab,\n",
    "                              vocab = vocab_mecab, \n",
    "                              term_frequency = term_freq_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topics_wrapper_ct = dtm_model_ct.dtm_coherence(time = 0)\n",
    "topics_dtm_ct = ldaseq_ct.dtm_coherence(time = 2)\n",
    "topics_dtm2_ct = ldaseq_chain_ct.dtm_coherence( time = 2)\n",
    "\n",
    "cm_wrapper_ct = CoherenceModel(topics = topics_wrapper_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm_ct = CoherenceModel(topics = topics_dtm_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm2_ct = CoherenceModel(topics = topics_dtm2_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "print ('U_mass topic coherence')\n",
    "print ('Wrapper coherence is {}'.format(cm_wrapper_ct.get_coherence()))\n",
    "print ('DTM Python coherence is {}'.format(cm_dtm_ct.get_coherence()))\n",
    "print ('DTM (chain variance) Python coherence is {}'.format(cm_dtm2_ct.get_coherence()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topics_wrapper_mecab = dtm_model_mecab.dtm_coherence(time = 0)\n",
    "topics_dtm_mecab = ldaseq_mecab.dtm_coherence(time = 2)\n",
    "topics_dtm2_mecab = ldaseq_chain_mecab.dtm_coherence( time = 2)\n",
    "\n",
    "cm_wrapper_mecab = CoherenceModel(topics = topics_wrapper_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm_mecab = CoherenceModel(topics = topics_dtm_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm2_mecab = CoherenceModel(topics = topics_dtm2_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "print ('U_mass topic coherence')\n",
    "print ('Wrapper coherence is {}'.format(cm_wrapper_mecab.get_coherence()))\n",
    "print ('DTM Python coherence is {}'.format(cm_dtm_mecab.get_coherence()))\n",
    "print ('DTM (chain variance) Python coherence is {}'.format(cm_dtm2_mecab.get_coherence()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
