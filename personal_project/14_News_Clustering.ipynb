{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "import sys \n",
    "import os\n",
    "import logging\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, ldaseqmodel, LdaMulticore, lda_dispatcher\n",
    "from gensim.models.wrappers import LdaMallet, DtmModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer(doc, tagger, stopwords):\n",
    "    pos = tagger.pos(doc)\n",
    "    pos = [word[0] for word in pos if (len(word[0])>1) & (not word[0] in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nav_tokenizer_noun(doc, tagger, stopwords):\n",
    "    pos = tagger.nouns(doc)\n",
    "    pos = [word for word in pos if (len(word)>1) & (not word in stopwords)]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_graph(dictionary, corpus, texts, limit):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictNaver = pickle.load(open('./data/pre_data/stastics/for_statistics_Naver_from_mongodb.pickled','rb'))\n",
    "dfNaver = pd.DataFrame.from_dict(dictNaver, orient='index')\n",
    "print (dfNaver.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictDaum = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "dfDaum = pd.DataFrame.from_dict(dictDaum, orient='index')\n",
    "print (dfDaum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 기사 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedDf = pd.concat([dfNaver, dfDaum])\n",
    "combinedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData_text = combinedDf.title + '\\n' + combinedDf.mainText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform =='darwin':\n",
    "    clusteringPath ='/Volumes/disk1/Clustering/'\n",
    "    clusteringModelPath = '/Volumes/disk1/Clustering_model/'\n",
    "elif sys.platform =='win32':\n",
    "    clusteringPath = 'd:/Clustering/' \n",
    "    clusteringModelPath = 'd:/Clustering_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "ct = Twitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 명사만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_ct = clusteringPath + 'nouns_taggerd_news_text_by_ct.pickled'\n",
    "if not os.path.isfile(outfile_ct):\n",
    "    tagged_text_ct = [Nav_tokenizer_noun(doc, ct, stopwords) for doc in tqdm(rawData_text)]\n",
    "    pickle.dump(tagged_text_ct, open(outfile_ct, 'wb'))\n",
    "else:\n",
    "    tagged_text_ct = pickle.load(open(outfile_ct, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_mecab = clusteringPath + 'nouns_taggerd_news_text_by_mecab.pickled'\n",
    "if not os.path.isfile(outfile_mecab):\n",
    "    tagged_text_mecab = [Nav_tokenizer_noun(doc, mecab, stopwords) for doc in tqdm(rawData_text)]\n",
    "    pickle.dump(tagged_text_mecab, open(outfile_mecab, 'wb'))\n",
    "else:\n",
    "    tagged_text_mecab = pickle.load(open(outfile_mecab, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagged_text_ct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_text_mecab[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사전 데이터 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_ct_name = clusteringModelPath + 'dictionary_ct'\n",
    "dict_mecab_name = clusteringModelPath + 'dictionary_mecab'\n",
    "if not os.path.isfile(dict_ct_name):\n",
    "    dictionary_ct = Dictionary(tagged_text_ct)\n",
    "    dictionary_ct.save(dict_ct_name)\n",
    "else:\n",
    "    dictionary_ct = Dictionary.load(dict_ct_name)\n",
    "if not os.path.isfile(dict_mecab_name):\n",
    "    dictionary_mecab = Dictionary(tagged_text_mecab)\n",
    "    dictionary_mecab.save(dict_mecab_name)\n",
    "else:\n",
    "    dictionary_mecab = Dictionary.load(dict_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_ct_name = clusteringModelPath + 'corpus_ct.pickled'\n",
    "corpus_mecab_name = clusteringModelPath + 'corpus_mecab.pickled'\n",
    "if not os.path.isfile(corpus_ct_name):\n",
    "    corpus_ct = [ dictionary_ct.doc2bow(text) for text in tqdm(tagged_text_ct)]\n",
    "    pickle.dump(corpus_ct, open(corpus_ct_name, 'wb'))\n",
    "else:\n",
    "    corpus_ct = pickle.load(open(corpus_ct_name, 'rb'))\n",
    "if not os.path.isfile(corpus_mecab_name):\n",
    "    corpus_mecab = [ dictionary_mecab.doc2bow(text) for text in tqdm(tagged_text_mecab)]\n",
    "    pickle.dump(corpus_mecab, open(corpus_mecab_name, 'wb'))\n",
    "else:\n",
    "    corpus_mecab = pickle.load(open(corpus_mecab_name, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary_ct))\n",
    "print('Number of documents: %d' % len(corpus_ct))\n",
    "print('Number of unique tokens: %d' % len(dictionary_mecab))\n",
    "print('Number of documents: %d' % len(corpus_mecab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI (  Latent Semantic Indexing )\n",
    "* an indexing and retrieval method that uses a mathematical technique called singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lsimodel_ct_name = clusteringModelPath + 'lsimodel_ct'\n",
    "lsimodel_mecab_name = clusteringModelPath + 'lsimidel_mecab'\n",
    "if not os.path.isfile(lsimodel_ct_name):\n",
    "    lsimodel_ct = LsiModel(corpus = corpus_ct, num_topics = 20, id2word = dictionary_ct)\n",
    "    lsimodel_ct.save(lsimodel_ct_name)\n",
    "else:\n",
    "    lsimodel_ct = LsiModel.load(lsimodel_ct_name)\n",
    "if not os.path.isfile(lsimodel_mecab_name):\n",
    "    lsimodel_mecab = LsiModel(corpus = corpus_mecab, num_topics = 20, id2word = dictionary_mecab)\n",
    "    lsimodel_mecab.save(lsimodel_mecab_name)\n",
    "else:\n",
    "    lsimodel_mecab = LsiModel.load(lsimodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel_ct.show_topics(num_topics = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel_mecab.show_topics(num_topics = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsitopics_ct = lsimodel_ct.show_topics(formatted = False)\n",
    "lsitopics_mecab = lsimodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP (Hierarchical Dirichlet Process)\n",
    "* a non-parametric bayesian method (note the missing number of requested topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdpmodel_ct_name = clusteringModelPath+'hdpmodel_ct'\n",
    "hdpmodel_mecab_name = clusteringModelPath+'hdpmodel_mecab'\n",
    "if not os.path.isfile(hdpmodel_ct_name):\n",
    "    hdpmodel_ct = HdpModel(corpus = corpus_ct, id2word = dictionary_ct)\n",
    "    hdpmodel_ct.save(clusteringModelPath+'hdpmodel_ct')\n",
    "else:\n",
    "    hdpmodel_ct = HdpModel.load(hdpmodel_ct_name)\n",
    "if not os.path.isfile(hdpmodel_mecab_name):\n",
    "    hdpmodel_mecab = HdpModel(corpus = corpus_mecab, id2word = dictionary_mecab)\n",
    "    hdpmodel_mecab.save(clusteringModelPath+'hdpmodel_mecab')\n",
    "else:\n",
    "    hdpmodel_mecab = HdpModel.load(hdpmodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdpmodel_ct.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdpmodel_mecab.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdptopics_ct = hdpmodel_ct.show_topics(formatted = False)\n",
    "hdptopics_mecab = hdpmodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (Latent Dirichlet allocation)\n",
    "* a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA model1\n",
    "* basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_ct = PerplexityMetric(corpus = corpus_ct, logger = 'shell', \n",
    "                        title = 'Perplexity (twitter)')\n",
    "ch_umass_ct = CoherenceMetric(corpus = corpus_ct, coherence = 'u_mass', \n",
    "                             logger = 'shell', title = ' Coherence (u_mass)')\n",
    "ch_cv_ct = CoherenceMetric(corpus = corpus_ct, logger = 'shell', \n",
    "                          texts = tagged_text_ct, coherence = 'c_v', \n",
    "                          title = 'Coherence (c_v)')\n",
    "diff_kl_ct = DiffMetric(distance = 'kullback_leibler', \n",
    "                       logger = 'shell', title = 'Diff (kullback_leibler)')\n",
    "convergence_kl_ct = ConvergenceMetric(distance = 'jaccard', logger = 'shell', \n",
    "                                     title = 'Convergence (jaccard)')\n",
    "callbacks_ct = [pl_ct, ch_umass_ct, ch_cv_ct, diff_kl_ct, convergence_kl_ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ldamodel_ct_name = clusteringModelPath + 'ldamodel_ct'\n",
    "if not os.path.isfile(ldamodel_ct_name):\n",
    "    ldamodel_ct = LdaModel(corpus = corpus_ct, num_topics = 20,\n",
    "                           id2word = dictionary_ct, passes = 50,\n",
    "                           chunksize = 6123, iterations = 250,\n",
    "                           alpha='symmetric', callbacks = callbacks_ct)\n",
    "    ldamodel_ct.save(ldamodel_ct_name)\n",
    "else:\n",
    "    ldamodel_ct = LdaModel.load(ldamodel_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_um_ct_name = clusteringModelPath + 'coherence1_ct_u_mass'\n",
    "if not os.path.isfile(coherence1_um_ct_name):\n",
    "    cm_ct = CoherenceModel(model = ldamodel_ct, \n",
    "                      corpus = corpus_ct, \n",
    "                      dictionary = dictionary_ct,\n",
    "                      coherence = 'u_mass')\n",
    "    cm_ct.save(coherence1_um_ct_name)\n",
    "else:\n",
    "    cm_ct = CoherenceModel.load(coherence1_um_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_ct.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_cv_ct_name = clusteringModelPath + 'coherence1_ct_c_v'\n",
    "if not os.path.isfile(coherence1_cv_ct_name):\n",
    "    cm_ct_cv = CoherenceModel(model = ldamodel_ct, \n",
    "                         texts = tagged_text_ct,\n",
    "                         dictionary = dictionary_ct, \n",
    "                         coherence = 'c_v')\n",
    "    cm_ct_cv.save(coherence1_cv_ct_name)\n",
    "else:\n",
    "    cm_ct_cv = CoherenceModel.load(coherence1_cv_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_ct_cv.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyLDAvis.gensim.prepare(ldamodel_ct, corpus_ct, dictionary_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_ct = ldamodel_ct.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_mecab = PerplexityMetric(corpus = corpus_mecab, logger = 'shell', \n",
    "                           title = 'Perplexity (Mecab)')\n",
    "ch_umass_mecab = CoherenceMetric(corpus = corpus_mecab, coherence = 'u_mass', \n",
    "                             logger = 'shell', title = ' Coherence (u_mass)')\n",
    "ch_cv_mecab = CoherenceMetric(corpus = corpus_mecab, logger = 'shell', \n",
    "                          texts = tagged_text_mecab, coherence = 'c_v', \n",
    "                          title = 'Coherence (c_v)')\n",
    "diff_kl_mecab = DiffMetric(distance = 'kullback_leibler', \n",
    "                       logger = 'shell', title = 'Diff (kullback_leibler)')\n",
    "convergence_kl_mecab = ConvergenceMetric(distance = 'jaccard', logger = 'shell', \n",
    "                                     title = 'Convergence (jaccard)')\n",
    "callbacks_mecab = [pl_mecab, ch_umass_mecab, ch_cv_mecab, diff_kl_mecab, convergence_kl_mecab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ldamodel_mecab_name = clusteringModelPath + 'ldamodel_mecab'\n",
    "if not os.path.isfile(ldamodel_mecab_name):\n",
    "    ldamodel_mecab = LdaModel( corpus = corpus_mecab, num_topics = 20,\n",
    "                              id2word = dictionary_mecab, passes = 100,\n",
    "                           chunksize = 6123, iterations = 200,\n",
    "                           alpha='symmetric', callbacks = callbacks_mecab)\n",
    "    ldamodel_mecab.save(ldamodel_mecab_name)\n",
    "else:\n",
    "    ldamodel_mecab = LdaModel.load(ldamodel_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_um_mecab = clusteringModelPath + 'coherence1_mecab_u_mass'\n",
    "if not os.path.isfile(coherence1_um_mecab):\n",
    "    cm_mecab = CoherenceModel(model = ldamodel_mecab, \n",
    "                      corpus = corpus_mecab, \n",
    "                      dictionary = dictionary_mecab,\n",
    "                      coherence = 'u_mass')\n",
    "    cm_mecab.save(coherence1_um_mecab)\n",
    "else:\n",
    "    cm_mecab = CoherenceModel.load(coherence1_um_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_mecab.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coherence1_cv_mecab = clusteringModelPath + 'coherence1_mecab_c_v'\n",
    "if not os.path.isfile(coherence1_cv_mecab):\n",
    "    cm_mecab_cv = CoherenceModel(model = ldamodel_mecab, \n",
    "                         texts = tagged_text_mecab,\n",
    "                         dictionary = dictionary_mecab, \n",
    "                         coherence = 'c_v')\n",
    "    cm_mecab_cv.save(coherence1_cv_mecab)\n",
    "else:\n",
    "    cm_mecab_cv = CoherenceModel.load(coherence1_cv_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Coherence : {}'.format(cm_mecab_cv.get_coherence()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyLDAvis.gensim.prepare(ldamodel_mecab, corpus_mecab, dictionary_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatopics_mecab = ldamodel_mecab.show_topics(formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### display num_topics - LDA graph using c_v coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_ct, c_v_ct = evaluate_graph(dictionary = dictionary_ct, corpus = corpus_ct, texts = tagged_text_ct, limit = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lmlist_mecab, c_v_mecab = evaluate_graph(dictionary = dictionary_mecab, corpus = corpus_mecab, texts = tagged_text_mecab, limit = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* The constructor estimates Dynamic Topic Model parameters based on a training corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_ct_name = clusteringModelPath + 'ldaseqmodel_ct'\n",
    "if not os.path.isfile(ldaseq_ct_name):\n",
    "    ldaseq_ct = ldaseqmodel.LdaSeqModel(corpus = corpus_ct, \n",
    "                                   id2word = dictionary_ct,\n",
    "                                   time_slice= [8164, 8164, 8164], \n",
    "                                   num_topics = 20)\n",
    "    ldaseq_ct.save(ldaseq_ct_name)\n",
    "else:\n",
    "    ldaseq_ct = ldaseqmodel.LdaSeqModel.load(ldaseq_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_ct, topic_term_ct, doc_lengths_ct, term_freq_ct,vocab_ct = ldaseq_ct.dtm_vis(time = 0, corpus = corpus_ct)\n",
    "vis_wrapper_ct = pyLDAvis.prepare(topic_term_dists = topic_term_ct,\n",
    "                               doc_topic_dists = doc_topic_ct,\n",
    "                              doc_lengths = doc_lengths_ct,\n",
    "                              vocab = vocab_ct, \n",
    "                              term_frequency = term_freq_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_mecab_name = clusteringModelPath + 'ldaseqmodel_mecab'\n",
    "if not os.path.isfile(ldaseq_mecab_name):\n",
    "    ldaseq_mecab = ldaseqmodel.LdaSeqModel(corpus = corpus_mecab, \n",
    "                                   id2word = dictionary_mecab,\n",
    "                                   time_slice = [8164, 8164, 8164], \n",
    "                                   num_topics = 20)\n",
    "    ldaseq_mecab.save(ldaseq_mecab_name)\n",
    "else:\n",
    "    ldaseq_mecab = ldaseqmodel.LdaSeqModel.load(ldaseq_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_mecab, topic_term_mecab, doc_lengths_mecab, term_freq_mecab,vocab_mecab = ldaseq_mecab.dtm_vis(time = 0, corpus = corpus_mecab)\n",
    "vis_wrapper_mecab = pyLDAvis.prepare(topic_term_dists = topic_term_mecab,\n",
    "                               doc_topic_dists = doc_topic_mecab,\n",
    "                              doc_lengths = doc_lengths_mecab,\n",
    "                              vocab = vocab_mecab, \n",
    "                              term_frequency = term_freq_mecab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDASEQ\n",
    "* chain_variance : 0.05  \n",
    "> * a constant which dictates how the beta values evolve - it is a gaussian parameter defined in the beta distribution  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_chain_ct_name = clusteringModelPath + 'ldaseqmodel_chain_ct'\n",
    "if not os.path.isfile(ldaseq_chain_ct_name):\n",
    "    ldaseq_chain_ct = ldaseqmodel.LdaSeqModel(corpus = corpus_ct, \n",
    "                                         id2word = dictionary_ct, \n",
    "                                         time_slice = [8164, 8164, 8164],\n",
    "                                         num_topics = 20, \n",
    "                                         chain_variance = 0.05)\n",
    "    ldaseq_chain_ct.save(ldaseq_chain_ct_name)\n",
    "else:\n",
    "    ldaseq_chain_ct = ldaseqmodel.LdaSeqModel.load(ldaseq_chain_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ldaseq_chain_mecab_name = clusteringModelPath + 'ldaseqmodel_chain_mecab'\n",
    "if not os.path.isfile(ldaseq_chain_mecab_name):\n",
    "    ldaseq_chain_mecab = ldaseqmodel.LdaSeqModel(corpus = corpus_mecab, \n",
    "                                         id2word = dictionary_mecab, \n",
    "                                         time_slice = [8164, 8164, 8164],\n",
    "                                         num_topics = 20, \n",
    "                                         chain_variance = 0.05)\n",
    "    ldaseq_chain_mecab.save(ldaseq_chain_mecab_name)\n",
    "else:\n",
    "    ldaseq_chain_mecab = ldaseqmodel.LdaSeqModel.load(ldaseq_chain_mecab_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = '/Users/hyunyoun/Documents/GitHub/Private_Project/dtm-darwin64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtm_model_ct_name = clusteringModelPath + 'dtm_ct'\n",
    "if not os.path.isfile(dtm_model_ct_name):\n",
    "    dtm_model_ct = DtmModel(dtm_path, corpus = corpus_ct,  \n",
    "                       num_topics = 20, \n",
    "                       id2word = dictionary_ct, \n",
    "                       initialize_lda = True)\n",
    "    dtm_model_ct.save(dtm_model_ct_name)\n",
    "else:\n",
    "    dtm_model_ct = DtmModel.load(dtm_model_ct_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_ct, topic_term_ct, doc_lengths_ct, term_freq_ct,vocab_ct = dtm_model_ct.dtm_vis(time = 0, corpus = corpus_ct)\n",
    "vis_wrapper_ct = pyLDAvis.prepare(topic_term_dists = topic_term_ct,\n",
    "                               doc_topic_dists = doc_topic_ct,\n",
    "                              doc_lengths = doc_lengths_ct,\n",
    "                              vocab = vocab_ct, \n",
    "                              term_frequency = term_freq_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dtm_model_mecab_name = clusteringModelPath + 'dtm_mecab'\n",
    "if not os.path.isfile(dtm_model_mecab_name):\n",
    "    dtm_model_mecab = DtmModel(dtm_path, corpus = corpus_mecab, \n",
    "                       num_topics = 20, \n",
    "                       id2word = dictionary_mecab, \n",
    "                       initialize_lda = True)\n",
    "    \n",
    "    dtm_model_mecab.save(dtm_model_mecab_name)\n",
    "else:\n",
    "    dtm_model_mecab = DtmModel.load(dtm_model_mecab_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "doc_topic_mecab, topic_term_mecab, doc_lengths_mecab, term_freq_mecab,vocab_mecab = dtm_model_mecab.dtm_vis(time = 0, corpus = corpus_mecab)\n",
    "vis_wrapper_mecab = pyLDAvis.prepare(topic_term_dists = topic_term_mecab,\n",
    "                               doc_topic_dists = doc_topic_mecab,\n",
    "                              doc_lengths = doc_lengths_mecab,\n",
    "                              vocab = vocab_mecab, \n",
    "                              term_frequency = term_freq_mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topics_wrapper_ct = dtm_model_ct.dtm_coherence(time = 0)\n",
    "topics_dtm_ct = ldaseq_ct.dtm_coherence(time = 2)\n",
    "topics_dtm2_ct = ldaseq_chain_ct.dtm_coherence( time = 2)\n",
    "\n",
    "cm_wrapper_ct = CoherenceModel(topics = topics_wrapper_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm_ct = CoherenceModel(topics = topics_dtm_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm2_ct = CoherenceModel(topics = topics_dtm2_ct, corpus = corpus_ct,\n",
    "                            dictionaray = dictionary_ct, coherence = 'u_mass')\n",
    "\n",
    "print ('U_mass topic coherence')\n",
    "print ('Wrapper coherence is {}'.format(cm_wrapper_ct.get_coherence()))\n",
    "print ('DTM Python coherence is {}'.format(cm_dtm_ct.get_coherence()))\n",
    "print ('DTM (chain variance) Python coherence is {}'.format(cm_dtm2_ct.get_coherence()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "topics_wrapper_mecab = dtm_model_mecab.dtm_coherence(time = 0)\n",
    "topics_dtm_mecab = ldaseq_mecab.dtm_coherence(time = 2)\n",
    "topics_dtm2_mecab = ldaseq_chain_mecab.dtm_coherence( time = 2)\n",
    "\n",
    "cm_wrapper_mecab = CoherenceModel(topics = topics_wrapper_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm_mecab = CoherenceModel(topics = topics_dtm_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "cm_dtm2_mecab = CoherenceModel(topics = topics_dtm2_mecab, corpus = corpus_mecab,\n",
    "                            dictionaray = dictionary_mecab, coherence = 'u_mass')\n",
    "\n",
    "print ('U_mass topic coherence')\n",
    "print ('Wrapper coherence is {}'.format(cm_wrapper_mecab.get_coherence()))\n",
    "print ('DTM Python coherence is {}'.format(cm_dtm_mecab.get_coherence()))\n",
    "print ('DTM (chain variance) Python coherence is {}'.format(cm_dtm2_mecab.get_coherence()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
