{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "> * Positive or Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import html\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "import multiprocessing\n",
    "from konlpy.tag import Mecab\n",
    "from konlpy.utils import pprint\n",
    "import numpy as np\n",
    "from ckonlpy.tag import Twitter as ctwitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "mecab = Mecab()\n",
    "ct = ctwitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_ct = pickle.load(open('./data/pre_data/pre_by_ct_data_tagged_run_docs.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tagged_ct, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectorizer = doc2vec.Doc2Vec(size=2500, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "doc_vectorizer.build_vocab(train)\n",
    "\n",
    "for epoch in range(30):\n",
    "    doc_vectorizer.train(train, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002  # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha  # fix the learning rate, no decay\n",
    "\n",
    "#To save\n",
    "doc_vectorizer.save('./model/doc2vec_size2500_epoch30_by_ct.model')\n",
    "pprint(doc_vectorizer.most_similar('문재인/Noun'))\n",
    "pprint(doc_vectorizer.most_similar('노무현/Noun'))\n",
    "pprint(doc_vectorizer.most_similar('박근혜/Noun'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc2vec.Doc2Vec.load('./model/doc2vec_size2000_epoch30_by_ct.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [model.infer_vector(doc.words) for doc in train]\n",
    "train_y = [doc.tags[0] for doc in train]\n",
    "test_x = [model.infer_vector(doc.words) for doc in test]\n",
    "test_y = [doc.tags[0] for doc in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=1234)\n",
    "classifier.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classifier.score(test_x, test_y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_mecab = pickle.load(open('./data/pre_data/pre_by_mecab_data_tagged_run_docs.pickled','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 = train_test_split(tagged_mecab, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = doc2vec.Doc2Vec.load('./model/doc2vec_size2000_epoch30_by_mecab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2_x = [model2.infer_vector(doc.words) for doc in train2]\n",
    "train2_y = [doc.tags[0] for doc in train2]\n",
    "test2_x = [model2.infer_vector(doc.words) for doc in test2]\n",
    "test2_y = [doc.tags[0] for doc in test2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = LogisticRegression(random_state=1234)\n",
    "classifier2.fit(train2_x, train2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classifier2.score(test2_x, test2_y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
