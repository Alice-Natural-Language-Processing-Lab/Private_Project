{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음의 News Classification Using FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunyoun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import html\n",
    "import multiprocessing\n",
    "from collections import namedtuple, OrderedDict\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings \n",
    "from numba import jit\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import FastText, KeyedVectors\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from konlpy.utils import pprint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve,  accuracy_score, auc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras_tqdm import TQDMCallback, TQDMNotebookCallback\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Input, Flatten, Dense, Embedding, embeddings, merge, Dropout, Activation,  LSTM, Bidirectional, SimpleRNN, GRU\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout1D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.layers.merge import dot\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3394246986896511570\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Basic_Module as bm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daum : (9372, 11)\n"
     ]
    }
   ],
   "source": [
    "#Daum\n",
    "daumData = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "daumData = pd.DataFrame.from_dict(daumData, orient = 'index')\n",
    "daumData.reset_index(inplace = True)\n",
    "daumData.rename(columns = {'index' : 'id'}, inplace = True)\n",
    "extDaumData = daumData.loc[:,['id','title','extracted_keywords']].copy()\n",
    "print ('Daum : {}'.format(daumData.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT/과학' '경제' '사회' '생활/문화' '세계' '스포츠' '연예' '정치']\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('./data/pre_data/news_tagged_data/pre_data_category_label_encoder_by_ct_for_doc2vec_news_classification.pickled'):\n",
    "    le = pickle.load(open('./data/pre_data/news_tagged_data/pre_data_category_label_encoder_by_ct_for_doc2vec_news_classification.pickled','rb'))\n",
    "else:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(naverData['category'])\n",
    "    pickle.dump(le, open('./data/pre_data/news_tagged_data/pre_data_category_label_encoder_by_ct_for_doc2vec_news_classification.pickled','wb'))\n",
    "print (le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if sys.platform =='darwin':\n",
    "    loadModelPath = '/Volumes/disk1/news_model/'\n",
    "elif sys.platform =='win32':\n",
    "    loadModelPath = 'd:/news_model/'\n",
    "daumNewsPath = './data/pre_data/news_daum_news/'\n",
    "classifierPath = './data/pre_data/news_classifier/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a2a61bf588c13481c229d1e</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>1093</td>\n",
       "      <td>911</td>\n",
       "      <td>1</td>\n",
       "      <td>\"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소</td>\n",
       "      <td>주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...</td>\n",
       "      <td>[부작용, 비아그라, 아일랜드]</td>\n",
       "      <td>{건강, 남성들, 공장, 부작용, 세보 효과, 연기, 지역}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a2a61bf588c13481c229d1f</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>헬스조선</td>\n",
       "      <td>603</td>\n",
       "      <td>386</td>\n",
       "      <td>2</td>\n",
       "      <td>식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지</td>\n",
       "      <td>점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...</td>\n",
       "      <td>[커피, 낮잠, 음식물]</td>\n",
       "      <td>{커피, 철분, 건강, 입냄새, 식후, 자세, 치아, 낮잠, 점심 식사, 디스크}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a2a61bf588c13481c229d20</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1067</td>\n",
       "      <td>811</td>\n",
       "      <td>3</td>\n",
       "      <td>'십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"</td>\n",
       "      <td>(성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...</td>\n",
       "      <td>[살인혐의, 철원, 검찰송치]</td>\n",
       "      <td>{성관계, 경찰, 범행, 진술, 철원, 앙심, 지인, 주변, 남편, 아들}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a2a61bf588c13481c229d21</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>헤럴드경제</td>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>신영자, 억 소리나는 갑질</td>\n",
       "      <td>신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...</td>\n",
       "      <td>[신영자, 갑질, 롯데백화점]</td>\n",
       "      <td>{유통업체, 검찰, 혐의, 매장, 롯데, 네이처리퍼블릭, 신영자 이사장, 징역}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a2a61bf588c13481c229d22</td>\n",
       "      <td>뉴스</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>434</td>\n",
       "      <td>368</td>\n",
       "      <td>5</td>\n",
       "      <td>\"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지</td>\n",
       "      <td>(청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...</td>\n",
       "      <td>[공범, 살인, 과자]</td>\n",
       "      <td>{폭행, 경찰, 범행, 남자친구, 쪽지, 혐의, 과자, 유치장}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id category        date  press  number_of_comment  \\\n",
       "0  5a2a61bf588c13481c229d1e       뉴스  2017.12.07   세계일보               1093   \n",
       "1  5a2a61bf588c13481c229d1f       뉴스  2017.12.07   헬스조선                603   \n",
       "2  5a2a61bf588c13481c229d20       뉴스  2017.12.07   연합뉴스               1067   \n",
       "3  5a2a61bf588c13481c229d21       뉴스  2017.12.07  헤럴드경제                418   \n",
       "4  5a2a61bf588c13481c229d22       뉴스  2017.12.07   연합뉴스                434   \n",
       "\n",
       "   number_of_crawled_comment rank                                title  \\\n",
       "0                        911    1     \"밤이 무섭다\"..비아그라 공장 연기에 남성들 부작용 호소   \n",
       "1                        386    2  식후 커피·늦은 양치질..점심식사 후 하면 안 좋은 습관 3가지   \n",
       "2                        811    3  '십년지기 생매장' 진짜 이유는..\"'청부 통정' 알려질까 봐\"   \n",
       "3                        369    4                       신영자, 억 소리나는 갑질   \n",
       "4                        368    5   \"배신하지마\" 20대女 살인 피의자 유치장서 공범 남친에 쪽지   \n",
       "\n",
       "                                            mainText           keywords  \\\n",
       "0   주민들은 공장에서 배출된 연기가 '남성이 매우 건강해지는 부작용'을 일으킨다며, ...  [부작용, 비아그라, 아일랜드]   \n",
       "1   점심식사를 마친 후 후식으로 커피를 마시는 사람들이 많다. 실제로 직장이 밀집돼 ...      [커피, 낮잠, 음식물]   \n",
       "2   (성남=연합뉴스) 최해민 기자 = 십년지기 지인을 산 채로 묻어 살해한 50대 여...   [살인혐의, 철원, 검찰송치]   \n",
       "3  신영자, 적용안된 혐의→검찰 상고에서 인정\\n신영자, 얼마를 어떻게 받았나  [헤럴...   [신영자, 갑질, 롯데백화점]   \n",
       "4  (청주=연합뉴스) 이승민 기자 = 지난 9월 청주의 한 하천에서 20대 여성을 둔기...       [공범, 살인, 과자]   \n",
       "\n",
       "                              extracted_keywords  \n",
       "0              {건강, 남성들, 공장, 부작용, 세보 효과, 연기, 지역}  \n",
       "1  {커피, 철분, 건강, 입냄새, 식후, 자세, 치아, 낮잠, 점심 식사, 디스크}  \n",
       "2      {성관계, 경찰, 범행, 진술, 철원, 앙심, 지인, 주변, 남편, 아들}  \n",
       "3   {유통업체, 검찰, 혐의, 매장, 롯데, 네이처리퍼블릭, 신영자 이사장, 징역}  \n",
       "4            {폭행, 경찰, 범행, 남자친구, 쪽지, 혐의, 과자, 유치장}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daumData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Mecab\n",
    "ct = Twitter()\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data set으로 부터 TF-IDF Vectorizer을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12852/12852 [00:00<00:00, 805769.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12852, 73912)\n",
      "vocab size : 73912\n"
     ]
    }
   ],
   "source": [
    "trainName = './data/pre_data/news_train_test_Data/pre_data_fastText_train_for_news_classification_by_ct.pickled'\n",
    "train = pickle.load(open(trainName, 'rb'))\n",
    "tfidf = bm.Build_tfidf(train)\n",
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News to Tagged Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9372/9372 [1:17:24<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags category')\n",
    "if os.path.isfile('./data/pre_data/news_tagged_data/pre_data_daum_news_by_ct_for_fastText_news_classification.pickled'):\n",
    "    daumData2 = pickle.load(open('./data/pre_data/news_tagged_data/pre_data_daum_news_by_ct_for_fastText_news_classification.pickled', 'rb'))\n",
    "else:\n",
    "    daumData2 = bm.MakeTaggedDataDAUM2(daumData, TaggedDocument, ct, stopwords, 'daum')\n",
    "    pickle.dump(daumData2, open('./data/pre_data/news_tagged_data/pre_data_daum_news_by_ct_for_fastText_news_classification.pickled', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-0_cbow_mean-0_min_count-2_by-ct.model')\n",
    "model2 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-0_cbow_mean-1_min_count-2_by-ct.model')\n",
    "model3 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-1_cbow_mean-0_min_count-2_by-ct.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1383/80610 [00:00<00:05, 13403.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80610, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80610/80610 [00:02<00:00, 35105.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:02.320463\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [05:04, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:05:07.633408\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model1, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model1,'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "NeuralNetwork_1\n",
      "XGBoost\n",
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "NeuralNetwork_2\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 148324.16it/s]\n",
      "9372it [00:00, 399234.39it/s]\n",
      "9372it [00:00, 382558.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 1.34 s, total: 52.6 s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1357/80610 [00:00<00:06, 12700.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80610, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80610/80610 [00:02<00:00, 28450.30it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:02.849950\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [05:28, 28.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:05:32.445265\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model2, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model2,'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_2\n",
      "XGBoost\n",
      "RandomForestClassifier\n",
      "LogisticRegression\n",
      "SVC\n",
      "NeuralNetwork_1\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 72528.67it/s]\n",
      "9372it [00:00, 253392.40it/s]\n",
      "9372it [00:00, 320803.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 s, sys: 895 ms, total: 40.9 s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2788/80610 [00:00<00:02, 26828.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80610, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80610/80610 [00:01<00:00, 43018.18it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:01.879819\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [05:51, 26.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:05:53.770223\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model3, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model3,'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_2\n",
      "XGBoost\n",
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "SVC\n",
      "NeuralNetwork_1\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 374774.92it/s]\n",
      "9372it [00:00, 185470.63it/s]\n",
      "9372it [00:00, 423784.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.1 s, sys: 643 ms, total: 40.7 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data set으로 부터 TF-IDF Vectorizer을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12852/12852 [00:00<00:00, 790248.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12852, 73347)\n",
      "vocab size : 73347\n"
     ]
    }
   ],
   "source": [
    "trainName = './data/pre_data/news_train_test_Data/pre_data_fastText_train_for_news_classification_by_mecab.pickled'\n",
    "train = pickle.load(open(trainName, 'rb'))\n",
    "tfidf = bm.Build_tfidf(train)\n",
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News to Tagged Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9372/9372 [11:05<00:00, 14.08it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('./data/pre_data/news_tagged_data/pre_data_daum_news_by_mecab_for_fastText_news_classification.pickled'):\n",
    "    daumData2 = pickle.load(open('./data/pre_data/news_tagged_data/pre_data_daum_news_by_mecab_for_fastText_news_classification.pickled', 'rb'))\n",
    "else:\n",
    "    daumData2 = bm.MakeTaggedDataDAUM2(daumData, TaggedDocument, mecab, stopwords, 'daum')\n",
    "    pickle.dump(daumData2, open('./data/pre_data/news_tagged_data/pre_data_daum_news_by_mecab_for_fastText_news_classification.pickled', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-0_cbow_mean-0_min_count-2_by-mecab.model')\n",
    "model2 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-0_cbow_mean-1_min_count-2_by-mecab.model')\n",
    "model3 = FastText.load(loadModelPath+'fastText_size-500_epoch-20_ngrams-3_window-10_negative-7_hs-0_sg-1_cbow_mean-0_min_count-2_by-mecab.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2268/80210 [00:00<00:03, 22466.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80210, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80210/80210 [00:03<00:00, 25410.46it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:03.184548\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [06:57, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:07:01.275496\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model1, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model1,'mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "XGBoost\n",
      "NeuralNetwork_2\n",
      "LogisticRegression\n",
      "NeuralNetwork_1\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 375734.97it/s]\n",
      "9372it [00:00, 240988.11it/s]\n",
      "9372it [00:00, 214120.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.1 s, sys: 1.56 s, total: 55.7 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80210, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80210/80210 [00:05<00:00, 14661.13it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:05.486503\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [06:11, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:06:17.729918\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model2, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model2,'mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "XGBoost\n",
      "NeuralNetwork_2\n",
      "LogisticRegression\n",
      "SVC\n",
      "NeuralNetwork_1\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 406963.56it/s]\n",
      "9372it [00:00, 139695.36it/s]\n",
      "9372it [00:00, 289204.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 s, sys: 868 ms, total: 42.1 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2778/80210 [00:00<00:02, 27489.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=80210, size=500, alpha=0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80210/80210 [00:01<00:00, 41266.08it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 0:00:01.951271\n",
      "Vectorizing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [03:52, 40.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling Data\n",
      "total running time : 0:03:55.253834\n"
     ]
    }
   ],
   "source": [
    "wv1, vecs_w2v = bm.Make_Pre_Data_For_DAUM(model3, tfidf, 500, daumData2)\n",
    "modelName = bm.Return_ModelName('fastText', model3,'mecab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = glob(classifierPath+'*'+modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_2\n",
      "LogisticRegression\n",
      "SVC\n",
      "NeuralNetwork_1\n",
      "RandomForestClassifier\n",
      "XGBoost\n"
     ]
    }
   ],
   "source": [
    "loadClassifierDict = dict(map(lambda x:bm.LoadClassifier(x), classifierList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9372it [00:00, 374610.63it/s]\n",
      "9372it [00:00, 424631.82it/s]\n",
      "9372it [00:00, 418599.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.3 s, sys: 683 ms, total: 42 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "warnings.filterwarnings('ignore')\n",
    "predictOutcome = dict(map(lambda x: bm.PredictNewsClassification(vecs_w2v, x, loadClassifierDict[x]), loadClassifierDict))\n",
    "predictOutcome = pd.DataFrame.from_dict(predictOutcome)\n",
    "predictOutcome = predictOutcome.applymap(lambda x: le.inverse_transform(int(x)))\n",
    "predictOutcome = extDaumData.merge(predictOutcome,\n",
    "                                   left_index = True, right_index = True)\n",
    "predictOutcome.to_csv('./outcome_news_classification/outcome_news_classification_'+modelName,index=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
