{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import warnings\n",
    "import sys \n",
    "import os\n",
    "import logging\n",
    "from multiprocessing import cpu_count\n",
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ckonlpy.tag import Twitter\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, ldaseqmodel, LdaMulticore, lda_dispatcher, doc2vec\n",
    "from gensim.models.wrappers import LdaMallet, DtmModel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "from gensim.matutils import hellinger\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Twitter()\n",
    "mecab = Mecab()\n",
    "def nav_tokenizer(tagger, corpus, stopwords):\n",
    "    pos = tagger.pos(corpus)\n",
    "    pos = ['/'.join(t) for t in pos if not t[0] in stopwords]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTaggedData(df, taggedDoc, tagger, stopwords):\n",
    "    w2v_docs = list()\n",
    "    for idx in tqdm(df.index):\n",
    "        text = df.loc[idx,'title']+'.\\n'+df.loc[idx,'mainText']\n",
    "        pos = nav_tokenizer(tagger, text, stopwords)\n",
    "        label = ['news_'+str(idx)]\n",
    "        w2v_docs.append(TaggedDocument(pos, label))\n",
    "    return w2v_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = int(multiprocessing.cpu_count())\n",
    "def Make_Doc2Vec_Model(modelPath, data, size, dm, dm_concat, dm_mean, hs, negative, epoch, window, alpha, min_alpha, workers, tagger):\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas(desc=\"progress-bar\")\n",
    "    from datetime import datetime\n",
    "    from gensim.models import doc2vec\n",
    "    start = datetime.now()\n",
    "    modelName = 'doc2vec_size-{}_epoch-{}_window-{}_negative-{}_hs-{}_dm-{}_dm_concat-{}_dm_mean-{}_by-{}.model'.format(\n",
    "        size, epoch, window, negative, hs, dm, dm_concat, dm_mean, tagger)\n",
    "    modelName = modelPath+modelName\n",
    "    print (modelName)\n",
    "    if window!=None:\n",
    "        d2v_model = doc2vec.Doc2Vec(vector_size = size, dm = dm, dm_concat = dm_concat,\n",
    "                   dm_mean = dm_mean, negative = negative, hs = hs, window = window,\n",
    "                   alpha = alpha, min_alpha = min_alpha, workers = workers, epochs= epoch)\n",
    "    else:\n",
    "        d2v_model = doc2vec.Doc2Vec(vector_size = size, dm = dm, dm_concat = dm_concat,\n",
    "                   dm_mean = dm_mean, negative = negative, hs = hs,\n",
    "                   alpha = alpha, min_alpha = min_alpha, workers = workers, epochs= epoch)\n",
    "    d2v_model.build_vocab(tqdm(data))\n",
    "    d2v_model.train_lbls = False # do not train labels of words\n",
    "    d2v_model.train(tqdm(data), total_examples=d2v_model.corpus_count, epochs=d2v_model.iter)\n",
    "    \n",
    "    end = datetime.now()\n",
    "    d2v_model.save(modelName)\n",
    "    print (\"Total running time: \", end-start)\n",
    "    return d2v_model\n",
    "print (cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = Twitter()\n",
    "mecab = Mecab()\n",
    "def nav_tokenizer(tagger, corpus, stopwords):\n",
    "    pos = tagger.pos(corpus)\n",
    "    pos = ['/'.join(t) for t in pos if not t[0] in stopwords]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = open('./data/stopwordsList.txt',encoding='utf-8').readlines()\n",
    "stopwords = list(map(lambda x: x.strip(), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15120, 10)\n"
     ]
    }
   ],
   "source": [
    "dictNaver = pickle.load(open('./data/pre_data/stastics/for_statistics_Naver_from_mongodb.pickled','rb'))\n",
    "dfNaver = pd.DataFrame.from_dict(dictNaver, orient='index')\n",
    "print (dfNaver.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9372, 10)\n"
     ]
    }
   ],
   "source": [
    "dictDaum = pickle.load(open('./data/pre_data/stastics/for_statistics_daum_from_mongodb.pickled','rb'))\n",
    "dfDaum = pd.DataFrame.from_dict(dictDaum, orient='index')\n",
    "print (dfDaum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴스기사 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>press</th>\n",
       "      <th>number_of_comment</th>\n",
       "      <th>number_of_crawled_comment</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>mainText</th>\n",
       "      <th>keywords</th>\n",
       "      <th>extracted_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973a</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>1713</td>\n",
       "      <td>1465</td>\n",
       "      <td>1</td>\n",
       "      <td>北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"</td>\n",
       "      <td>美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...</td>\n",
       "      <td>[외무성, 핵전쟁, 대변인]</td>\n",
       "      <td>{조선반도, 핵전쟁, 미국, 북한, 고위, 중앙, 도화선, 대변인}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973b</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>한국일보</td>\n",
       "      <td>2551</td>\n",
       "      <td>2062</td>\n",
       "      <td>2</td>\n",
       "      <td>예산전쟁, 예결위 간사ㆍ호남이 웃었다</td>\n",
       "      <td>예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...</td>\n",
       "      <td>[예산, 예결위, soc]</td>\n",
       "      <td>{의원, 정부안, 증액, 지역구, 예산안, 호남, 국민의당}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973c</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>610</td>\n",
       "      <td>536</td>\n",
       "      <td>3</td>\n",
       "      <td>혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나</td>\n",
       "      <td>【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...</td>\n",
       "      <td>[최경환, 구속영장, 국가정보원]</td>\n",
       "      <td>{의원, 국정원장, 혐의, 구속영장 청구, 검찰, 조사, 정기국회}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973d</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>145</td>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "      <td>최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"</td>\n",
       "      <td>감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...</td>\n",
       "      <td>[이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]</td>\n",
       "      <td>{후보자, 법관, 감사원장, 생활, 지명, 공직 사회}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a29c445588c132954d1973e</th>\n",
       "      <td>정치</td>\n",
       "      <td>2017.12.07</td>\n",
       "      <td>동아일보</td>\n",
       "      <td>1074</td>\n",
       "      <td>932</td>\n",
       "      <td>5</td>\n",
       "      <td>B-1B 한반도에 뜨자, 평양 비운 김정은</td>\n",
       "      <td>[동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...</td>\n",
       "      <td>[김정은, b-1b, 한반도]</td>\n",
       "      <td>{양강도, 사무차장, 훈련, 공장, 시찰, 펠트먼, 접경, 김정은, 삼지연}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category        date press  number_of_comment  \\\n",
       "5a29c445588c132954d1973a       정치  2017.12.07  연합뉴스               1713   \n",
       "5a29c445588c132954d1973b       정치  2017.12.07  한국일보               2551   \n",
       "5a29c445588c132954d1973c       정치  2017.12.07   뉴시스                610   \n",
       "5a29c445588c132954d1973d       정치  2017.12.07  연합뉴스                145   \n",
       "5a29c445588c132954d1973e       정치  2017.12.07  동아일보               1074   \n",
       "\n",
       "                          number_of_crawled_comment rank  \\\n",
       "5a29c445588c132954d1973a                       1465    1   \n",
       "5a29c445588c132954d1973b                       2062    2   \n",
       "5a29c445588c132954d1973c                        536    3   \n",
       "5a29c445588c132954d1973d                        133    4   \n",
       "5a29c445588c132954d1973e                        932    5   \n",
       "\n",
       "                                                    title  \\\n",
       "5a29c445588c132954d1973a    北외무성 \"전쟁 바라지 않지만 결코 피하지 않을 것\"   \n",
       "5a29c445588c132954d1973b             예산전쟁, 예결위 간사ㆍ호남이 웃었다   \n",
       "5a29c445588c132954d1973c  혐의 부인에 20시간 조사…檢, 최경환 구속 카드 꺼내나   \n",
       "5a29c445588c132954d1973d   최재형 감사원장 후보자 \"독립성 강화는 임명권자의 뜻\"   \n",
       "5a29c445588c132954d1973e          B-1B 한반도에 뜨자, 평양 비운 김정은   \n",
       "\n",
       "                                                                   mainText  \\\n",
       "5a29c445588c132954d1973a  美고위인사 대북언급 비난하며 \"전쟁 기정사실화\" 위협  며칠 새 이어지는 북한 군민...   \n",
       "5a29c445588c132954d1973b  예결위 간사들이 최대 수혜자..당 지도부 내 몫 챙기기도 여전   황주홍ㆍ김도읍 등...   \n",
       "5a29c445588c132954d1973c  【서울=뉴시스】 최진석 기자 = 박근혜 정부 시절 국가정보원 특수활동비 수수 의혹 ...   \n",
       "5a29c445588c132954d1973d  감사원장에 내정된 최재형 사법연수원장(고양=연합뉴스) 이희열 기자 = 7일 감사원장...   \n",
       "5a29c445588c132954d1973e  [동아일보] 북중 접경지 양강도 삼지연 시찰… 방북 유엔 사무차장 면담 안할듯 B-...   \n",
       "\n",
       "                                                    keywords  \\\n",
       "5a29c445588c132954d1973a                     [외무성, 핵전쟁, 대변인]   \n",
       "5a29c445588c132954d1973b                      [예산, 예결위, soc]   \n",
       "5a29c445588c132954d1973c                  [최경환, 구속영장, 국가정보원]   \n",
       "5a29c445588c132954d1973d  [이슈 · 최재형 감사원장 내정, 감사원장, 최재형, 감사원]   \n",
       "5a29c445588c132954d1973e                    [김정은, b-1b, 한반도]   \n",
       "\n",
       "                                                  extracted_keywords  \n",
       "5a29c445588c132954d1973a       {조선반도, 핵전쟁, 미국, 북한, 고위, 중앙, 도화선, 대변인}  \n",
       "5a29c445588c132954d1973b           {의원, 정부안, 증액, 지역구, 예산안, 호남, 국민의당}  \n",
       "5a29c445588c132954d1973c       {의원, 국정원장, 혐의, 구속영장 청구, 검찰, 조사, 정기국회}  \n",
       "5a29c445588c132954d1973d              {후보자, 법관, 감사원장, 생활, 지명, 공직 사회}  \n",
       "5a29c445588c132954d1973e  {양강도, 사무차장, 훈련, 공장, 시찰, 펠트먼, 접경, 김정은, 삼지연}  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDf = pd.concat([dfNaver, dfDaum])\n",
    "combinedDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform =='darwin':\n",
    "    clusteringPath ='/Volumes/disk1/Clustering_doc2vec/'\n",
    "    \n",
    "elif sys.platform =='win32':\n",
    "    clusteringPath = 'd:/Clustering_doc2vec/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec 기본 포맷으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_ct = 'ct'\n",
    "filename_ct = clusteringPath+'predata_doc2vec_{}'.format(tagger_ct)\n",
    "if os.path.isfile(filename_ct):\n",
    "    w2v_docs_ct = pickle.load(open(filename_ct, 'rb'))\n",
    "else:\n",
    "    w2v_docs_ct = MakeTaggedData(combinedDf, TaggedDocument, ct, stopwords)\n",
    "    pickle.dump(w2v_docs_ct, open(filename_ct,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Doc2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 814/24492 [00:00<00:05, 4054.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/disk1/Clustering_doc2vec/doc2vec_size-300_epoch-20_window-5_negative-7_hs-0_dm-1_dm_concat-1_dm_mean-0_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24492/24492 [00:04<00:00, 5279.94it/s]\n",
      "100%|██████████| 24492/24492 [02:49<00:00, 144.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:54:02.643884\n",
      "CPU times: user 1h 30min 7s, sys: 1min 36s, total: 1h 31min 43s\n",
      "Wall time: 54min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "modelName = '/Volumes/disk1/Clustering_doc2vec/doc2vec_size-300_epoch-20_window-5_negative-7_hs-0_dm-1_dm_concat-1_dm_mean-0_by-ct.model'\n",
    "if not os.path.isfile(modelName):\n",
    "    d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_ct, size = 300, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')\n",
    "else:\n",
    "    d2v_model = doc2vec.Doc2Vec.load(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 270/24492 [00:00<00:09, 2629.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/disk1/Clustering_doc2vec/doc2vec_size-300_epoch-20_window-10_negative-7_hs-0_dm-1_dm_concat-0_dm_mean-1_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24492/24492 [00:11<00:00, 2102.79it/s]\n",
      "100%|██████████| 24492/24492 [00:47<00:00, 515.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  0:13:25.071448\n",
      "CPU times: user 29min 35s, sys: 48.7 s, total: 30min 23s\n",
      "Wall time: 13min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_ct, size = 300, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/24492 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/disk1/Clustering_doc2vec/doc2vec_size-300_epoch-20_window-None_negative-7_hs-0_dm-0_dm_concat-0_dm_mean-0_by-ct.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24492/24492 [00:03<00:00, 6764.50it/s]\n",
      "100%|██████████| 24492/24492 [00:26<00:00, 937.08it/s] \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# PV - DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_ct, size = 300, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = None,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_ct = 'mecab'\n",
    "filename_ct = clusteringPath+'predata_doc2vec_{}'.format(tagger_ct)\n",
    "if os.path.isfile(filename_ct):\n",
    "    w2v_docs_mecab = pickle.load(open(filename_ct, 'rb'))\n",
    "else:\n",
    "    w2v_docs_mecab = MakeTaggedData(combinedDf, TaggedDocument, mecab, stopwords)\n",
    "    pickle.dump(w2v_docs_mecab, open(filename_ct,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM W/\n",
    "d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_mecab, size = 300, dm = 1, dm_concat = 1,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = 5,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#PV-DM w/\n",
    "d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_mecab, size = 300, dm = 1, dm_concat = 0,\n",
    "                   dm_mean = 1, negative = 7, hs = 0, epoch = 20, window = 10,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# PV - DBOW\n",
    "d2v_model = Make_Doc2Vec_Model(modelPath=clusteringPath, data=w2v_docs_mecab, size = 300, dm = 0, dm_concat = 0,\n",
    "                   dm_mean = 0, negative = 7, hs = 0, epoch = 20, window = None,\n",
    "                   alpha = 0.025, min_alpha = 0.025, workers = cores, tagger = 'ct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
